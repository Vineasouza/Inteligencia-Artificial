{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worthy-combat",
   "metadata": {},
   "source": [
    "#### https://keras.io/api/applications/xception/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electric-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "formal-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500 # quantidade de vezes a ser executado o algoritmo, uma epoch é quanto todo o conjunto de treino foi utilizado\n",
    "batch = 32 # número de amostras que será carregado a cada execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "round-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega o modelo da InceptionResNetV2 com os pesos aprendidos no treino da InceptionResNetV2 sem a camada densa (include_top=False)\n",
    "base_model = tf.keras.applications.Xception(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elegant-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O restante do modelo e suas camadas são discutidos a seguir \n",
    "# x recebe o final da InceptionResNetV2\n",
    "x=base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extended-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 1 512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 2 32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 7 186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 7 2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          262272      global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            99          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,134,187\n",
      "Trainable params: 21,079,659\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Nova configuração para o modelo\n",
    "\n",
    "#adiciona apos x uma camada GlobalMaxPooling2D e atribui este no a x novamente (logo x e o topo novamente)\n",
    "x=tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "#adiciona apos x uma camada densa com 128 neuronios com funcao de ativacao relu. Atribui este no a x novamente\n",
    "x=tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "#adiciona apos x uma camada densa com 64 neuronios com funcao de ativacao relu. Atribui este no a x novamente\n",
    "x=tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "\n",
    "#adiciona apos x uma camada densa com 32 neuronios com funcao de ativacao relu. Atribui este no a x novamente\n",
    "x=tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "\n",
    "#adiciona após x os neurônios que devem ser utilizados, nesse caso foram desligados 20% dos neuronios\n",
    "x=tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "#adiciona apos x uma camada densa com 7 neuronios (sete classes) com funcao de ativacao softmax (distribuicao de probabilidade). Atribui este no a preds\n",
    "#preds=tf.keras.layers.Dense(3,activation='softmax')(x)\n",
    "preds=tf.keras.layers.Dense(3,activation='sigmoid')(x)\n",
    "\n",
    "#definindo modelo final\n",
    "model=tf.keras.models.Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "#mostrando modelo final e sua estrutura\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "golden-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "#congelando os neuronios já treinados na ImageNet, queremos retreinar somente a ultima camada\n",
    "for l in model.layers:\n",
    "    if l.name.split('_')[0] != 'dense':\n",
    "        l.trainable=False\n",
    "    else:\n",
    "        l.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "marine-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iniciando objeto que apanhara todas as imagens de treino, processando as imagens com o metodo da ResNet50V2\n",
    "train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input) #included in our dependencies\n",
    "\n",
    "#iniciando objeto que apanhara todas as imagens de teste, processando as imagens com o metodo da ResNet50V2\n",
    "test_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "studied-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#CARREGANDO PRÓPRIO DATASET PARA USO\n",
    "# target_size=(224, 224)\n",
    "\n",
    "#definindo gerador de imagens de treino\n",
    "train_generator = train_data_gen.flow_from_directory('shapes_split/train',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "#definindo gerador de imagens de teste\n",
    "test_generator = test_data_gen.flow_from_directory('shapes_split/test',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "individual-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.optimizers.Adam(learning_rate=0.001) #estabelecendo taxa de otimização\n",
    "\n",
    "model.compile(optimizer=lr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instrumental-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicao dos steps\n",
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_test = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "about-bride",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vinicius\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 12s 1s/step - loss: 0.9452 - accuracy: 0.5145 - val_loss: 0.2771 - val_accuracy: 0.9688\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.3169 - accuracy: 0.8931 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0932 - accuracy: 0.9743 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0757 - accuracy: 0.9791 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0429 - accuracy: 0.9938 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0631 - accuracy: 0.9706 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0344 - accuracy: 0.9820 - val_loss: 0.0259 - val_accuracy: 0.9688\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0176 - accuracy: 0.9960 - val_loss: 7.6443e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0402 - accuracy: 0.9838 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0314 - accuracy: 0.9906 - val_loss: 1.9902e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0233 - accuracy: 0.9952 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0267 - accuracy: 0.9841 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0325 - accuracy: 0.9875 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 6.5938e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0162 - accuracy: 0.9914 - val_loss: 2.6811e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0114 - accuracy: 0.9931 - val_loss: 4.0806e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 8.7726e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0073 - accuracy: 0.9964 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0156 - accuracy: 0.9892 - val_loss: 1.6933e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0085 - accuracy: 0.9942 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0115 - accuracy: 0.9945 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0171 - accuracy: 0.9895 - val_loss: 5.8045e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 0.9981 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0049 - accuracy: 0.9972 - val_loss: 6.8391e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7397e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0092 - accuracy: 0.9961 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0215 - accuracy: 0.9852 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0203 - accuracy: 0.9825 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 3.9115e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0067 - accuracy: 0.9951 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0036 - accuracy: 0.9981 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 0.9981 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0135 - accuracy: 0.9919 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0114 - accuracy: 0.9948 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.6728e-04 - accuracy: 1.0000 - val_loss: 8.2307e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0066 - accuracy: 0.9961 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 0.9972 - val_loss: 6.7055e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0080 - accuracy: 0.9962 - val_loss: 2.1431e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0142 - accuracy: 0.9887 - val_loss: 6.1477e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0301 - accuracy: 0.9717 - val_loss: 1.5048e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0136 - accuracy: 0.9877 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0147 - accuracy: 0.9862 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0034 - accuracy: 0.9981 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0106 - accuracy: 0.9905 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0261 - accuracy: 0.9856 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.2430e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0035 - accuracy: 0.9981 - val_loss: 7.9889e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 9.7084e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.3388e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 3.3689e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0076 - accuracy: 0.9933 - val_loss: 3.9452e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0117 - accuracy: 0.9893 - val_loss: 4.9384e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0089 - accuracy: 0.9962 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0216 - accuracy: 0.9880 - val_loss: 0.0321 - val_accuracy: 0.9688\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0139 - accuracy: 0.9887 - val_loss: 0.0226 - val_accuracy: 0.9688\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.5670e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1322e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.4771e-04 - accuracy: 1.0000 - val_loss: 2.1417e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0042 - accuracy: 0.9965 - val_loss: 8.9153e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.7961e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0035 - accuracy: 0.9972 - val_loss: 1.3826e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3236e-04 - accuracy: 1.0000 - val_loss: 4.9135e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0129 - accuracy: 0.9891 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0078 - accuracy: 0.9931 - val_loss: 1.6665e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.2583e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.0504e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0025 - accuracy: 0.9981 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0042 - accuracy: 0.9975 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 1.6765e-04 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0260 - accuracy: 0.9774 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.6340e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.6200e-04 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0027 - accuracy: 0.9974 - val_loss: 3.8056e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 4.9173e-07 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 0.9969 - val_loss: 1.4901e-07 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.5090e-06 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.6917e-04 - accuracy: 1.0000 - val_loss: 4.0343e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 0.9981 - val_loss: 4.0323e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5185e-04 - accuracy: 1.0000 - val_loss: 8.6363e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0165 - accuracy: 0.9873 - val_loss: 1.2011e-04 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0094 - accuracy: 0.9909 - val_loss: 1.4183e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.0218e-04 - accuracy: 1.0000 - val_loss: 4.9691e-06 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 1.6396e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0125 - accuracy: 0.9892 - val_loss: 1.6391e-07 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 8.5285e-05 - accuracy: 1.0000 - val_loss: 8.5336e-06 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0105 - accuracy: 0.9913 - val_loss: 8.5150e-06 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0049 - accuracy: 0.9950 - val_loss: 2.7940e-07 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0060 - accuracy: 0.9952 - val_loss: 2.8685e-07 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0500e-04 - accuracy: 1.0000 - val_loss: 9.1294e-06 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0076 - accuracy: 0.9931 - val_loss: 8.9136e-06 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0081 - accuracy: 0.9931 - val_loss: 8.9510e-06 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0043 - accuracy: 0.9961 - val_loss: 1.5907e-06 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0197 - accuracy: 0.9892 - val_loss: 9.6587e-06 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.5483e-04 - accuracy: 1.0000 - val_loss: 3.3191e-06 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0393e-04 - accuracy: 1.0000 - val_loss: 1.3763e-05 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.5222e-06 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 9.8354e-04 - accuracy: 1.0000 - val_loss: 1.0291e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0731e-05 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0044 - accuracy: 0.9961 - val_loss: 1.0846e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 1.8162e-05 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 9.5353e-06 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0079 - accuracy: 0.9931 - val_loss: 8.4478e-06 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 1.1032e-05 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0082 - accuracy: 0.9893 - val_loss: 1.1052e-05 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.4215e-04 - accuracy: 1.0000 - val_loss: 2.3059e-06 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0097 - accuracy: 0.9938 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 1.2806e-04 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1404 - accuracy: 0.9823 - val_loss: 0.0815 - val_accuracy: 0.9688\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.1854 - accuracy: 0.9796 - val_loss: 0.1623 - val_accuracy: 0.9688\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0165 - accuracy: 0.9879 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0309 - accuracy: 0.9751 - val_loss: 0.1052 - val_accuracy: 0.9688\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0076 - accuracy: 0.9931 - val_loss: 0.0677 - val_accuracy: 0.9688\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0117 - accuracy: 0.9919 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 7.4093e-04 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 4.4998e-06 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 4.6907e-05 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0128 - accuracy: 0.9931 - val_loss: 2.7195e-07 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0064 - accuracy: 0.9962 - val_loss: 2.2352e-07 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0134 - accuracy: 0.9881 - val_loss: 5.1568e-04 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.3874e-05 - accuracy: 1.0000 - val_loss: 2.4622e-04 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0042 - accuracy: 0.9964 - val_loss: 1.0588e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0150 - accuracy: 0.9858 - val_loss: 7.6480e-05 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.0186e-05 - accuracy: 1.0000 - val_loss: 6.9532e-05 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0093 - accuracy: 0.9988 - val_loss: 7.3554e-05 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0283 - accuracy: 0.9919 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7676e-04 - accuracy: 1.0000 - val_loss: 9.3640e-06 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 9.3565e-06 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1960e-04 - accuracy: 1.0000 - val_loss: 8.8798e-06 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.6730e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0161 - accuracy: 0.9899 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 9.3295e-04 - accuracy: 1.0000 - val_loss: 4.1013e-06 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0034 - accuracy: 0.9964 - val_loss: 2.4186e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0106 - accuracy: 0.9892 - val_loss: 7.1773e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.1808e-04 - accuracy: 1.0000 - val_loss: 6.7383e-06 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0022 - accuracy: 0.9972 - val_loss: 6.5000e-06 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0173e-04 - accuracy: 1.0000 - val_loss: 6.3510e-06 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.8160e-04 - accuracy: 1.0000 - val_loss: 6.1834e-06 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.2181e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0058 - accuracy: 0.9931 - val_loss: 4.8030e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0161 - accuracy: 0.9880 - val_loss: 4.9378e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0888e-04 - accuracy: 1.0000 - val_loss: 2.0352e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.1877e-05 - accuracy: 1.0000 - val_loss: 4.1794e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 3.0183e-04 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1682e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0061 - accuracy: 0.9948 - val_loss: 7.1294e-06 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.2010e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0215 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 0.9948 - val_loss: 1.4090e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0063 - accuracy: 0.9930 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3368e-05 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0807e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0087 - accuracy: 0.9928 - val_loss: 1.1081e-05 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0046 - accuracy: 0.9952 - val_loss: 1.0206e-05 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.7044e-04 - accuracy: 1.0000 - val_loss: 9.7178e-06 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2737e-05 - accuracy: 1.0000 - val_loss: 9.8738e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0082 - accuracy: 0.9928 - val_loss: 4.2055e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 0.9973 - val_loss: 9.6143e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 9.1182e-06 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0055 - accuracy: 0.9928 - val_loss: 9.1107e-06 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 3.1637e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.0620e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0062 - accuracy: 0.9961 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0099 - accuracy: 0.9920 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4980e-04 - accuracy: 1.0000 - val_loss: 3.9206e-05 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0010 - accuracy: 0.9988 - val_loss: 7.2563e-04 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.3206e-04 - accuracy: 1.0000 - val_loss: 2.5973e-05 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0194 - accuracy: 0.9875 - val_loss: 2.0486e-05 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.4574e-04 - accuracy: 1.0000 - val_loss: 7.0890e-04 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.9451e-04 - accuracy: 1.0000 - val_loss: 5.9173e-04 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5879e-04 - accuracy: 1.0000 - val_loss: 1.4399e-05 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.8988e-04 - accuracy: 1.0000 - val_loss: 5.4757e-06 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 4.6443e-04 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0123 - accuracy: 0.9892 - val_loss: 1.8292e-05 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1748e-04 - accuracy: 1.0000 - val_loss: 5.1926e-06 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0125 - accuracy: 0.9880 - val_loss: 3.2893e-04 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.1802e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 4.2205e-06 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7074e-04 - accuracy: 1.0000 - val_loss: 6.8169e-06 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3579e-04 - accuracy: 1.0000 - val_loss: 2.1768e-04 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0033 - accuracy: 0.9961 - val_loss: 1.9130e-04 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.8880e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.6166e-04 - accuracy: 1.0000 - val_loss: 1.1374e-04 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4064e-06 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.1035e-04 - accuracy: 1.0000 - val_loss: 2.0265e-06 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.4599e-04 - accuracy: 1.0000 - val_loss: 8.3614e-05 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 0.9981 - val_loss: 1.8589e-06 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0083 - accuracy: 0.9932 - val_loss: 7.2432e-05 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.2052e-04 - accuracy: 1.0000 - val_loss: 3.4719e-06 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0040 - accuracy: 0.9964 - val_loss: 4.2547e-05 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9168e-06 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0045 - accuracy: 0.9965 - val_loss: 2.4775e-05 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3578e-04 - accuracy: 1.0000 - val_loss: 4.6193e-07 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0176e-05 - accuracy: 1.0000 - val_loss: 1.6440e-05 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.0643e-04 - accuracy: 1.0000 - val_loss: 2.7567e-07 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0152 - accuracy: 0.9892 - val_loss: 1.1599e-05 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0292e-05 - accuracy: 1.0000 - val_loss: 1.0146e-05 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0048 - accuracy: 0.9962 - val_loss: 2.6486e-06 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6486e-06 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3336e-05 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0093 - accuracy: 0.9919 - val_loss: 2.4403e-05 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.5469e-06 - accuracy: 1.0000 - val_loss: 2.4361e-05 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 1.5758e-06 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6046e-04 - accuracy: 1.0000 - val_loss: 4.4331e-07 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0892e-04 - accuracy: 1.0000 - val_loss: 2.5612e-05 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 2.6230e-05 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.3211e-05 - accuracy: 1.0000 - val_loss: 1.1362e-06 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.7113e-04 - accuracy: 1.0000 - val_loss: 5.7741e-07 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0125 - accuracy: 0.9889 - val_loss: 3.0938e-05 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.7738e-06 - accuracy: 1.0000 - val_loss: 4.5448e-07 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0237e-05 - accuracy: 1.0000 - val_loss: 4.3586e-07 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 3.2070e-05 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.5862e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.2383e-05 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2304e-04 - accuracy: 1.0000 - val_loss: 3.1020e-05 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 7.7858e-07 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0053 - accuracy: 0.9931 - val_loss: 2.9245e-05 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.1584e-05 - accuracy: 1.0000 - val_loss: 2.8330e-05 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0037 - accuracy: 0.9962 - val_loss: 2.9271e-05 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5880e-04 - accuracy: 1.0000 - val_loss: 3.1359e-05 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0127 - accuracy: 0.9891 - val_loss: 2.4214e-07 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0033 - accuracy: 0.9971 - val_loss: 2.1979e-07 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0042 - accuracy: 0.9960 - val_loss: 2.1916e-05 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9581e-04 - accuracy: 1.0000 - val_loss: 3.9860e-07 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4450e-04 - accuracy: 1.0000 - val_loss: 2.1093e-05 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0513e-04 - accuracy: 1.0000 - val_loss: 5.3271e-07 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.3211e-06 - accuracy: 1.0000 - val_loss: 2.3334e-05 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0064 - accuracy: 0.9945 - val_loss: 2.4376e-05 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0307e-05 - accuracy: 1.0000 - val_loss: 2.5277e-05 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1293e-05 - accuracy: 1.0000 - val_loss: 2.6119e-05 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 0.9981 - val_loss: 4.8056e-07 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0036 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.9623e-04 - accuracy: 1.0000 - val_loss: 5.0291e-07 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3648e-05 - accuracy: 1.0000 - val_loss: 2.8947e-05 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6077e-05 - accuracy: 1.0000 - val_loss: 2.9152e-05 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0067 - accuracy: 0.9945 - val_loss: 4.0978e-07 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.9336e-05 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.0239e-06 - accuracy: 1.0000 - val_loss: 1.6078e-05 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0501e-06 - accuracy: 1.0000 - val_loss: 1.4700e-05 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.5419e-05 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.1862e-05 - accuracy: 1.0000 - val_loss: 1.6845e-05 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0022 - accuracy: 0.9972 - val_loss: 1.6983e-05 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6171e-05 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.5957e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.2107e-05 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 4.5695e-04 - accuracy: 1.0000 - val_loss: 3.9240e-05 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.3013e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3179e-04 - accuracy: 1.0000 - val_loss: 2.5050e-05 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0092 - accuracy: 0.9893 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6214e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.4427e-04 - accuracy: 1.0000 - val_loss: 1.6153e-05 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5565e-06 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0183 - accuracy: 0.9853 - val_loss: 9.4124e-06 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.2645e-05 - accuracy: 1.0000 - val_loss: 7.8296e-06 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0028 - accuracy: 0.9972 - val_loss: 6.6489e-06 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1487e-04 - accuracy: 1.0000 - val_loss: 5.7588e-06 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 4.9319e-06 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0212 - accuracy: 0.9866 - val_loss: 4.2428e-06 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 4.4402e-06 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.7656e-04 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.5500e-06 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1909e-06 - accuracy: 1.0000 - val_loss: 9.6857e-08 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.4682e-07 - accuracy: 1.0000 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.7950e-07 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.0241e-04 - accuracy: 1.0000 - val_loss: 2.6337e-06 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3110e-04 - accuracy: 1.0000 - val_loss: 2.3506e-06 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7856e-05 - accuracy: 1.0000 - val_loss: 2.2202e-06 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0110 - accuracy: 0.9948 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.5508e-06 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 2.1904e-06 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.0312e-05 - accuracy: 1.0000 - val_loss: 2.5629e-06 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1198e-05 - accuracy: 1.0000 - val_loss: 1.5720e-06 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1578e-06 - accuracy: 1.0000 - val_loss: 1.3783e-06 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.6616e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.0542e-06 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 9.2013e-07 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.9314e-06 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2781e-07 - accuracy: 1.0000 - val_loss: 1.0431e-06 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.4178e-06 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4440e-05 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.9111e-04 - accuracy: 1.0000 - val_loss: 7.0780e-08 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9226e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0099 - accuracy: 0.9887 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0031 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0153 - accuracy: 0.9879 - val_loss: 1.1548e-07 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.2619e-04 - accuracy: 1.0000 - val_loss: 6.8128e-06 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.6843e-06 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.3152e-04 - accuracy: 1.0000 - val_loss: 8.5595e-06 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 9.6060e-06 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0072 - accuracy: 0.9950 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7955e-06 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0098 - accuracy: 0.9961 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0091 - accuracy: 0.9901 - val_loss: 1.1809e-06 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2420e-06 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.8090e-04 - accuracy: 1.0000 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 6.8545e-07 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.3710e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.5949e-06 - accuracy: 1.0000 - val_loss: 2.0404e-05 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.2486e-05 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0043 - accuracy: 0.9974 - val_loss: 4.1484e-05 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.9404e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.5366e-07 - accuracy: 1.0000 - val_loss: 4.6748e-05 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0448e-04 - accuracy: 1.0000 - val_loss: 4.6349e-05 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 2.0013e-05 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0652e-06 - accuracy: 1.0000 - val_loss: 1.8744e-05 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.8576e-04 - accuracy: 1.0000 - val_loss: 2.7611e-05 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0088 - accuracy: 0.9930 - val_loss: 2.1979e-07 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 4.7320e-05 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0152 - accuracy: 0.9907 - val_loss: 5.6428e-05 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.4184e-04 - accuracy: 1.0000 - val_loss: 5.6280e-05 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.2004e-04 - accuracy: 1.0000 - val_loss: 5.0448e-05 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.1101e-08 - accuracy: 1.0000 - val_loss: 4.4132e-05 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.3021e-04 - accuracy: 1.0000 - val_loss: 2.4214e-07 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0221 - accuracy: 0.9826 - val_loss: 2.1234e-07 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3875e-05 - accuracy: 1.0000 - val_loss: 1.9371e-07 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.3507e-06 - accuracy: 1.0000 - val_loss: 2.3167e-05 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8160e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 9.8551e-06 - accuracy: 1.0000 - val_loss: 2.1852e-05 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6852e-05 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.1052e-04 - accuracy: 1.0000 - val_loss: 1.5996e-05 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0034 - accuracy: 0.9963 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 0.9972 - val_loss: 2.2977e-05 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 2.5396e-05 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4623e-06 - accuracy: 1.0000 - val_loss: 1.5274e-07 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3248e-05 - accuracy: 1.0000 - val_loss: 1.4529e-07 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8260e-05 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.6857e-08 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5994e-06 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0041 - accuracy: 0.9965 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.7883e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.3558e-05 - accuracy: 1.0000 - val_loss: 2.0099e-05 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0027 - accuracy: 0.9965 - val_loss: 1.6808e-05 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6671e-07 - accuracy: 1.0000 - val_loss: 1.3725e-05 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.4467e-05 - accuracy: 1.0000 - val_loss: 1.2797e-05 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0130 - accuracy: 0.9892 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.8110e-04 - accuracy: 1.0000 - val_loss: 1.2470e-05 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.2488e-05 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2255e-06 - accuracy: 1.0000 - val_loss: 1.2291e-05 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.7753e-06 - accuracy: 1.0000 - val_loss: 1.2347e-05 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 9.6857e-08 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3675e-06 - accuracy: 1.0000 - val_loss: 1.1278e-05 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 0.9961 - val_loss: 1.0265e-05 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0034 - accuracy: 0.9972 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9803e-06 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1718e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1745e-04 - accuracy: 1.0000 - val_loss: 8.9990e-06 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.1683e-04 - accuracy: 1.0000 - val_loss: 9.2969e-06 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 9.6806e-06 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.8174e-05 - accuracy: 1.0000 - val_loss: 9.9673e-06 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.6662e-05 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.7312e-10 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0150e-05 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3791e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.7065e-04 - accuracy: 1.0000 - val_loss: 1.0131e-05 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.1773e-05 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.2250e-05 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.2027e-05 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4221e-06 - accuracy: 1.0000 - val_loss: 1.1844e-05 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.0117e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.8871e-07 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0113 - accuracy: 0.9945 - val_loss: 1.4529e-07 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7156e-04 - accuracy: 1.0000 - val_loss: 2.0862e-07 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0115 - accuracy: 0.9901 - val_loss: 2.4214e-07 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3983e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.0692e-07 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.9556e-06 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2338e-05 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0052 - accuracy: 0.9962 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0558e-07 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0048 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.3641e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0088 - accuracy: 0.9930 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.6012e-06 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.6750e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.7509e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0062 - accuracy: 0.9949 - val_loss: 5.6210e-04 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.3260e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0918e-04 - accuracy: 1.0000 - val_loss: 5.1866e-04 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0026 - accuracy: 0.9964 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5190e-05 - accuracy: 1.0000 - val_loss: 6.3424e-04 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.0489e-04 - accuracy: 1.0000 - val_loss: 4.6536e-04 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.1659e-06 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 0.9988 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.1123e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0229 - accuracy: 0.9892 - val_loss: 3.4803e-04 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 0.9931 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.8345e-06 - accuracy: 1.0000 - val_loss: 3.4804e-04 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.6443e-04 - accuracy: 1.0000 - val_loss: 3.3922e-04 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.2828e-04 - accuracy: 1.0000 - val_loss: 3.0806e-04 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4382e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 0.9973 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0085 - accuracy: 0.9931 - val_loss: 1.6666e-04 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.3122e-05 - accuracy: 1.0000 - val_loss: 1.4495e-04 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.1474e-06 - accuracy: 1.0000 - val_loss: 1.2439e-04 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0046 - accuracy: 0.9964 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1690e-06 - accuracy: 1.0000 - val_loss: 6.8887e-05 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.5696e-09 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.7322e-06 - accuracy: 1.0000 - val_loss: 5.9801e-05 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0127 - accuracy: 0.9866 - val_loss: 6.6251e-05 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 1s/step - loss: 1.5316e-05 - accuracy: 1.0000 - val_loss: 6.9649e-05 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8341e-06 - accuracy: 1.0000 - val_loss: 7.1485e-05 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.1438e-06 - accuracy: 1.0000 - val_loss: 2.4027e-06 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.1686e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.1829e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0094 - accuracy: 0.9930 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.7169e-06 - accuracy: 1.0000 - val_loss: 4.2726e-06 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0094 - accuracy: 0.9925 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4952e-04 - accuracy: 1.0000 - val_loss: 6.5931e-06 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.6742e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0089 - accuracy: 0.9928 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.8018e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0105 - accuracy: 0.9919 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2179e-06 - accuracy: 1.0000 - val_loss: 9.0958e-06 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.6692e-06 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.3247e-04 - accuracy: 1.0000 - val_loss: 5.2299e-06 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0055 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.2281e-07 - accuracy: 1.0000 - val_loss: 1.6018e-06 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0148 - accuracy: 0.9880 - val_loss: 1.5311e-06 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5032e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0112 - accuracy: 0.9891 - val_loss: 1.1064e-06 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1196e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 8.4935e-07 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 0.9972 - val_loss: 8.3818e-07 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5492e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.6375e-07 - accuracy: 1.0000 - val_loss: 9.4621e-07 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.5318e-06 - accuracy: 1.0000 - val_loss: 9.6484e-07 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.2957e-07 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0101 - accuracy: 0.9919 - val_loss: 2.3097e-07 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0077 - accuracy: 0.9892 - val_loss: 1.6764e-07 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0023 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.1295e-04 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2905e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0065e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7136e-07 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1639e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4398e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0120 - accuracy: 0.9901 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.7273e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6696e-06 - accuracy: 1.0000 - val_loss: 2.7567e-07 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1979e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#treinando e testando o modelo\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_generator,\n",
    "                   validation_steps=step_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "quality-denver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vinicius\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 1.000\n"
     ]
    }
   ],
   "source": [
    "#Avaliando o modelo\n",
    "loss_train, train_acc = model.evaluate_generator(train_generator, steps=step_size_train)\n",
    "loss_test, test_acc = model.evaluate_generator(test_generator, steps=step_size_test)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "northern-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Apresentando resultados em graficos\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "industrial-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando graficos para visualização dos resultados\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "upper-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando classificações..\n",
      "Rótulos ['circles', 'squares', 'triangles']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vinicius\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds Created\n",
      "Preds 1D created\n"
     ]
    }
   ],
   "source": [
    "print('Criando classificações..')\n",
    "labels = os.listdir('shapes_split/test')\n",
    "print('Rótulos', labels)\n",
    "#criando estruturas para métricas de avaliação, processo um pouco mais demorado\n",
    "Y_pred = model.predict_generator(test_generator)\n",
    "print('Preds Created')\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Preds 1D created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beneficial-fluid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------CLASSIFICATION--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     circles       0.30      0.30      0.30        20\n",
      "     squares       0.45      0.45      0.45        20\n",
      "   triangles       0.40      0.40      0.40        20\n",
      "\n",
      "    accuracy                           0.38        60\n",
      "   macro avg       0.38      0.38      0.38        60\n",
      "weighted avg       0.38      0.38      0.38        60\n",
      "\n",
      "----------------MATRIX--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification = classification_report(test_generator.classes, y_pred, target_names=labels)\n",
    "print('----------------CLASSIFICATION--------------')\n",
    "print(classification)\n",
    "matrix = confusion_matrix(test_generator.classes, y_pred)\n",
    "df_cm = pd.DataFrame(matrix, index = [i for i in range(3)],\n",
    "                  columns = [i for i in range(3)])\n",
    "plt.figure(figsize = (10,7))\n",
    "print('----------------MATRIX--------------')\n",
    "sn.heatmap(df_cm, annot=True, linewidths=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-raising",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
