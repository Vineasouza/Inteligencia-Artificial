{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f876f84",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <h1 align=\"center\">Trabalho de Deep Learning</h1>\n",
    "  <div align=\"center\">Lucas de Almeida, RA: 1996762</div>\n",
    "  <div align=\"center\">Vinícius Augusto de Souza, RA: 1997530</div>\n",
    "  <hr/>\n",
    "  <div align=\"center\">Uma abordagem dos conceitos de redes neurais convolucionais pré treinadas utilizando o método de <i>transfer learning</i>.\n",
    "</div>\n",
    "  <div align=\"center\">A base de dados a ser utilizada será a <i>Basic Shapes</i>, que pode ser encontrada <a href=\"https://www.kaggle.com/cactus3/basicshapes\">neste link</a>. Ela é bem simples e objetiva, contendo um acervo de 300 imagens: 100 imagens de cada forma geométrica (circulos, quadrados e triangulos) desenhados manualmente por <a href=\"https://www.kaggle.com/cactus3\">Mark S.</a></div>\n",
    "</div>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-naples",
   "metadata": {},
   "source": [
    "<h3>Considerações sobre o trabalho:</h3>\n",
    "<hr/>\n",
    "<p>Para o desenvolvimento deste trabalho, foi escolhido o modelo pré-treinado da literatura <i><a href=\"https://keras.io/api/applications/inceptionresnetv2/\">InceptionResNetV2</a></i>, considerando os pesos também pré treinados da <i>ImageNet</i>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "premier-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900cd2fe",
   "metadata": {},
   "source": [
    "<h3>Separação dos arquivos:</h3>\n",
    "<hr>\n",
    "<div>Antes de começar a tratar os dados, é necessário realizar a divisão do dataset em 80% para treino e 20% para testes.</div>\n",
    "<div>O código a seguir realiza essa tarefa, passando como variáveis:</div>\n",
    "<ul>\n",
    "    <li><i>data_dir</i>: o nome do caminho do diretório do dataset escolhido;</li>\n",
    "    <li><i>classes</i>: as classes das quais os arquivos pertencem (circulos, quadrados e triângulos);</li>\n",
    "    <li><i>output_dir</i>: o nome do caminho do diretório de saída, após separação;</li>\n",
    "    <li><i>ratio</i>: a taxa de divisão dos arquivos (i.e. 80% treino e 20% testes);</li>\n",
    "</ul>\n",
    "<p>Em seguida são carregadas essas variávies e todas as imagens <i>.png</i> são selecionadas e armazenadas na variável <i>file</i>.</p>\n",
    "<p>Em seguida, é escolhida uma <i>seed</i> arbitrária para embaralhar as imagens de forma que seja possível reproduzir essa mesma divisão posteriormente. Os arquivos então são embaralhados e divididos conforme os parâmetros passados anteriormente.</p>\n",
    "<p>Por fim, os arquivos divididos são enviados cada um para seu respectivo diretório, treino ou teste, e sempre divididos em pastas referentes à sua classe, conforme a estrutura a seguir:</p>\n",
    "<ul>\n",
    "    <li><i>test</i> <span  style=\"color:lightgrey\">(80% do dataset)</span></li>\n",
    "    <ul>\n",
    "        <li><i>circles</i></li>\n",
    "        <li><i>triangles</i></li>\n",
    "        <li><i>squares</i></li>\n",
    "    </ul>\n",
    "    <li><i>train</i> <span  style=\"color:lightgrey\">(20% do dataset)</span></li>\n",
    "    <ul>\n",
    "        <li><i>circles</i></li>\n",
    "        <li><i>triangles</i></li>\n",
    "        <li><i>squares</i></li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9a4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"shapes\"\n",
    "classes = [\"circles\", \"squares\", \"triangles\"]\n",
    "output_dir = \"shapes_split\"\n",
    "ratio = [0.8, 0.2]\n",
    "\n",
    "def split(data_dir, output_dir, ratio):\n",
    "    for cell in classes:\n",
    "        cell_path = os.path.join(data_dir, cell)\n",
    "        files = os.listdir(cell_path)\n",
    "        files = [os.path.join(cell_path, f) for f in files if f.endswith('.png')]\n",
    "\n",
    "        random.seed(230)\n",
    "        files.sort()\n",
    "        random.shuffle(files)\n",
    "\n",
    "        split_train = int(ratio[0] * len(files))\n",
    "        split_test = split_train\n",
    "\n",
    "        files_train = files[:split_train]\n",
    "        files_test = files[split_test:]\n",
    "        files_type = [(files_train, \"train\"), (files_test, \"test\")]\n",
    "\n",
    "        for (files, folder_type) in files_type:\n",
    "            full_path = os.path.join(output_dir, folder_type)\n",
    "            full_path = os.path.join(full_path, cell)\n",
    "            pathlib.Path(full_path).mkdir(parents=True, exist_ok=True)\n",
    "            for f in files:\n",
    "                shutil.copy2(f, full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72791dcc",
   "metadata": {},
   "source": [
    "<h3>Definição dos parâmetros do modelo:</h3>\n",
    "<hr>\n",
    "<div>Antes de prosseguir, é necessário compreender em quais parâmetros o modelo se baseia. Dois desses parâmetros terão de ser definidos neste momento, os quais são:</div>\n",
    "<ul>\n",
    "    <li><i>epochs</i>: quantas vezes o algoritmo de treino será executado;</li>\n",
    "    <li><i>batch size</i>: quantas amostras serão carregadas a cada uma dessas execuções.</li>\n",
    "</ul>\n",
    "<div>Para o treinamento, foi definido que seriam utilizadas 500 <i>epochs</i> e 32 como <i>batch size</i>.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pleased-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd69601",
   "metadata": {},
   "source": [
    "<h3>Carregamento do modelo \"<i>InceptionResNetV2</i>\":</h3>\n",
    "<hr>\n",
    "<div>Primeiramente o modelo escolhido é carregado juntamente com os pesos aprendidos durante o treino (sem a camada densa) para a variável <i>base_model</i>. Em seguida, a variável <i>x</i> recebe a saída do modelo carregado.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lined-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 42s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "built-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=base_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c065c",
   "metadata": {},
   "source": [
    "<h3>Configuração do modelo \"<i>InceptionResNetV2</i>\":</h3>\n",
    "<hr />\n",
    "<div>\n",
    "  Nesta etapa é necessário adicionar algumas camadas de nós. Para explicar o que\n",
    "  ocorre em cada uma das camadas, é preciso observá-las uma a uma, conforme\n",
    "  descrito abaixo:\n",
    "</div>\n",
    "<ul>\n",
    "  <li>\n",
    "    <i>camada GlobalMaxPooling</i>: Para reduzir a resolução, é utilizada uma\n",
    "    operação de <i>pooling</i> conhecida como “<i>pooling máximo</i>” (ou\n",
    "    <i>max pooling</i>). Nesta operação de agrupamento, um “bloco” com altura\n",
    "    'A' e largura 'L' desliza sobre os dados de entrada (conforme na figura\n",
    "    abaixo, de 'a' até 'd'). A cada iteração (ou seja, o quanto ela avança\n",
    "    durante a operação de deslizamento) é muitas vezes igual ao tamanho da\n",
    "    <i>pool</i>, de modo que seu efeito é igual a uma redução na altura e\n",
    "    largura. Para cada bloco, ou “pool”, a operação envolve simplesmente o\n",
    "    cálculo do valor máximo. Fazendo isso para cada pool, obtemos um resultado\n",
    "    bem reduzido, otimizando muito a quantidade de espaço de que precisamos.\n",
    "  </li>\n",
    "  <img src=\"max-pooling.png\" width=\"500\" />\n",
    "  <br /><br />\n",
    "  <li>\n",
    "    camada densa com função de ativação \"<i>ReLU</i>\": A função de ativação\n",
    "    linear retificada (ou <i>ReLU</i>) é uma função linear por partes que\n",
    "    produzirá a entrada diretamente se for positiva, caso contrário, ela\n",
    "    produzirá zero. Ela se comporta conforme o gráfico abaixo:\n",
    "    <br />\n",
    "    <img src=\"relu.jpg\" width=\"500\" />\n",
    "    Neste caso, foram adicionadas três camadas densas deste tipo, porém uma com\n",
    "    128 neurônios, outra com 64 neurônios e outra com 32 neurônios.\n",
    "    <br />\n",
    "  </li>\n",
    "  <li>\n",
    "    <i>camada dropout</i>: é feita uma espécide de \"regularização\", onde alguns\n",
    "    neurônios são desligados de forma aleatória, juntamente com suas conexões,\n",
    "    apenas durante o período de treinamento, porém durante a predição todos os\n",
    "    neurônios são mantidos ativos. O motivo de se fazer isso é evitar\n",
    "    <i>overfitting</i> no treinamento. A porcentagem escolhida nesse caso foi de\n",
    "    50%, conforme orientação no enunciado do projeto.\n",
    "  </li>\n",
    "  <li>\n",
    "    <i>camada de ativação</i>: utiliza uma função de ativação ao final das camadas anteriores. Essa função tenta aplicar um comportamento biologicamente análogo às excitações dos neurônios reais, isto é, replicar o comportamento de transmissão de informações dos neurônios, que só conseguem passar adiante a informação após sofrerem um estímulo. O que ocorre na prática é que a função insere um comportamento de \"não-linearidade\" após a função dos pesos com as entradas. Conforme enunciado, teria de ser feita uma escolha entre a função <i>sigmóide</i> e a função <i>softmax</i>. A escolha nesta situação é intuitiva, pois a função sigmóid é mais utilizada no aprendizado de funções lógicas, uma vez que ela tenta encaixar os valores entre 0 e 1. Já a função softmax produz uma distribuição de probabilidades para cada uma das classes das imagens durante a classificação, ao contrário da sigmóid que só consegue lidar com duas classes. Sendo assim, fica definido então que a função a ser utilizada é a <i>softmax</i> com 3 classes.\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<div>\n",
    "  Em seguida é feita a definição do modelo final bem como sua exibição, que pode\n",
    "  ser vista na sumário a seguir:\n",
    "</div>\n",
    "<span style=\"color: lightgrey\"\n",
    "  >Obs.: em virtude do tamanho do sumário, a linha de código que o exibe foi\n",
    "  comentada.</span\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "upper-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "preds=tf.keras.layers.Dense(3,activation='softmax')(x)\n",
    "\n",
    "model=tf.keras.models.Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2d0de",
   "metadata": {},
   "source": [
    "<h3>Treinamento e teste do modelo:</h3>\n",
    "<hr />\n",
    "<div>\n",
    "  Primeiramente, é feito o congelamento dos neurônios já treinados na\n",
    "  <i>ImageNet</i>, para retreinar somente as camadas densas incluídas no passo\n",
    "  anterior. Para fazer isso, é feita a mudança na variável booleana\n",
    "  \"<i>treinable</i>\" de cada camada que não inicia com o nome \"<i>dense</i>\"\n",
    "  para false.\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Em seguida são criados dois objetos:\n",
    "  <ul>\n",
    "    <li><i>train_data_gen</i>;</li>\n",
    "    <li><i>test_data_gen</i>.</li>\n",
    "  </ul>\n",
    "  Cada um desses objetos irá receber as imagens já processadas com o método da <i>ResNetV2</i>, separados em treino e teste conforme a nomenclatura da variável.\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Posteriormente, é necessário criar os geradores das imagens (tanto de teste quanto de treino). Isso é feito atravez dos objetos criados anteriormente, através da função \"<i>flow_from_directory</i>\". Seus parâmetros são os que seguem:\n",
    "  <ul>\n",
    "    <li><i>path</i>: o caminho do diretório onde estão localizadas as imagens;</li>\n",
    "    <li><i>target_size</i>: o tamanho da imagem (neste caso, foi escolhido o tamanho 128x128);</li>\n",
    "    <li><i>batch_size</i>: o mesmo explicado anteriormente, que já foi definido como 32;</li>\n",
    "    <li><i>class_mode</i>: pode ser \"input\", caso a imagem de entrada e saída forem as mesmas, \"binary\" se existirem apenas duas classes para realizar a predição ou \"categorical\", caso hajam mais classes, que é este caso;</li>\n",
    "    <li><i>shuffle</i>: <i>booleano</i> para ativar ou não o embaralhamento da ordem das imagens que seram utilizadas.</li>\n",
    "  </ul>\n",
    "  O resultado obtido são dois geradores como saída, armazenados nos objetos:\n",
    "  <ul>\n",
    "    <li><i>train_generator</i>;</li>\n",
    "    <li><i>test_generator</i>.</li>\n",
    "  </ul>\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Com os geradores criados, é preciso definir o otimizador. Conforme enunciado, os otimizadores que apresentam melhores resultados são o <i>SGD</i> e o <i>Adam</i>. Sendo assim, foi escolhido o <i>Adam</i>. Sendo assim, foi compilado o modelo com esses parâmetros, juntamente com a métrica escolhida como sendo por acurácia (<i>accuracy</i>), conforme orientação do enunciado.\n",
    "</div>\n",
    "</div>\n",
    "<br />\n",
    "<div>Por fim foram definidos os steps, e o modelo foi efetivamente treinado e testado. Os resultados podem ser vistos nos próximos tópicos.</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "therapeutic-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    if l.name.split('_')[0] != 'dense':\n",
    "        l.trainable=False\n",
    "    else:\n",
    "        l.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "british-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)\n",
    "\n",
    "test_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "black-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory('shapes_split/train',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "test_generator = test_data_gen.flow_from_directory('shapes_split/test',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expired-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
    "\n",
    "model.compile(optimizer=lr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "industrial-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_test = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "practical-crossing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0114 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.6136e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.0751e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.1903e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.4990e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9458e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.9482e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0080 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0052 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.8036e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0102 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 4.7800e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0052 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0115 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0038 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1209e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.9407e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0060 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.6879e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0045 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0108 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2925e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0234e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0053 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.7194e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1593e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0048 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.2213e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.0690e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.3616e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0052 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.4644e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.5016e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.0435e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0108 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.7312e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 6.5003e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.2497e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.4894e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0096 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.0114e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.7767e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.1522e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 1.4209e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 9.7597e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.7590e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0052 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.3358e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7797e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 1s/step - loss: 7.1214e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.5397e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.5094e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.5217e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.2201e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.4532e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0039 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.1223e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.7740e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0113 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.8086e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0092 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3539e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.9715e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.4817e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.1137e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0109 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0072 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.6680e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.9352e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0038 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.7424e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.9514e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0889e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.4248e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 1.6396e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3748e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0094 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0105 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 6s 928ms/step - loss: 3.0432e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 6s 1s/step - loss: 7.2518e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0050 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 7s 969ms/step - loss: 4.5498e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 6s 916ms/step - loss: 7.7327e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 7s 965ms/step - loss: 1.1339e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4617e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 7s 954ms/step - loss: 7.6840e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.6944e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.5347e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.0038 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 6s 912ms/step - loss: 0.0053 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.9598e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0112 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 7s 983ms/step - loss: 1.7758e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 7s 965ms/step - loss: 1.0258e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0061 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 985ms/step - loss: 2.5002e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 6s 921ms/step - loss: 4.8598e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 6s 930ms/step - loss: 9.3988e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "7/7 [==============================] - 6s 920ms/step - loss: 0.0039 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 6s 920ms/step - loss: 2.1426e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.3066e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 6s 901ms/step - loss: 2.6341e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2972e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.2601e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 7s 949ms/step - loss: 0.0088 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0092 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 7s 988ms/step - loss: 3.9272e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 6s 908ms/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 6s 871ms/step - loss: 4.3283e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2371e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 6s 884ms/step - loss: 4.3557e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 6s 931ms/step - loss: 6.6365e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 7s 976ms/step - loss: 6.0773e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 7s 985ms/step - loss: 1.2424e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 7s 943ms/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 6s 903ms/step - loss: 1.2172e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 7s 933ms/step - loss: 1.5299e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 6s 955ms/step - loss: 1.7375e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 6s 908ms/step - loss: 0.0110 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 6s 992ms/step - loss: 1.2021e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 6s 887ms/step - loss: 0.0053 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 6s 898ms/step - loss: 0.0108 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 6s 881ms/step - loss: 0.0105 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6879e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 7s 986ms/step - loss: 1.6047e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.8626e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.7312e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0089 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.7259e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 7s 1000ms/step - loss: 9.6799e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 6s 899ms/step - loss: 3.3730e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 7s 959ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 6s 900ms/step - loss: 1.9543e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 6s 973ms/step - loss: 2.6364e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 1.5203e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2090e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.0052 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 6s 935ms/step - loss: 1.6155e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 7s 976ms/step - loss: 0.0051 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.9065e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1018e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 7s 919ms/step - loss: 1.3508e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 6s 928ms/step - loss: 2.4587e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 7s 982ms/step - loss: 2.6134e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 995ms/step - loss: 0.0055 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.8356e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 7s 973ms/step - loss: 8.9118e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 7s 964ms/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 7s 975ms/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 3.5533e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.6634e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 7s 996ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.6745e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.4406e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2859e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.8081e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2574e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 7s 973ms/step - loss: 7.8168e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2122e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.5507e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 7s 964ms/step - loss: 1.7766e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 7s 979ms/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 7s 999ms/step - loss: 7.9317e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 7s 969ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6660e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5920e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.7853e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.8734e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 7s 986ms/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.7706e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1657e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 7s 974ms/step - loss: 1.1462e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 7s 958ms/step - loss: 1.9085e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0103 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 7s 968ms/step - loss: 0.0098 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.0632e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 7s 975ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.7311e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 7s 985ms/step - loss: 0.0083 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.9601e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5646e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.2880e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0042 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.8314e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.0847e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0039 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1727e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.5676e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0092 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.7539e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.8775e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0212e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.9486e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0057 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3334e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.3835e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0102 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.8083e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.4414e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.0148e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 7s 999ms/step - loss: 3.7863e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.8741e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2925e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1472e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0168 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0057 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.7824e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.3300e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.8901e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.3479e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.6620e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1434e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.7312e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.9900e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.0132e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3048e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0059e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2925e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0051 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 7s 981ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2925e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4087e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1877e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2925e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3640e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 1.5747e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.3464e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0055 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6026e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.1581e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.3814e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 7s 971ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0039 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.3529e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0035 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 7s 975ms/step - loss: 0.0110 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - 7s 981ms/step - loss: 1.1716e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 1.2489e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 7s 960ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "7/7 [==============================] - 7s 951ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.5710e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.9061e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0366e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.0375e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0113 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 2.4759e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.8899e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1462e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0035 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 7s 985ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 5.2037e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.6147e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.7051e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.3429e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 7s 1000ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.3283e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0034 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.0399e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 8.4360e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 7s 967ms/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.3670e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0889e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.4416e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9256e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0114 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0055 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0862e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.9372e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0115 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0037 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "7/7 [==============================] - 7s 988ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.4604e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.7566e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.7550e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0114 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 2.6707e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.4444e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4297e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0056 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 0.0045 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.8231e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.5807e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1205e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.5504e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 6.8789e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7767e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.9773e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.6392e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.6477e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 7s 967ms/step - loss: 1.7093e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.6195e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3547e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.8256e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.3102e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.7380e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.1699e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.7767e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.9515e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0053 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 7s 953ms/step - loss: 9.7431e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.5675e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.4387e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.7312e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0889e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2820e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 6s 937ms/step - loss: 1.2310e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 7s 965ms/step - loss: 2.3052e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 7s 955ms/step - loss: 1.5360e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0054 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0054 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.3557e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5896e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.8751e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 7s 958ms/step - loss: 7.7594e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.4644e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 7s 966ms/step - loss: 1.1462e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2572e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 7s 948ms/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3346e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 6s 934ms/step - loss: 1.6946e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.4808e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.1546e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 6s 948ms/step - loss: 2.8656e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 1s/step - loss: 6.7999e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 6s 934ms/step - loss: 0.0102 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 7s 941ms/step - loss: 2.6280e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "7/7 [==============================] - 7s 945ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 6s 941ms/step - loss: 1.1462e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "7/7 [==============================] - 7s 943ms/step - loss: 0.0042 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.4762e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "7/7 [==============================] - 7s 947ms/step - loss: 0.0102 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 7s 945ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 7s 958ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 7s 936ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 7s 940ms/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 7s 950ms/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 6s 945ms/step - loss: 0.0102 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 7s 947ms/step - loss: 4.2984e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 7s 952ms/step - loss: 8.9407e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 7s 938ms/step - loss: 1.1061e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 6s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 6s 946ms/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 6s 930ms/step - loss: 1.2119e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 6s 939ms/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 7s 966ms/step - loss: 3.9773e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 7s 937ms/step - loss: 0.0063 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 7s 977ms/step - loss: 0.0117 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 7s 962ms/step - loss: 5.1008e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 7s 945ms/step - loss: 0.0087 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 7s 935ms/step - loss: 1.6287e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 7s 937ms/step - loss: 2.5733e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 7s 964ms/step - loss: 3.2372e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 7s 970ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 7s 948ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 6s 938ms/step - loss: 1.3041e-04 - accuracy: 1.0000 - val_loss: 2.0065e-05 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 6s 941ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 4.4030e-06 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 6s 932ms/step - loss: 1.2067e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 7s 943ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 7s 951ms/step - loss: 8.6411e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4281e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 6s 946ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 6s 931ms/step - loss: 1.7235e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 7s 936ms/step - loss: 0.0079 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 7s 943ms/step - loss: 0.0092 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "7/7 [==============================] - 6s 926ms/step - loss: 6.3577e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.5496e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.8223e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.8914e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0055 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 7s 958ms/step - loss: 1.0889e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0037 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 6s 940ms/step - loss: 5.4138e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.0920e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 6s 930ms/step - loss: 0.0060 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 7s 971ms/step - loss: 5.8155e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 960ms/step - loss: 2.6126e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.8600e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.2377e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0054 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.2793e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.7279e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3296e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.3525e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3220e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3991e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0867e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.7690e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.3483e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0977e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.0649e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.6764e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0034 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0054 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.4816e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0118e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.6507e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3218e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 2.5603e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.5967e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.7431e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0039 - accuracy: 0.9955 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.5707e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0315 - accuracy: 0.9952 - val_loss: 0.6480 - val_accuracy: 0.9688\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.1457 - accuracy: 0.9856 - val_loss: 0.2141 - val_accuracy: 0.9688\n",
      "Epoch 489/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0087 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2531 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.3397 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2214 - accuracy: 0.9955 - val_loss: 0.3730 - val_accuracy: 0.9375\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.3703 - accuracy: 0.9663 - val_loss: 1.2777e-06 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.1885e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.9688\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.9688\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.9688\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1356 - val_accuracy: 0.9688\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0059 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.3786e-04 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit_generator(generator=train_generator,\n",
    "#                    steps_per_epoch=step_size_train,\n",
    "#                    epochs=epochs,\n",
    "#                    validation_data=test_generator,\n",
    "#                    validation_steps=step_size_test)\n",
    "history = model.fit(train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_generator,\n",
    "                   validation_steps=step_size_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9187df",
   "metadata": {},
   "source": [
    "<h3>Resultados:</h3>\n",
    "<hr />\n",
    "<div>\n",
    "  Primeiramente, é feito o cálculo da acurácia do treino e do teste, que podem\n",
    "  ser vistas abaixo.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "therapeutic-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 963ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Acurácia de treino: 1.000 \n",
      "Acurácia de teste: 1.000 \n"
     ]
    }
   ],
   "source": [
    "loss_train, train_acc = model.evaluate(train_generator, steps=step_size_train)\n",
    "loss_test, test_acc = model.evaluate_generator(test_generator, steps=step_size_test)\n",
    "print('Acurácia de treino: %.3f ' % (train_acc))\n",
    "print('Acurácia de teste: %.3f ' % (test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79578af2",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "  Observando os números acima para a acurácia, podemos ver que o resultado foi um número muito atípico, no caso <i>1.000</i>, que representa 100% de acurácia no treino e no teste. Quando isso acontece, geralmente se dá o nome de <i>overfit</i> (ou <i>overfitting</i>), que é quando um modelo estatístico se ajusta bem demais ao conjunto de dados observado, mas se mostra ineficaz para prever novos resultados. Os gráficos abaixo ilustram bem esse comportamento:\n",
    "<img src=\"https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png\" width=\"700\"/>\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  O gráfico seguinte apresenta a taxa de perda de treino e de teste:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "contained-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Perda')\n",
    "plt.plot(history.history['loss'], label='treino')\n",
    "plt.plot(history.history['val_loss'], label='teste')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db897441",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "  O gráfico seguinte apresenta a acurácia de treino e de teste:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "assured-flesh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Acurácia')\n",
    "plt.plot(history.history['accuracy'], label='treino')\n",
    "plt.plot(history.history['val_accuracy'], label='teste')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff75ca",
   "metadata": {},
   "source": [
    "<div>\n",
    "  Por fim, são feitas as classificações finais, onde são criadas as estruturas para as métricas de avaliação. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "forty-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando classificações..\n",
      "Rótulos ['circles', 'squares', 'triangles']\n",
      "Preds Created\n",
      "Preds 1D created\n"
     ]
    }
   ],
   "source": [
    "labels = os.listdir('shapes_split/test')\n",
    "print('Rótulos', labels)\n",
    "#criando estruturas para métricas de avaliação, processo um pouco mais demorado\n",
    "Y_pred = model.predict(test_generator)\n",
    "print('Preds Created')\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Preds 1D created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4612397e",
   "metadata": {},
   "source": [
    "Podemos observar as classificações finais, divididas em:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nuclear-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------CLASSIFICATION--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     circles       0.35      0.35      0.35        20\n",
      "     squares       0.25      0.25      0.25        20\n",
      "   triangles       0.40      0.40      0.40        20\n",
      "\n",
      "    accuracy                           0.33        60\n",
      "   macro avg       0.33      0.33      0.33        60\n",
      "weighted avg       0.33      0.33      0.33        60\n",
      "\n",
      "----------------MATRIX--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification = classification_report(test_generator.classes, y_pred, target_names=labels)\n",
    "print('----------------CLASSIFICATION--------------')\n",
    "print(classification)\n",
    "matrix = confusion_matrix(test_generator.classes, y_pred)\n",
    "df_cm = pd.DataFrame(matrix, index = [i for i in range(3)],\n",
    "                  columns = [i for i in range(3)])\n",
    "plt.figure(figsize = (10,7))\n",
    "print('----------------MATRIX--------------')\n",
    "sn.heatmap(df_cm, annot=True, linewidths=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1e421",
   "metadata": {},
   "source": [
    "<h3>Referências bibliográficas:</h3>\n",
    "<hr />\n",
    "<div>\n",
    "<p>https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/</p>\n",
    "    \n",
    "<p>https://www.viceri.com.br/insights/arquiteturas-de-redes-neurais-convolucionais-para-reconhecimento-de-imagens/</p>\n",
    "\n",
    "<p>https://abracd.org/overfitting-e-underfitting-em-machine-learning/</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
