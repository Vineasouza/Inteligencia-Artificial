{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legitimate-naples",
   "metadata": {},
   "source": [
    "#### https://keras.io/api/applications/inceptionresnetv2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "premier-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pleased-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500 # quantidade de vezes a ser executado o algoritmo, uma epoch é quanto todo o conjunto de treino foi utilizado\n",
    "batch = 32 # número de amostras que será carregado a cada execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lined-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega o modelo da InceptionResNetV2 com os pesos aprendidos no treino da InceptionResNetV2 sem a camada densa (include_top=False)\n",
    "base_model = tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "built-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O restante do modelo e suas camadas são discutidos a seguir \n",
    "# x recebe o final da InceptionResNetV2\n",
    "x=base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "upper-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 3 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None, 3 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 6 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, None, None, 6 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 8 5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 8 240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 8 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 1 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 9 55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 4 144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 9 288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 4 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 9 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, None, None, 1 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 9 18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 6 76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 6 12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 9 288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 6 192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 9 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 6 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, None, None, 3 0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 3 96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 3 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 4 13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 3 96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 4 144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 3 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 4 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 3 9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 6 27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 3 96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 6 192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 3 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 6 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, None, None, 1 0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, None, None, 3 41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, None, None, 3 0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, None, None, 3 0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 3 96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 3 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 4 13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 3 96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 4 144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 3 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 4 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 3 9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 3 96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 3 96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 3 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 3 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, None, None, 1 0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, None, None, 3 41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, None, None, 3 0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, None, None, 3 0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 4 13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 3 96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 4 144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 3 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 4 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 3 9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 6 27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 3 96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 3 96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 6 192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 3 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 3 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 6 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, None, None, 1 0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, None, None, 3 41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, None, None, 3 0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, None, None, 3 0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 3 96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 3 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 4 13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 3 96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 4 144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 3 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 4 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 3 9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 6 27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 3 96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 3 96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 6 192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 3 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 3 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 6 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, None, None, 1 0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, None, None, 3 41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, None, None, 3 0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, None, None, 3 0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 3 96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 3 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 4 13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 3 96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 4 144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 3 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 4 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 3 9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 6 27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 3 96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 3 96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 6 192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 3 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 3 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 6 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, None, None, 1 0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, None, None, 3 41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, None, None, 3 0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, None, None, 3 0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 3 96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 3 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 4 13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 3 96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 4 144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 3 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 4 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 3 9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 6 27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 3 96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 3 96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 6 192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 3 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 3 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 6 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, None, None, 1 0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, None, None, 3 41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, None, None, 3 0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, None, None, 3 0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 3 96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 3 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 4 13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 3 96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 4 144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 3 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 4 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 3 9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 6 27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 3 96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 3 96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 6 192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 3 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 3 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 6 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, None, None, 1 0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, None, None, 3 41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, None, None, 3 0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, None, None, 3 0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 3 96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 3 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 4 13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 3 96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 4 144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 3 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 4 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 3 9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 6 27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 3 96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 3 96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 6 192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 3 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 3 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 6 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, None, None, 1 0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, None, None, 3 41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, None, None, 3 0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, None, None, 3 0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 3 96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 3 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 4 13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 3 96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 4 144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 3 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 4 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 3 9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 6 27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 3 96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 3 96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 6 192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 3 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 3 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 6 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, None, None, 1 0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, None, None, 3 41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, None, None, 3 0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, None, None, 3 0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 3 96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 3 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 4 13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 3 96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 4 144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 3 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 4 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 3 9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 6 27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 3 96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 3 96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 6 192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 3 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 3 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 6 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, None, None, 1 0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, None, None, 3 41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, None, None, 3 0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, None, None, 3 0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 2 81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 2 768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 2 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 2 589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 2 768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 2 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 3 884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 3 1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 3 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 3 0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 1 139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 1 384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 1 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 1 143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 1 480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 1 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 1 215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 1 576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 1 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, None, None, 3 0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, None, None, 1 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, None, None, 1 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, None, None, 1 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 1 139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 1 384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 1 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 1 143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 1 480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 1 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 1 208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 1 215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 1 576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 1 576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 1 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 1 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, None, None, 3 0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, None, None, 1 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, None, None, 1 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, None, None, 1 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 1 143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 1 480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 1 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 1 208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 1 215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 1 576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 1 576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 1 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 1 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, None, None, 3 0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, None, None, 1 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, None, None, 1 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, None, None, 1 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 1 139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 1 384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 1 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 1 143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 1 480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 1 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 1 208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 1 215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 1 576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 1 576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 1 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 1 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, None, None, 3 0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, None, None, 1 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, None, None, 1 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, None, None, 1 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 1 139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 1 384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 1 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 1 208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, None, None, 1 215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 1 576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, None, 1 576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 1 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 1 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, None, None, 3 0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, None, None, 1 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, None, None, 1 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, None, None, 1 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, None, None, 1 139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, None, 1 384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 1 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, None, None, 1 143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, None, 1 480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 1 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, None, None, 1 208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, None, None, 1 215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, None, 1 576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, None, 1 576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 1 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 1 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, None, None, 3 0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, None, None, 1 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, None, None, 1 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, None, None, 1 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, None, None, 1 139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, None, 1 384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 1 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, None, None, 1 143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, None, 1 480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 1 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, None, None, 1 208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, None, None, 1 215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, None, 1 576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, None, 1 576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 1 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 1 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, None, None, 3 0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, None, None, 1 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, None, None, 1 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, None, None, 1 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, None, None, 1 139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, None, 1 384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 1 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, None, None, 1 143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, None, 1 480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 1 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, None, None, 1 208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, None, None, 1 215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, None, 1 576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, None, 1 576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 1 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 1 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, None, None, 3 0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, None, None, 1 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, None, None, 1 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, None, None, 1 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, None, None, 1 139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, None, 1 384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 1 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, None, None, 1 143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, None, 1 480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 1 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, None, None, 1 208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, None, None, 1 215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, None, 1 576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, None, 1 576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 1 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 1 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, None, None, 3 0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, None, None, 1 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, None, None, 1 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, None, None, 1 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, None, None, 1 139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, None, 1 384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 1 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, None, None, 1 143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, None, 1 480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 1 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, None, None, 1 208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, None, None, 1 215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, None, 1 576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, None, None, 1 576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 1 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 1 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, None, None, 3 0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, None, None, 1 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, None, None, 1 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, None, None, 1 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, None, None, 1 139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, None, None, 1 384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 1 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, None, None, 1 143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, None, None, 1 480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 1 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, None, None, 1 208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, None, None, 1 215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, None, None, 1 576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, None, None, 1 576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 1 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 1 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, None, None, 3 0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, None, None, 1 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, None, None, 1 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, None, None, 1 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, None, None, 1 139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, None, None, 1 384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 1 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, None, None, 1 143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, None, None, 1 480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 1 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, None, None, 1 208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, None, None, 1 215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, None, None, 1 576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, None, None, 1 576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 1 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 1 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, None, None, 3 0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, None, None, 1 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, None, None, 1 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, None, None, 1 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, None, None, 1 139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, None, None, 1 384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, None, None, 1 143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, None, None, 1 480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 1 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, None, None, 1 208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, None, None, 1 215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, None, None, 1 576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, None, None, 1 576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, None, 1 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 1 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, None, None, 3 0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, None, None, 1 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, None, None, 1 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, None, None, 1 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, None, None, 1 139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, None, None, 1 384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 1 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, None, None, 1 143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, None, None, 1 480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 1 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, None, None, 1 208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, None, None, 1 215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, None, None, 1 576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, None, None, 1 576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 1 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 1 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, None, None, 3 0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, None, None, 1 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, None, None, 1 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, None, None, 1 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, None, 1 139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, None, None, 1 384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 1 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, None, 1 143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, None, None, 1 480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, None, None, 1 208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, None, 1 215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, None, None, 1 576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, None, None, 1 576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 1 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 1 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, None, None, 3 0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, None, None, 1 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, None, None, 1 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, None, None, 1 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, None, 1 139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, None, None, 1 384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 1 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, None, 1 143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, None, None, 1 480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 1 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, None, 1 208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, None, 1 215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, None, None, 1 576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, None, None, 1 576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 1 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 1 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, None, None, 3 0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, None, None, 1 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, None, None, 1 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, None, None, 1 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, None, 1 139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, None, None, 1 384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 1 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, None, 1 143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, None, None, 1 480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 1 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, None, 1 208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, None, None, 1 215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, None, None, 1 576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, None, None, 1 576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 1 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, None, None, 3 0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, None, None, 1 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, None, None, 1 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, None, None, 1 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, None, None, 1 139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, None, None, 1 384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, None, None, 1 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, None, None, 1 143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, None, None, 1 480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, None, None, 1 0           batch_normalization_146[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, None, 1 208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, None, None, 1 215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, None, None, 1 576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, None, None, 1 576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, None, None, 1 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, None, None, 1 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, None, None, 3 0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, None, None, 1 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, None, None, 1 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, None, None, 1 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, None, None, 1 139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, None, None, 1 384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, None, None, 1 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, None, None, 1 143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, None, None, 1 480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, None, None, 1 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, None, None, 1 208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, None, None, 1 215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, None, None, 1 576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, None, None, 1 576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, None, None, 1 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, None, None, 1 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, None, None, 3 0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, None, None, 1 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, None, None, 1 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, None, None, 1 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, None, None, 1 139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, None, None, 1 384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, None, None, 1 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, None, None, 1 143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, None, None, 1 480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, None, None, 1 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, None, None, 1 208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, None, None, 1 215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, None, None, 1 576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, None, None, 1 576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, None, None, 1 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, None, None, 1 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, None, None, 3 0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, None, None, 1 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, None, None, 1 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, None, None, 1 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, None, None, 2 768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, None, 2 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, None, None, 2 663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, None, None, 2 768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, None, None, 2 768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, None, None, 2 864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, None, None, 2 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, None, None, 2 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, None, 2 0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, None, None, 3 884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, None, None, 2 663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, None, None, 3 829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, None, None, 3 1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, None, None, 2 864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, None, None, 3 960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, None, None, 3 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, None, None, 2 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, None, 3 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, None, None, 2 0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, None, None, 1 576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, None, 1 0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, None, None, 2 129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, None, None, 2 672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, None, 2 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, None, None, 2 172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, None, None, 1 576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, None, None, 2 768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, None, 1 0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, None, 2 0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, None, None, 4 0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, None, None, 2 933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, None, None, 2 0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, None, None, 2 0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, None, None, 1 576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, None, 1 0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, None, None, 2 129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, None, None, 2 672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, None, 2 0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, None, None, 2 172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, None, None, 1 576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, None, None, 2 768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, None, 1 0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, None, 2 0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, None, None, 4 0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, None, None, 2 933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, None, None, 2 0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, None, None, 2 0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, None, None, 1 576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, None, 1 0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, None, None, 2 129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, None, None, 2 672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, None, 2 0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, None, None, 2 172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, None, None, 1 576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, None, None, 2 768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, None, 1 0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, None, 2 0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, None, None, 4 0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, None, None, 2 933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, None, None, 2 0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, None, None, 2 0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, None, None, 1 576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, None, 1 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, None, None, 2 129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, None, None, 2 672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, None, 2 0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, None, None, 2 172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, None, None, 1 576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, None, None, 2 768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, None, 1 0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, None, 2 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, None, None, 4 0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, None, None, 2 933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, None, None, 2 0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, None, None, 2 0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, None, None, 1 576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, None, None, 1 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, None, None, 2 129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, None, None, 2 672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, None, None, 2 0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, None, None, 2 172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, None, None, 1 576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, None, None, 2 768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, None, 1 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, None, None, 2 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, None, None, 4 0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, None, None, 2 933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, None, None, 2 0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, None, None, 2 0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, None, None, 1 576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, None, None, 1 0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, None, None, 2 129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, None, None, 2 672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, None, None, 2 0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, None, None, 2 172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, None, None, 1 576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, None, None, 2 768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, None, None, 1 0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, None, None, 2 0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, None, None, 4 0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, None, None, 2 933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, None, None, 2 0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, None, None, 2 0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, None, None, 1 576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, None, None, 1 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, None, None, 2 129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, None, None, 2 672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, None, None, 2 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, None, None, 2 172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, None, None, 1 576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, None, None, 2 768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, None, None, 1 0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, None, None, 2 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, None, None, 4 0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, None, None, 2 933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, None, None, 2 0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, None, None, 2 0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, None, None, 1 576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, None, None, 1 0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, None, None, 2 129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, None, None, 2 672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, None, None, 2 0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, None, None, 2 172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, None, None, 1 576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, None, None, 2 768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, None, None, 1 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, None, None, 2 0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, None, None, 4 0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, None, None, 2 933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, None, None, 2 0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, None, None, 2 0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, None, None, 1 576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, None, None, 1 0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, None, None, 2 129024      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, None, None, 2 672         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, None, None, 2 0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, None, None, 2 172032      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, None, None, 1 576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, None, None, 2 768         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, None, None, 1 0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, None, None, 2 0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, None, None, 4 0           activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, None, None, 2 933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, None, None, 2 0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, None, None, 2 0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, None, None, 1 576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, None, None, 1 0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, None, None, 2 129024      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, None, None, 2 672         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, None, None, 2 0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, None, None, 2 172032      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, None, None, 1 576         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, None, None, 2 768         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, None, None, 1 0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, None, None, 2 0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, None, None, 4 0           activation_199[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, None, None, 2 933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, None, None, 2 0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, None, None, 1 3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, None, None, 1 4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, None, None, 1 0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          196736      global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            99          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 54,543,907\n",
      "Trainable params: 54,483,363\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Nova configuração para o modelo\n",
    "\n",
    "#adiciona apos x uma camada GlobalMaxPooling2D e atribui este no a x novamente (logo x e o topo novamente)\n",
    "x=tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "#adiciona apos x uma camada densa com 128 neuronios com funcao de ativacao relu. Atribui este no a x novamente\n",
    "x=tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "#adiciona apos x uma camada densa com 64 neuronios com funcao de ativacao relu. Atribui este no a x novamente\n",
    "x=tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "\n",
    "#adiciona apos x uma camada densa com 32 neuronios com funcao de ativacao relu. Atribui este no a x novamente\n",
    "x=tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "\n",
    "#adiciona após x os neurônios que devem ser utilizados, nesse caso foram desligados 20% dos neuronios\n",
    "x=tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "#adiciona apos x uma camada densa com 7 neuronios (sete classes) com funcao de ativacao softmax (distribuicao de probabilidade). Atribui este no a preds\n",
    "#preds=tf.keras.layers.Dense(3,activation='softmax')(x)\n",
    "preds=tf.keras.layers.Dense(3,activation='sigmoid')(x)\n",
    "\n",
    "#definindo modelo final\n",
    "model=tf.keras.models.Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "#mostrando modelo final e sua estrutura\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "therapeutic-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "#congelando os neuronios já treinados na ImageNet, queremos retreinar somente a ultima camada\n",
    "for l in model.layers:\n",
    "    if l.name.split('_')[0] != 'dense':\n",
    "        l.trainable=False\n",
    "    else:\n",
    "        l.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "british-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iniciando objeto que apanhara todas as imagens de treino, processando as imagens com o metodo da ResNet50V2\n",
    "train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input) #included in our dependencies\n",
    "\n",
    "#iniciando objeto que apanhara todas as imagens de teste, processando as imagens com o metodo da ResNet50V2\n",
    "test_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "black-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#CARREGANDO PRÓPRIO DATASET PARA USO\n",
    "#target_size=(224, 224)\n",
    "\n",
    "#definindo gerador de imagens de treino\n",
    "train_generator = train_data_gen.flow_from_directory('shapes_split/train',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "#definindo gerador de imagens de teste\n",
    "test_generator = test_data_gen.flow_from_directory('shapes_split/test',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expired-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.optimizers.Adam(learning_rate=0.001) #estabelecendo taxa de otimização\n",
    "\n",
    "model.compile(optimizer=lr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "industrial-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicao dos steps\n",
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_test = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "practical-crossing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vinicius\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 29s 2s/step - loss: 1.7329 - accuracy: 0.4753 - val_loss: 0.1561 - val_accuracy: 0.9688\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.2681 - accuracy: 0.8773 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.1077 - accuracy: 0.9393 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0451 - accuracy: 0.9840 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0425 - accuracy: 0.9807 - val_loss: 6.9987e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 4.3023e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0212 - accuracy: 0.9957 - val_loss: 1.4090e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0235e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 5.5700e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0185 - accuracy: 0.9912 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 4.1436e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.5311e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.1727e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.2052e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0107 - accuracy: 0.9948 - val_loss: 2.3271e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 6.5074e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 5.6638e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.6932e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 6.3775e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 9.2822e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2836e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.2991e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.1531e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.3351e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0057 - accuracy: 0.9945 - val_loss: 1.9223e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7000e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.7424e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6697e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6850e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0145 - accuracy: 0.9931 - val_loss: 1.6279e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 6.3400e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.9532e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0028 - accuracy: 0.9976 - val_loss: 4.1908e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9403e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 2.1606e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5311e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.8324e-04 - accuracy: 1.0000 - val_loss: 4.6566e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.6689e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0054 - accuracy: 0.9950 - val_loss: 7.0773e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 5.0325e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 1.1176e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0103 - accuracy: 0.9931 - val_loss: 9.3665e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0041 - accuracy: 0.9961 - val_loss: 7.8673e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0224 - accuracy: 0.9814 - val_loss: 1.1576e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0255 - accuracy: 0.9816 - val_loss: 2.4890e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1399e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0065 - accuracy: 0.9961 - val_loss: 4.1722e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.2128e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 2.0005e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.6263e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.8237e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.2724e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9930e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 4.6974e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0143 - accuracy: 0.9916 - val_loss: 1.6913e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0113 - accuracy: 0.9931 - val_loss: 5.1256e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0110 - accuracy: 0.9948 - val_loss: 1.8030e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0083 - accuracy: 0.9945 - val_loss: 1.1651e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0075 - accuracy: 0.9928 - val_loss: 1.0283e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.2181e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.4564e-04 - accuracy: 1.0000 - val_loss: 7.6368e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0322 - accuracy: 0.9853 - val_loss: 3.0583e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0074 - accuracy: 0.9945 - val_loss: 1.1548e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0059 - accuracy: 0.9948 - val_loss: 5.5502e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.0439e-04 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9848e-04 - accuracy: 1.0000 - val_loss: 1.6093e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 1.6242e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 9.7590e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 7.1152e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.8609e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0154 - accuracy: 0.9892 - val_loss: 9.6857e-08 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 1.6130e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0032 - accuracy: 0.9969 - val_loss: 0.2306 - val_accuracy: 0.9375\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0250 - accuracy: 0.9907 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.2269e-04 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0507 - accuracy: 0.9809 - val_loss: 1.2256e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0068 - accuracy: 0.9961 - val_loss: 1.7732e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 0.9950 - val_loss: 8.0838e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 6.9290e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.5757e-04 - accuracy: 1.0000 - val_loss: 4.9174e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.6857e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0100 - accuracy: 0.9945 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 4.1350e-07 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.1757e-04 - accuracy: 1.0000 - val_loss: 3.0547e-07 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.0614e-05 - accuracy: 1.0000 - val_loss: 2.4214e-07 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.4665e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0192 - accuracy: 0.9880 - val_loss: 3.1887e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.5864e-04 - accuracy: 1.0000 - val_loss: 2.3841e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 0.9981 - val_loss: 8.4664e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0174 - accuracy: 0.9880 - val_loss: 1.5717e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0184 - accuracy: 0.9892 - val_loss: 1.8999e-07 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 1.9632e-06 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0098 - accuracy: 0.9887 - val_loss: 1.3336e-06 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.1264e-04 - accuracy: 1.0000 - val_loss: 1.0431e-06 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.8429e-08 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.4378e-04 - accuracy: 1.0000 - val_loss: 5.3644e-07 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.0300e-04 - accuracy: 1.0000 - val_loss: 1.2293e-07 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.0233e-07 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.2924e-04 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.1403e-04 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0058e-07 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8685e-07 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.7253e-07 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.9659e-04 - accuracy: 1.0000 - val_loss: 3.2037e-07 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.8312e-07 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.5009e-04 - accuracy: 1.0000 - val_loss: 2.3097e-07 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9935e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.7294e-05 - accuracy: 1.0000 - val_loss: 2.4214e-07 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5116e-04 - accuracy: 1.0000 - val_loss: 2.6822e-07 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.2037e-07 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.7625e-07 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.2267e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0034 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.8704e-04 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.3378e-05 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2956e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0093 - accuracy: 0.9919 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5402e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.1127e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.9283e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0053 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0085 - accuracy: 0.9931 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.1702e-04 - accuracy: 1.0000 - val_loss: 3.1665e-07 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9963e-04 - accuracy: 1.0000 - val_loss: 6.1467e-07 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.2724e-07 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1697e-06 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.4387e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 5.3900e-06 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0325e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6953e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0011 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4577e-05 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.2543e-04 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5248e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3658e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1341e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0453e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.3947e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.5103e-05 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.9013e-06 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6916e-04 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6567e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.0289e-04 - accuracy: 1.0000 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.3157e-05 - accuracy: 1.0000 - val_loss: 8.6053e-07 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1038e-04 - accuracy: 1.0000 - val_loss: 9.9836e-07 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9711e-04 - accuracy: 1.0000 - val_loss: 7.4132e-07 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6231e-04 - accuracy: 1.0000 - val_loss: 4.7311e-07 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0159 - accuracy: 0.9892 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.0444e-04 - accuracy: 1.0000 - val_loss: 1.9371e-07 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7057e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 3.8335e-04 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7470e-04 - accuracy: 1.0000 - val_loss: 8.7916e-07 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3530e-06 - accuracy: 1.0000 - val_loss: 7.7485e-07 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0145 - accuracy: 0.9981 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0659 - accuracy: 0.9909 - val_loss: 1.7639e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2303 - accuracy: 0.9778 - val_loss: 0.2009 - val_accuracy: 0.9375\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0586 - accuracy: 0.9868 - val_loss: 6.9290e-07 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0328 - accuracy: 0.9879 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0165 - accuracy: 0.9961 - val_loss: 1.1548e-07 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7863e-06 - accuracy: 1.0000 - val_loss: 6.2255e-05 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0157 - accuracy: 0.9975 - val_loss: 1.9855e-06 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.8957e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.0181e-05 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.7163e-04 - accuracy: 1.0000 - val_loss: 1.8999e-07 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0091 - accuracy: 0.9949 - val_loss: 6.7055e-08 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.3940e-05 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.5882e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0094 - accuracy: 0.9950 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 0.9988 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.2545e-05 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.5164e-06 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.8178e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.2017e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.8715e-06 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0067 - accuracy: 0.9948 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0094 - accuracy: 0.9919 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.1435e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0037e-04 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.8489e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.9942e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.9227e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9628e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0077 - accuracy: 0.9931 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6208e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.9293e-06 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3832e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.4736e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0045 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0203 - accuracy: 0.9892 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0738e-04 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 6.3483e-04 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2403e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0077 - accuracy: 0.9951 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0126e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0120 - accuracy: 0.9948 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0334e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0963e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3087e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.7479e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.1490e-05 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4748e-08 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0140 - accuracy: 0.9887 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0418e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.9476e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0084 - accuracy: 0.9928 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0025 - accuracy: 0.9981 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0092e-05 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.6466e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3691e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1872e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8134e-04 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.2140e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.8101e-07 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0172 - accuracy: 0.9892 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3364e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0083 - accuracy: 0.9928 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5392e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.8671e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1129e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.8983e-04 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.4431e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.7281e-04 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0084 - accuracy: 0.9962 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.9106e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4834e-05 - accuracy: 1.0000 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5528e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6324e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9603e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 1.1369e-05 - accuracy: 1.0000 - val_loss: 1.2293e-07 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.1402e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.1709e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0028 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.9321e-07 - accuracy: 1.0000 - val_loss: 1.3038e-07 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5519e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 0.9964 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2202e-04 - accuracy: 1.0000 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0093 - accuracy: 0.9926 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.4752e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.6359e-04 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3339e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.7077e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6133e-07 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.4602e-06 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.4383e-06 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.0012e-04 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0074 - accuracy: 0.9965 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.0932e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.5042e-05 - accuracy: 1.0000 - val_loss: 7.0780e-08 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0441e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0084 - accuracy: 0.9927 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4982e-05 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6653e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2690e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4295e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9843e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3926e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7508e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.7580e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.5872e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.7332e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.3776e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9980e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2134e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.1579e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.9137e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5921e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.7738e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.1706e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0033 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0092 - accuracy: 0.9930 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.8895e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.7356e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.9844e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0900e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9014e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8964e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.6337e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 4.1671e-07 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3225e-04 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.4813e-05 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6153e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.0878e-06 - accuracy: 1.0000 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.1775e-08 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.6444e-04 - accuracy: 1.0000 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0632e-05 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.4734e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.4555e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2481e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 9.5087e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0192 - accuracy: 0.9825 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0061 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1007e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6706e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.0960e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.9994e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.1983e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.0589e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.6759e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.2542e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2600e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9734e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3991e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1199e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 0.9973 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8541e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.2213e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.1528e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0213 - accuracy: 0.9891 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.4442e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.3738e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 4.8308e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3077e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0132 - accuracy: 0.9887 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.5383e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.4853e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.2897e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0077 - accuracy: 0.9926 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.6063e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6159e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0083 - accuracy: 0.9932 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5671e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.7553e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0079 - accuracy: 0.9931 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6013e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4563e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0107 - accuracy: 0.9887 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0108 - accuracy: 0.9930 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1907e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8206e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.9576e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.8492e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9030e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0078 - accuracy: 0.9932 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3797e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1816e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.4989e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2251e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 0.9964 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0632e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1473e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3449e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.9028e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.8467e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.6232e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9736e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.2597e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.4962e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0124 - accuracy: 0.9893 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4035e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0048 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9681e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.0369e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2014e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3127e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.4140e-07 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.0887e-06 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0685e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 7.8402e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4550e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0070 - accuracy: 0.9931 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.7298e-06 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.2988e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4791e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.8763e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.3447e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6271e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.3006e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2128e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0053 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.6035e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1174e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.6895e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0135 - accuracy: 0.9841 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.6514e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.7372e-05 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.3450e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.7689e-06 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0063 - accuracy: 0.9948 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.6003e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8480e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 0.9981 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6232e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.8331e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9830e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.7962e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1395e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.3402e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.1041e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.3385e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.4107e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4484e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.6460e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.0833e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4534e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1047e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.4328e-06 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.2800e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.7896e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.5522e-07 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#treinando e testando o modelo\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_generator,\n",
    "                   validation_steps=step_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "therapeutic-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vinicius\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 1.000\n"
     ]
    }
   ],
   "source": [
    "#Avaliando o modelo\n",
    "loss_train, train_acc = model.evaluate_generator(train_generator, steps=step_size_train)\n",
    "loss_test, test_acc = model.evaluate_generator(test_generator, steps=step_size_test)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "contained-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Apresentando resultados em graficos\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assured-flesh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando graficos para visualização dos resultados\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "forty-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando classificações..\n",
      "Rótulos ['circles', 'squares', 'triangles']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vinicius\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds Created\n",
      "Preds 1D created\n"
     ]
    }
   ],
   "source": [
    "print('Criando classificações..')\n",
    "labels = os.listdir('shapes_split/test')\n",
    "print('Rótulos', labels)\n",
    "#criando estruturas para métricas de avaliação, processo um pouco mais demorado\n",
    "Y_pred = model.predict_generator(test_generator)\n",
    "print('Preds Created')\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Preds 1D created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nuclear-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------CLASSIFICATION--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     circles       0.35      0.35      0.35        20\n",
      "     squares       0.35      0.35      0.35        20\n",
      "   triangles       0.30      0.30      0.30        20\n",
      "\n",
      "    accuracy                           0.33        60\n",
      "   macro avg       0.33      0.33      0.33        60\n",
      "weighted avg       0.33      0.33      0.33        60\n",
      "\n",
      "----------------MATRIX--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification = classification_report(test_generator.classes, y_pred, target_names=labels)\n",
    "print('----------------CLASSIFICATION--------------')\n",
    "print(classification)\n",
    "matrix = confusion_matrix(test_generator.classes, y_pred)\n",
    "df_cm = pd.DataFrame(matrix, index = [i for i in range(3)],\n",
    "                  columns = [i for i in range(3)])\n",
    "plt.figure(figsize = (10,7))\n",
    "print('----------------MATRIX--------------')\n",
    "sn.heatmap(df_cm, annot=True, linewidths=2.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
