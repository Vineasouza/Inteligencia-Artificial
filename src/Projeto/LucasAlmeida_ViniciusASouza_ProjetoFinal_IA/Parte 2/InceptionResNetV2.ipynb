{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f876f84",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <h1 align=\"center\">Trabalho de Deep Learning</h1>\n",
    "  <div align=\"center\">Lucas de Almeida, RA: 1996762</div>\n",
    "  <div align=\"center\">Vinícius Augusto de Souza, RA: 1997530</div>\n",
    "  <hr/>\n",
    "  <div align=\"center\">Uma abordagem dos conceitos de redes neurais convolucionais pré treinadas utilizando o método de <i>transfer learning</i>.\n",
    "</div>\n",
    "  <div align=\"center\">A base de dados a ser utilizada será a <i>Basic Shapes</i>, que pode ser encontrada <a href=\"https://www.kaggle.com/cactus3/basicshapes\">neste link</a>. Ela é bem simples e objetiva, contendo um acervo de 300 imagens: 100 imagens de cada forma geométrica (circulos, quadrados e triangulos) desenhados manualmente por <a href=\"https://www.kaggle.com/cactus3\">Mark S.</a></div>\n",
    "</div>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-naples",
   "metadata": {},
   "source": [
    "<h3>Considerações sobre o trabalho:</h3>\n",
    "<hr/>\n",
    "<p>Para o desenvolvimento deste trabalho, foi escolhido o modelo pré-treinado da literatura <i><a href=\"https://keras.io/api/applications/inceptionresnetv2/\">InceptionResNetV2</a></i>, considerando os pesos também pré treinados da <i>ImageNet</i>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "premier-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900cd2fe",
   "metadata": {},
   "source": [
    "<h3>Separação dos arquivos:</h3>\n",
    "<hr>\n",
    "<div>Antes de começar a tratar os dados, é necessário realizar a divisão do dataset em 80% para treino e 20% para testes.</div>\n",
    "<div>O código a seguir realiza essa tarefa, passando como variáveis:</div>\n",
    "<ul>\n",
    "    <li><i>data_dir</i>: o nome do caminho do diretório do dataset escolhido;</li>\n",
    "    <li><i>classes</i>: as classes das quais os arquivos pertencem (circulos, quadrados e triângulos);</li>\n",
    "    <li><i>output_dir</i>: o nome do caminho do diretório de saída, após separação;</li>\n",
    "    <li><i>ratio</i>: a taxa de divisão dos arquivos (i.e. 80% treino e 20% testes);</li>\n",
    "</ul>\n",
    "<p>Em seguida são carregadas essas variávies e todas as imagens <i>.png</i> são selecionadas e armazenadas na variável <i>file</i>.</p>\n",
    "<p>Em seguida, é escolhida uma <i>seed</i> arbitrária para embaralhar as imagens de forma que seja possível reproduzir essa mesma divisão posteriormente. Os arquivos então são embaralhados e divididos conforme os parâmetros passados anteriormente.</p>\n",
    "<p>Por fim, os arquivos divididos são enviados cada um para seu respectivo diretório, treino ou teste, e sempre divididos em pastas referentes à sua classe, conforme a estrutura a seguir:</p>\n",
    "<ul>\n",
    "    <li><i>test</i> <span  style=\"color:lightgrey\">(80% do dataset)</span></li>\n",
    "    <ul>\n",
    "        <li><i>circles</i></li>\n",
    "        <li><i>triangles</i></li>\n",
    "        <li><i>squares</i></li>\n",
    "    </ul>\n",
    "    <li><i>train</i> <span  style=\"color:lightgrey\">(20% do dataset)</span></li>\n",
    "    <ul>\n",
    "        <li><i>circles</i></li>\n",
    "        <li><i>triangles</i></li>\n",
    "        <li><i>squares</i></li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9a4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"shapes\"\n",
    "classes = [\"circles\", \"squares\", \"triangles\"]\n",
    "output_dir = \"shapes_split\"\n",
    "ratio = [0.8, 0.2]\n",
    "\n",
    "def split(data_dir, output_dir, ratio):\n",
    "    for cell in classes:\n",
    "        cell_path = os.path.join(data_dir, cell)\n",
    "        files = os.listdir(cell_path)\n",
    "        files = [os.path.join(cell_path, f) for f in files if f.endswith('.png')]\n",
    "\n",
    "        random.seed(230)\n",
    "        files.sort()\n",
    "        random.shuffle(files)\n",
    "\n",
    "        split_train = int(ratio[0] * len(files))\n",
    "        split_test = split_train\n",
    "\n",
    "        files_train = files[:split_train]\n",
    "        files_test = files[split_test:]\n",
    "        files_type = [(files_train, \"train\"), (files_test, \"test\")]\n",
    "\n",
    "        for (files, folder_type) in files_type:\n",
    "            full_path = os.path.join(output_dir, folder_type)\n",
    "            full_path = os.path.join(full_path, cell)\n",
    "            pathlib.Path(full_path).mkdir(parents=True, exist_ok=True)\n",
    "            for f in files:\n",
    "                shutil.copy2(f, full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72791dcc",
   "metadata": {},
   "source": [
    "<h3>Definição dos parâmetros do modelo:</h3>\n",
    "<hr>\n",
    "<div>Antes de prosseguir, é necessário compreender em quais parâmetros o modelo se baseia. Dois desses parâmetros terão de ser definidos neste momento, os quais são:</div>\n",
    "<ul>\n",
    "    <li><i>epochs</i>: quantas vezes o algoritmo de treino será executado;</li>\n",
    "    <li><i>batch size</i>: quantas amostras serão carregadas a cada uma dessas execuções.</li>\n",
    "</ul>\n",
    "<div>Para o treinamento, foi definido que seriam utilizadas 500 <i>epochs</i> e 32 como <i>batch size</i>.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pleased-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd69601",
   "metadata": {},
   "source": [
    "<h3>Carregamento do modelo \"<i>InceptionResNetV2</i>\":</h3>\n",
    "<hr>\n",
    "<div>Primeiramente o modelo escolhido é carregado juntamente com os pesos aprendidos durante o treino (sem a camada densa) para a variável <i>base_model</i>. Em seguida, a variável <i>x</i> recebe a saída do modelo carregado.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lined-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "built-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=base_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c065c",
   "metadata": {},
   "source": [
    "<h3>Configuração do modelo \"<i>InceptionResNetV2</i>\":</h3>\n",
    "<hr />\n",
    "<div>\n",
    "  Nesta etapa é necessário adicionar algumas camadas de nós. Para explicar o que\n",
    "  ocorre em cada uma das camadas, é preciso observá-las uma a uma, conforme\n",
    "  descrito abaixo:\n",
    "</div>\n",
    "<ul>\n",
    "  <li>\n",
    "    <i>camada GlobalMaxPooling</i>: Para reduzir a resolução, é utilizada uma\n",
    "    operação de <i>pooling</i> conhecida como “<i>pooling máximo</i>” (ou\n",
    "    <i>max pooling</i>). Nesta operação de agrupamento, um “bloco” com altura\n",
    "    'A' e largura 'L' desliza sobre os dados de entrada (conforme na figura\n",
    "    abaixo, de 'a' até 'd'). A cada iteração (ou seja, o quanto ela avança\n",
    "    durante a operação de deslizamento) é muitas vezes igual ao tamanho da\n",
    "    <i>pool</i>, de modo que seu efeito é igual a uma redução na altura e\n",
    "    largura. Para cada bloco, ou “pool”, a operação envolve simplesmente o\n",
    "    cálculo do valor máximo. Fazendo isso para cada pool, obtemos um resultado\n",
    "    bem reduzido, otimizando muito a quantidade de espaço de que precisamos.\n",
    "  </li>\n",
    "  <img src=\"max-pooling.png\" width=\"500\" />\n",
    "  <br /><br />\n",
    "  <li>\n",
    "    camada densa com função de ativação \"<i>ReLU</i>\": A função de ativação\n",
    "    linear retificada (ou <i>ReLU</i>) é uma função linear por partes que\n",
    "    produzirá a entrada diretamente se for positiva, caso contrário, ela\n",
    "    produzirá zero. Ela se comporta conforme o gráfico abaixo:\n",
    "    <br />\n",
    "    <img src=\"relu.jpg\" width=\"500\" />\n",
    "    Neste caso, foram adicionadas três camadas densas deste tipo, porém uma com\n",
    "    128 neurônios, outra com 64 neurônios e outra com 32 neurônios.\n",
    "    <br />\n",
    "  </li>\n",
    "  <li>\n",
    "    <i>camada dropout</i>: é feita uma espécide de \"regularização\", onde alguns\n",
    "    neurônios são desligados de forma aleatória, juntamente com suas conexões,\n",
    "    apenas durante o período de treinamento, porém durante a predição todos os\n",
    "    neurônios são mantidos ativos. O motivo de se fazer isso é evitar\n",
    "    <i>overfitting</i> no treinamento. A porcentagem escolhida nesse caso foi de\n",
    "    50%, conforme orientação no enunciado do projeto.\n",
    "  </li>\n",
    "  <li>\n",
    "    <i>camada de ativação</i>: utiliza uma função de ativação ao final das camadas anteriores. Essa função tenta aplicar um comportamento biologicamente análogo às excitações dos neurônios reais, isto é, replicar o comportamento de transmissão de informações dos neurônios, que só conseguem passar adiante a informação após sofrerem um estímulo. O que ocorre na prática é que a função insere um comportamento de \"não-linearidade\" após a função dos pesos com as entradas. Conforme enunciado, teria de ser feita uma escolha entre a função <i>sigmóide</i> e a função <i>softmax</i>. A escolha nesta situação é intuitiva, pois a função sigmóid é mais utilizada no aprendizado de funções lógicas, uma vez que ela tenta encaixar os valores entre 0 e 1. Já a função softmax produz uma distribuição de probabilidades para cada uma das classes das imagens durante a classificação, ao contrário da sigmóid que só consegue lidar com duas classes. Sendo assim, fica definido então que a função a ser utilizada é a <i>softmax</i> com 3 classes.\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<div>\n",
    "  Em seguida é feita a definição do modelo final bem como sua exibição, que pode\n",
    "  ser vista na sumário a seguir:\n",
    "</div>\n",
    "<span style=\"color: lightgrey\"\n",
    "  >Obs.: em virtude do tamanho do sumário, a linha de código que o exibe foi\n",
    "  comentada.</span\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "upper-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "preds=tf.keras.layers.Dense(3,activation='softmax')(x)\n",
    "\n",
    "model=tf.keras.models.Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2d0de",
   "metadata": {},
   "source": [
    "<h3>Treinamento e teste do modelo:</h3>\n",
    "<hr />\n",
    "<div>\n",
    "  Primeiramente, é feito o congelamento dos neurônios já treinados na\n",
    "  <i>ImageNet</i>, para retreinar somente as camadas densas incluídas no passo\n",
    "  anterior. Para fazer isso, é feita a mudança na variável booleana\n",
    "  \"<i>treinable</i>\" de cada camada que não inicia com o nome \"<i>dense</i>\"\n",
    "  para false.\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Em seguida são criados dois objetos:\n",
    "  <ul>\n",
    "    <li><i>train_data_gen</i>;</li>\n",
    "    <li><i>test_data_gen</i>.</li>\n",
    "  </ul>\n",
    "  Cada um desses objetos irá receber as imagens já processadas com o método da <i>ResNetV2</i>, separados em treino e teste conforme a nomenclatura da variável.\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Posteriormente, é necessário criar os geradores das imagens (tanto de teste quanto de treino). Isso é feito atravez dos objetos criados anteriormente, através da função \"<i>flow_from_directory</i>\". Seus parâmetros são os que seguem:\n",
    "  <ul>\n",
    "    <li><i>path</i>: o caminho do diretório onde estão localizadas as imagens;</li>\n",
    "    <li><i>target_size</i>: o tamanho da imagem (neste caso, foi escolhido o tamanho 128x128);</li>\n",
    "    <li><i>batch_size</i>: o mesmo explicado anteriormente, que já foi definido como 32;</li>\n",
    "    <li><i>class_mode</i>: pode ser \"input\", caso a imagem de entrada e saída forem as mesmas, \"binary\" se existirem apenas duas classes para realizar a predição ou \"categorical\", caso hajam mais classes, que é este caso;</li>\n",
    "    <li><i>shuffle</i>: <i>booleano</i> para ativar ou não o embaralhamento da ordem das imagens que seram utilizadas.</li>\n",
    "  </ul>\n",
    "  O resultado obtido são dois geradores como saída, armazenados nos objetos:\n",
    "  <ul>\n",
    "    <li><i>train_generator</i>;</li>\n",
    "    <li><i>test_generator</i>.</li>\n",
    "  </ul>\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Com os geradores criados, é preciso definir o otimizador. Conforme enunciado, os otimizadores que apresentam melhores resultados são o <i>SGD</i> e o <i>Adam</i>. Sendo assim, foi escolhido o <i>Adam</i>. Sendo assim, foi compilado o modelo com esses parâmetros, juntamente com a métrica escolhida como sendo por acurácia (<i>accuracy</i>), conforme orientação do enunciado.\n",
    "</div>\n",
    "</div>\n",
    "<br />\n",
    "<div>Por fim foram definidos os steps, e o modelo foi efetivamente treinado e testado. Os resultados podem ser vistos nos próximos tópicos.</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "therapeutic-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    if l.name.split('_')[0] != 'dense':\n",
    "        l.trainable=False\n",
    "    else:\n",
    "        l.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "british-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)\n",
    "\n",
    "test_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "black-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory('shapes_split/train',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "test_generator = test_data_gen.flow_from_directory('shapes_split/test',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expired-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
    "\n",
    "model.compile(optimizer=lr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "industrial-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_test = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "practical-crossing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 25s 2s/step - loss: 1.7027 - accuracy: 0.4486 - val_loss: 0.1233 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 6s 930ms/step - loss: 0.3485 - accuracy: 0.8848 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2486 - accuracy: 0.9267 - val_loss: 0.0364 - val_accuracy: 0.9688\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.1763 - accuracy: 0.9271 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 6s 995ms/step - loss: 0.0697 - accuracy: 0.9733 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0603 - accuracy: 0.9798 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 6s 1s/step - loss: 0.0992 - accuracy: 0.9389 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 0.0532 - accuracy: 0.9739 - val_loss: 5.0587e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0460 - accuracy: 0.9828 - val_loss: 9.0406e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 7s 1000ms/step - loss: 0.0372 - accuracy: 0.9842 - val_loss: 3.4801e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0171 - accuracy: 0.9926 - val_loss: 3.4581e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 1.8868e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0432 - accuracy: 0.9757 - val_loss: 8.5624e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.0473 - accuracy: 0.9760 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0335 - accuracy: 0.9857 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0351 - accuracy: 0.9965 - val_loss: 7.9577e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.7154e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 4.3176e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0119 - accuracy: 0.9931 - val_loss: 5.2022e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0090 - accuracy: 0.9950 - val_loss: 4.3436e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.0249 - accuracy: 0.9945 - val_loss: 2.3232e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0228 - accuracy: 0.9892 - val_loss: 3.5054e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0364 - accuracy: 0.9773 - val_loss: 2.8251e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 9.4249e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 4.8479e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 3.4273e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0191 - accuracy: 0.9880 - val_loss: 6.3922e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 1.1383e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 2.5034e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.7938e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 11s 1s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 9.4414e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.6264e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.5507e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0124 - accuracy: 0.9931 - val_loss: 1.0356e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0130 - accuracy: 0.9930 - val_loss: 1.4600e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0127 - accuracy: 0.9892 - val_loss: 3.4273e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.1292e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.5314e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.6093e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0103 - accuracy: 0.9931 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0083 - accuracy: 0.9961 - val_loss: 1.2479e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 7s 978ms/step - loss: 0.0119 - accuracy: 0.9916 - val_loss: 1.4901e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 6.2212e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.9174e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.9115e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.4901e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0144 - accuracy: 0.9901 - val_loss: 3.6283e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 1.6655e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0067 - accuracy: 0.9961 - val_loss: 1.3411e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.1227e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0404 - accuracy: 0.9748 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0498 - accuracy: 0.9878 - val_loss: 2.9354e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 0.0237 - accuracy: 0.9945 - val_loss: 4.3802e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0102 - accuracy: 0.9928 - val_loss: 1.1029e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 3.0112e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 5.7404e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.4177e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1399e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0091 - accuracy: 0.9933 - val_loss: 2.7603e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 7s 970ms/step - loss: 0.0270 - accuracy: 0.9948 - val_loss: 3.6784e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 6s 939ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0366 - accuracy: 0.9919 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 4.8429e-08 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 7s 981ms/step - loss: 7.6174e-04 - accuracy: 1.0000 - val_loss: 9.1145e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.9657e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.9723e-04 - accuracy: 1.0000 - val_loss: 4.4030e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0920e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7471e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.2181e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0132 - accuracy: 0.9906 - val_loss: 1.1176e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.0783e-04 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0803e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.7422e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0122 - accuracy: 0.9944 - val_loss: 1.1176e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 1.8626e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0034 - accuracy: 0.9972 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.2119e-04 - accuracy: 1.0000 - val_loss: 2.6822e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.1455e-04 - accuracy: 1.0000 - val_loss: 2.0489e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8498e-04 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 2.7122e-04 - accuracy: 1.0000 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 7s 997ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.4326e-04 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2131e-04 - accuracy: 1.0000 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2289e-04 - accuracy: 1.0000 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0132e-04 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.2242e-04 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.7334e-05 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.8966e-04 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.7620e-04 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.0266e-04 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.7984e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.3192e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0056 - accuracy: 0.9960 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0206 - accuracy: 0.9829 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 7s 975ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.0059 - accuracy: 0.9948 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 938ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.3724e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0050 - accuracy: 0.9960 - val_loss: 3.7253e-08 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.3872e-04 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.1142e-04 - accuracy: 1.0000 - val_loss: 1.8551e-06 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9988e-04 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.6427e-04 - accuracy: 1.0000 - val_loss: 1.8626e-06 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.3011e-04 - accuracy: 1.0000 - val_loss: 1.5422e-06 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4007e-06 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3523e-06 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9851e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 0.9964 - val_loss: 2.9802e-07 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0066 - accuracy: 0.9945 - val_loss: 1.7509e-07 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 7s 986ms/step - loss: 4.7815e-05 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 7s 963ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2293e-07 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.2679e-05 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.3464e-05 - accuracy: 1.0000 - val_loss: 1.2666e-07 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 6.6430e-04 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.4503e-04 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 4.9847e-04 - accuracy: 1.0000 - val_loss: 5.5879e-08 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.0344e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0042 - accuracy: 0.9964 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 4.5740e-04 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.1576e-04 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.1041e-04 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0134 - accuracy: 0.9918 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2428e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.8677e-04 - accuracy: 1.0000 - val_loss: 7.0780e-08 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 9.3132e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 4.7307e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 7s 955ms/step - loss: 0.0093 - accuracy: 0.9988 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 7s 954ms/step - loss: 1.9231e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.9941e-05 - accuracy: 1.0000 - val_loss: 1.1176e-07 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0046 - accuracy: 0.9962 - val_loss: 1.1548e-07 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0063 - accuracy: 0.9951 - val_loss: 9.6857e-08 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 7s 948ms/step - loss: 4.3658e-04 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.0471e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0119 - accuracy: 0.9891 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.0566e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.8425e-05 - accuracy: 1.0000 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.1663e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0091 - accuracy: 0.9938 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 4.9947e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.0045 - accuracy: 0.9961 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 1s/step - loss: 2.4459e-05 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 1.8928e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 3.0930e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.1782e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.2394e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0040 - accuracy: 0.9964 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.1076e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0037 - accuracy: 0.9972 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.4918e-05 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 7s 1000ms/step - loss: 2.2548e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0040 - accuracy: 0.9963 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5754e-05 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0085 - accuracy: 0.9930 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.4165e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 7.4780e-06 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0177 - accuracy: 0.9892 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.8818e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3485e-05 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.8804e-05 - accuracy: 1.0000 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0061 - accuracy: 0.9944 - val_loss: 4.4703e-08 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0120 - accuracy: 0.9892 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8700e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0048 - accuracy: 0.9961 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.7589e-04 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 4.5852e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 7s 982ms/step - loss: 6.7820e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0123 - accuracy: 0.9887 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0034 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0038 - accuracy: 0.9961 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 0.9981 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.3877e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0164 - accuracy: 0.9848 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.2052e-05 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.5206e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1568e-05 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.7932e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0084 - accuracy: 0.9919 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.2853e-04 - accuracy: 1.0000 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.9546e-05 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.8353e-05 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 6.9779e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 2.6098e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 2.5919e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 7.9243e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.1349e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 10s 1s/step - loss: 9.5457e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0027 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.7329e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.6140e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0278 - accuracy: 0.9892 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8229e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0046 - accuracy: 0.9945 - val_loss: 1.4901e-07 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 4.4192e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0260 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0011 - accuracy: 0.9988 - val_loss: 0.0402 - val_accuracy: 0.9688\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 0.9945 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.7987e-05 - accuracy: 1.0000 - val_loss: 1.0725e-04 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.3946e-05 - accuracy: 1.0000 - val_loss: 1.8561e-05 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 4.5285e-04 - accuracy: 1.0000 - val_loss: 8.0791e-06 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1060e-04 - accuracy: 1.0000 - val_loss: 5.0883e-06 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5542e-04 - accuracy: 1.0000 - val_loss: 4.8128e-06 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 6.0843e-05 - accuracy: 1.0000 - val_loss: 3.5984e-06 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 3.5383e-04 - accuracy: 1.0000 - val_loss: 2.9242e-06 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3544e-05 - accuracy: 1.0000 - val_loss: 2.5443e-06 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 1.9957e-06 - accuracy: 1.0000 - val_loss: 2.3096e-06 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 12s 2s/step - loss: 1.9040e-06 - accuracy: 1.0000 - val_loss: 2.2053e-06 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 1.4265e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.5877e-04 - accuracy: 1.0000 - val_loss: 2.1308e-06 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2388e-06 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.4265e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 5.4847e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.1068e-05 - accuracy: 1.0000 - val_loss: 1.9669e-06 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.8333e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0032 - accuracy: 0.9972 - val_loss: 1.6279e-06 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 5.7936e-06 - accuracy: 1.0000 - val_loss: 1.6540e-06 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 9.7601e-07 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0034 - accuracy: 0.9975 - val_loss: 3.5390e-07 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 0.9945 - val_loss: 1.8626e-07 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 5.9670e-06 - accuracy: 1.0000 - val_loss: 1.4156e-07 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0075 - accuracy: 0.9930 - val_loss: 1.2293e-07 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.8011e-04 - accuracy: 1.0000 - val_loss: 9.6857e-08 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0515e-05 - accuracy: 1.0000 - val_loss: 8.1956e-08 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.2754e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 7s 966ms/step - loss: 8.0945e-05 - accuracy: 1.0000 - val_loss: 7.0780e-08 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "7/7 [==============================] - 7s 988ms/step - loss: 1.0331e-04 - accuracy: 1.0000 - val_loss: 6.7055e-08 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.6197e-05 - accuracy: 1.0000 - val_loss: 7.0780e-08 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 7s 944ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 7.4506e-08 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 7s 947ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 7s 983ms/step - loss: 1.5328e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 7s 945ms/step - loss: 6.3171e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 7s 954ms/step - loss: 1.2346e-04 - accuracy: 1.0000 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 7s 968ms/step - loss: 0.0122 - accuracy: 0.9892 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 6s 1s/step - loss: 9.9505e-05 - accuracy: 1.0000 - val_loss: 8.5682e-08 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 7s 964ms/step - loss: 0.0066 - accuracy: 0.9945 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 7s 972ms/step - loss: 2.1592e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "7/7 [==============================] - 6s 929ms/step - loss: 1.8412e-05 - accuracy: 1.0000 - val_loss: 1.2666e-07 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 7s 952ms/step - loss: 3.2984e-04 - accuracy: 1.0000 - val_loss: 1.3038e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/500\n",
      "7/7 [==============================] - 7s 937ms/step - loss: 0.0085 - accuracy: 0.9931 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.2643e-05 - accuracy: 1.0000 - val_loss: 1.1548e-07 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 7s 970ms/step - loss: 2.8391e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "7/7 [==============================] - 6s 934ms/step - loss: 0.0020 - accuracy: 0.9981 - val_loss: 9.6857e-08 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 6s 934ms/step - loss: 0.0146 - accuracy: 0.9866 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0104 - accuracy: 0.9897 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 6s 926ms/step - loss: 7.0219e-04 - accuracy: 1.0000 - val_loss: 2.6077e-08 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.5611e-04 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.8497e-05 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 7s 983ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.0043 - accuracy: 0.9961 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 7s 939ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 6s 926ms/step - loss: 0.0073 - accuracy: 0.9933 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0019 - accuracy: 0.9982 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 6s 942ms/step - loss: 0.0020 - accuracy: 0.9981 - val_loss: 1.0431e-07 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 6s 935ms/step - loss: 1.2998e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4605e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.3481e-08 - accuracy: 1.0000 - val_loss: 1.0803e-07 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0064 - accuracy: 0.9965 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2241e-05 - accuracy: 1.0000 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0107 - accuracy: 0.9919 - val_loss: 7.0780e-08 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.9435e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4489e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7257e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0079 - accuracy: 0.9928 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 2.8266e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.8221e-05 - accuracy: 1.0000 - val_loss: 3.3528e-08 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 3.2742e-04 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0037 - accuracy: 0.9948 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 0.2320 - val_accuracy: 0.9688\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0183 - accuracy: 0.9828 - val_loss: 9.2233e-05 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0070 - accuracy: 0.9961 - val_loss: 2.7940e-07 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.5054e-04 - accuracy: 1.0000 - val_loss: 4.6190e-06 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 0.0276 - accuracy: 0.9961 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0453 - accuracy: 0.9893 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.5554e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 7s 979ms/step - loss: 5.0455e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 6s 933ms/step - loss: 4.6203e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 7s 965ms/step - loss: 0.0125 - accuracy: 0.9892 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3395e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "7/7 [==============================] - 7s 942ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 7s 953ms/step - loss: 0.0084 - accuracy: 0.9928 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 7s 941ms/step - loss: 1.4836e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.0929e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.0587e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.3498e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.7769e-05 - accuracy: 1.0000 - val_loss: 6.7055e-08 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.5976e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.3451e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.8731e-06 - accuracy: 1.0000 - val_loss: 3.0195e-04 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.1921e-07 - accuracy: 1.0000 - val_loss: 4.5772e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 4.5256e-04 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 7s 988ms/step - loss: 1.3303e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 7s 978ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.8619e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.9922e-05 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 7s 977ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.5431e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.9054e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.0732e-07 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0115 - accuracy: 0.9893 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 7s 987ms/step - loss: 6.1326e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.0303e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 7s 981ms/step - loss: 1.7481e-07 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0028 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0119 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.6752e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 0.0254 - accuracy: 0.9779 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 7s 981ms/step - loss: 3.0869e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.7064e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 7s 944ms/step - loss: 0.0012 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 7s 946ms/step - loss: 4.3596e-06 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.5361e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 7s 980ms/step - loss: 3.3654e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 7s 956ms/step - loss: 1.0358e-07 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.7809e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.5017e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 0.0091 - accuracy: 0.9953 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 7s 963ms/step - loss: 0.0049 - accuracy: 0.9957 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0048 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 7s 950ms/step - loss: 2.5623e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 3.6752e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 7s 977ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0042 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.1831e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 7s 950ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 6s 936ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "7/7 [==============================] - 7s 983ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.5157e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.9721e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1752e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 7s 978ms/step - loss: 0.0141 - accuracy: 0.9919 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.4060e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0733e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0096e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 7s 944ms/step - loss: 1.2612e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 7s 965ms/step - loss: 2.8031e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "7/7 [==============================] - 7s 944ms/step - loss: 0.0152 - accuracy: 0.9887 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 7s 986ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2712e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 6s 928ms/step - loss: 1.4227e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 7s 962ms/step - loss: 3.4495e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 7s 969ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 6s 921ms/step - loss: 1.3009e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 6s 921ms/step - loss: 1.8243e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 7s 952ms/step - loss: 1.3949e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 6s 992ms/step - loss: 5.4909e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 7s 944ms/step - loss: 5.8539e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 7s 927ms/step - loss: 1.4894e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 6s 936ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 6s 927ms/step - loss: 2.6579e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 6s 922ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 7s 950ms/step - loss: 0.0019 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 7s 939ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 6s 934ms/step - loss: 0.0063 - accuracy: 0.9949 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.9938e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 1.0752e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 7s 940ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 6s 930ms/step - loss: 4.9398e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 7s 945ms/step - loss: 2.5753e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 7s 942ms/step - loss: 1.6667e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 6s 941ms/step - loss: 1.2608e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.3722e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 6s 936ms/step - loss: 1.0144e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 9.6269e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.5437e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 6s 930ms/step - loss: 5.9476e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0054 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 6s 938ms/step - loss: 0.0089 - accuracy: 0.9919 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 7s 960ms/step - loss: 0.0087 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 6s 925ms/step - loss: 1.0154e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 6s 921ms/step - loss: 6.9709e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 7s 982ms/step - loss: 1.9614e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.0000e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 6s 918ms/step - loss: 0.0069 - accuracy: 0.9945 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 7s 957ms/step - loss: 0.0239 - accuracy: 0.9880 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 6s 924ms/step - loss: 1.9376e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 6s 992ms/step - loss: 0.0049 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.3963e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 7s 997ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 6s 989ms/step - loss: 1.3690e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 7s 935ms/step - loss: 9.4861e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 6s 924ms/step - loss: 1.2023e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 7s 976ms/step - loss: 0.0095 - accuracy: 0.9931 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 6s 1s/step - loss: 3.6415e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "7/7 [==============================] - 6s 929ms/step - loss: 6.9752e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 7s 940ms/step - loss: 5.2441e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 930ms/step - loss: 6.2050e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 7s 967ms/step - loss: 8.6822e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 6s 920ms/step - loss: 3.1841e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "7/7 [==============================] - 6s 932ms/step - loss: 2.0508e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2617e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 6s 936ms/step - loss: 2.1952e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0049 - accuracy: 0.9961 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 6s 913ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 6s 922ms/step - loss: 0.0120 - accuracy: 0.9891 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.1041e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 6s 919ms/step - loss: 5.2301e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 7s 957ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 6s 942ms/step - loss: 3.3374e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 7s 939ms/step - loss: 1.1083e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 7s 962ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 6s 925ms/step - loss: 5.3338e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "7/7 [==============================] - 6s 928ms/step - loss: 0.0036 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 7s 946ms/step - loss: 4.7576e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 6s 915ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 7s 970ms/step - loss: 8.0197e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 6s 918ms/step - loss: 2.6950e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 6s 912ms/step - loss: 1.0702e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 7s 952ms/step - loss: 6.6540e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 6s 913ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 7s 952ms/step - loss: 5.3384e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 3.6845e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 7s 950ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 7s 945ms/step - loss: 2.6159e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 6s 923ms/step - loss: 3.7001e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 7s 940ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.5821e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 7s 925ms/step - loss: 3.2434e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 6s 921ms/step - loss: 2.5849e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.8899e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 6s 927ms/step - loss: 5.5330e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 6s 921ms/step - loss: 1.1812e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 7s 934ms/step - loss: 2.2140e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 6s 913ms/step - loss: 5.3599e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "7/7 [==============================] - 7s 963ms/step - loss: 6.2767e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 6s 920ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 6s 924ms/step - loss: 1.9592e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 7s 948ms/step - loss: 3.8822e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 6s 917ms/step - loss: 1.5978e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 7s 953ms/step - loss: 7.3431e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 7s 981ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 6s 913ms/step - loss: 1.9810e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 7s 937ms/step - loss: 1.6029e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 7s 926ms/step - loss: 1.9225e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit_generator(generator=train_generator,\n",
    "#                    steps_per_epoch=step_size_train,\n",
    "#                    epochs=epochs,\n",
    "#                    validation_data=test_generator,\n",
    "#                    validation_steps=step_size_test)\n",
    "history = model.fit(train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_generator,\n",
    "                   validation_steps=step_size_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9187df",
   "metadata": {},
   "source": [
    "<h3>Resultados:</h3>\n",
    "<hr />\n",
    "<div>\n",
    "  Primeiramente, é feito o cálculo da acurácia do treino e do teste, que podem\n",
    "  ser vistas abaixo.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "therapeutic-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 868ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Acurácia de treino: 1.000 \n",
      "Acurácia de teste: 1.000 \n"
     ]
    }
   ],
   "source": [
    "loss_train, train_acc = model.evaluate(train_generator, steps=step_size_train)\n",
    "loss_test, test_acc = model.evaluate_generator(test_generator, steps=step_size_test)\n",
    "print('Acurácia de treino: %.3f ' % (train_acc))\n",
    "print('Acurácia de teste: %.3f ' % (test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79578af2",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "  Observando os números acima para a acurácia, podemos ver que o resultado foi um número muito atípico, no caso <i>1.000</i>, que representa 100% de acurácia no treino e no teste. Quando isso acontece, geralmente se dá o nome de <i>overfit</i> (ou <i>overfitting</i>), que é quando um modelo estatístico se ajusta bem demais ao conjunto de dados observado, mas se mostra ineficaz para prever novos resultados. Os gráficos abaixo ilustram bem esse comportamento:\n",
    "<img src=\"https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png\" width=\"700\"/>\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  O gráfico seguinte apresenta a taxa de perda de treino e de teste:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "contained-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnMElEQVR4nO3deXxcdb3/8ddnZrI0STeaUNumQNmUighYNis/QASKIKAisuld8Naf96L+fnrZ7hVw4SpetYIKCCL2IlpF8GJ/UmxZCr0spQstdKNtCl3SLWnaptkzmfn8/jgn6SSZNGlJmp7k/Xw80plz5sycz5lO3vPN95zzPebuiIhI9MX6uwAREekdCnQRkQFCgS4iMkAo0EVEBggFuojIAKFAFxEZIBToIvvBzF40sy/1dx0i2SjQZUAys/Vm1mBmtWa23cymm1lRf9cl0pcU6DKQfcrdi4BTgUnAt3r6RAvo90MiRR9YGfDcfTPwDHCimZ1pZq+a2W4ze9PMzm1dLuxO+Q8zewWoB442swvM7G0zqzazXwCWsfwxZvaCmVWZ2Q4z+52ZjTi4WyeylwJdBjwzGw98EtgKPA3cBRwG/CvwpJmVZCz+BWAqMBSoBv5M0LIvBtYBkzNfGvgBMBY4ARgPfLsPN0VknxToMpA9ZWa7gZeBl4ByYJa7z3L3tLs/CywiCPtW0919hbu3ABcDK9z9CXdPAvcA21oXdPcyd3/W3ZvcvRKYBpxzULZMJItEfxcg0oeucPfnWifM7H7gc2b2qYxlcoC5GdObMu6PzZx2dzeztmkzGw3cC5xN0KKPAbt6dQtE9oNa6DKYbAJ+6+4jMn4K3f3ujGUyhx/dStCNAgQ7SjOnge+Hy3/I3YcB15PRxy5ysCnQZTB5DPiUmV1kZnEzyzezc82stIvlnwY+aGafMbME8DXgfRmPDwVqgWozGwfc1KfVi3RDgS6DhrtvAi4H/g2oJGix30QXvwfuvgP4HHA3UAUcB7ySsch3CA6JrCYI/z/3Ve0iPWG6wIWIyMCgFrqIyAChQBcRGSC6DXQze8TMKsxseRePX2dmb5nZsvAMvA/3fpkiItKdnrTQpwNT9vH4u8A57v4h4HvAQ71Ql4iI7KduTyxy93lmdtQ+Hn81Y3I+0NUhYO0UFxf7UUd1+bIiIpLF4sWLd7h7SbbHevtM0RsIBkHKysymEoyTwRFHHMGiRYt6efUiIgObmW3o6rFe2ylqZucRBPotXS3j7g+5+yR3n1RSkvULRkREDlCvtNDN7CTgYeBid6/qjdcUEZH9855b6GZ2BMEZcl9w9zXvvSQRETkQ3bbQzWwGcC5QbGblwJ0EI9Th7r8E7gBGAfcHYxfR4u6T+qpgERkckskk5eXlNDY29ncp/SI/P5/S0lJycnJ6/JyeHOVyTTePfwnQRXNFpFeVl5czdOhQjjrqKMLG4qDh7lRVVVFeXs6ECRN6/DydKSoih6TGxkZGjRo16MIcwMwYNWrUfv91okAXkUPWYAzzVgey7ZEL9NXbapg2ZzU7apv6uxQRkUNK5AJ9bUUNP3uhjJ11zf1diogMYLt37+b+++/fr+ds2bKFK6+8so8q6l7kAt3CK3xpGHcR6UtdBXpLS0uXzxk7dixPPPFEX5a1T9EL9LBbyVGii0jfufXWW1m3bh0nn3wyp512GmeffTaXXXYZEydOJJVKcdNNN3Haaadx0kkn8eCDDwKwfv16TjzxRACmT5/OZz7zGaZMmcJxxx3HzTff3PbaM2bM4EMf+hAnnngit9zS5cn1+623x3Lpc627CdRCFxk8vvP/VrByy55efc2JY4dx56c+2OXjd999N8uXL2fp0qW8+OKLXHLJJSxfvpwJEybw0EMPMXz4cBYuXEhTUxOTJ0/mwgsv7LQjc+nSpSxZsoS8vDze//7389WvfpV4PM4tt9zC4sWLGTlyJBdeeCFPPfUUV1xxxXvepui20BXoInIQnX766W3HhM+ZM4dHH32Uk08+mTPOOIOqqirWrl3b6Tnnn38+w4cPJz8/n4kTJ7JhwwYWLlzIueeeS0lJCYlEguuuu4558+b1So3Ra6GHia4uF5HBY18t6YOlsLCw7b678/Of/5yLLrqo3TLr169vN52Xl9d2Px6P77P/vTdEr4Ue3qqFLiJ9aejQodTU1GR97KKLLuKBBx4gmUwCsGbNGurq6nr0uqeffjovvfQSO3bsIJVKMWPGDM4555xeqTm6LXQFuoj0oVGjRjF58mROPPFEhgwZwujRo9se+9KXvsT69es59dRTcXdKSkp46qmnevS6Y8aM4e677+a8887D3bnkkku4/PLLe6Vm835KxkmTJvmBXODiuZXb+dKji5h542ROKh3R+4WJyCFh1apVnHDCCf1dRr/K9h6Y2eKuBkCMXpeLdoqKiGQV3UDv3zJERA450Qv0tjNFFekiIpkiF+iohS4iklXkAl2HLYqIZBe9QG87tVaJLiKSKXqBHt6qhS4ifelAhs9tdc8991BfX9/LFXUveoGuPnQROQiiGOjRO1NU46GLyEGQOXzuBRdcwOGHH87jjz9OU1MTn/70p/nOd75DXV0dV111FeXl5aRSKW6//Xa2b9/Oli1bOO+88yguLmbu3LnMmTOHO++8k6amJo455hh+85vfUFRU1Os1Ry7QY20nFinRRQaNZ26Fbct69zXf9yG4+O4uH84cPnfOnDk88cQTLFiwAHfnsssuY968eVRWVjJ27FiefvppAKqrqxk+fDjTpk1j7ty5FBcXs2PHDu666y6ee+45CgsL+eEPf8i0adO44447end7iGCgt3aip5XnInKQzJkzhzlz5nDKKacAUFtby9q1azn77LP55je/yS233MKll17K2Wef3em58+fPZ+XKlUyePBmA5uZmzjrrrD6pM3KB3tblol50kcFjHy3pg8Hdue222/jyl7/c6bE33niDWbNm8a1vfYvzzz+/U8vb3bnggguYMWNGn9cZ2Z2iynMR6UuZw+dedNFFPPLII9TW1gKwefNmKioq2LJlCwUFBVx//fXcdNNNvPHGG52ee+aZZ/LKK69QVlYGQF1dHWvWrOmTmrttoZvZI8ClQIW7n5jlcQPuBT4J1AN/7+5v9HahbesLb5XnItKXMofPvfjii7n22mvbukqKiop47LHHKCsr46abbiIWi5GTk8MDDzwAwNSpU5kyZQpjx45l7ty5TJ8+nWuuuYampiYA7rrrLo4//vher7nb4XPN7H8BtcCjXQT6J4GvEgT6GcC97n5Gdys+0OFzF7y7k6sefI3HbjiDjx1XvN/PF5Fo0PC5fTB8rrvPA3buY5HLCcLe3X0+MMLMxuxHzftl73HoaqOLiGTqjT70ccCmjOnycF4nZjbVzBaZ2aLKysoDWpnOFBURye6g7hR194fcfZK7TyopKTmg19CZoiKDx2A+3+RAtr03An0zMD5jujSc10c0HrrIYJCfn09VVdWg/F13d6qqqsjPz9+v5/XGcegzgRvN7A8EO0Wr3X1rL7xuVmqhiwwOpaWllJeXc6Dds1GXn59PaWnpfj2nJ4ctzgDOBYrNrBy4E8gBcPdfArMIjnApIzhs8R/2q4L91NqHrkQXGdhycnKYMGFCf5cRKd0Gurtf083jDvxLr1XUjdbx0HWUi4hIe5E7U3Tv4Fz9W4eIyKEmcoHeOpaLBucSEWkveoGu4XNFRLKKXKC3UpyLiLQXuUA39aGLiGQVvUDXeIsiIllFL9DVQhcRySq6gd6/ZYiIHHKiF+htY7n0cyEiIoeY6AW6xkMXEckqeoEe3qqFLiLSXvQCXX3oIiJZRS7QNR66iEh2kQt0Dc4lIpJd5AJdw+eKiGQXvUAPb9VCFxFpL3qBri4XEZGsohforTtF+7kOEZFDTfQCXeOhi4hkFblAb6U4FxFpL3KBbho9V0QkqwgGug5bFBHJJnqBHt6qC11EpL3oBbrGchERySp6ga7x0EVEsopcoMc0HrqISFY9CnQzm2Jmq82szMxuzfL4EWY218yWmNlbZvbJ3i+1dWXBTVp5LiLSTreBbmZx4D7gYmAicI2ZTeyw2LeAx939FOBq4P7eLrStHnTuv4hINj1poZ8OlLn7O+7eDPwBuLzDMg4MC+8PB7b0XontaaeoiEh2PQn0ccCmjOnycF6mbwPXm1k5MAv4arYXMrOpZrbIzBZVVlYeQLk6bFFEpCu9tVP0GmC6u5cCnwR+a2adXtvdH3L3Se4+qaSk5IBW1HZikRJdRKSdngT6ZmB8xnRpOC/TDcDjAO7+GpAPFPdGgR3pzH8Rkex6EugLgePMbIKZ5RLs9JzZYZmNwPkAZnYCQaAfWJ9KNzQeuohIdt0Guru3ADcCs4FVBEezrDCz75rZZeFi3wT+yczeBGYAf+991Cei8dBFRLJL9GQhd59FsLMzc94dGfdXApN7t7QuaDx0EZGsInemaNvwuSIi0k70Aj28VQNdRKS96AW6xkMXEckqcoEe01EuIiJZRS7QW49y0eBcIiLtRS/QNXyuiEhWkQv0VupyERFpL3KBrsMWRUSyi16go8G5RESyiV6g6ygXEZGsohfo4a3yXESkvegFett46P1ciIjIISZ6gR7e6rBFEZH2ohfo6kMXEckqgoGu8dBFRLKJXKC3URNdRKSdSAZ6zDSWi4hIR5EMdDPTTlERkQ6iGeiox0VEpKNoBrppp6iISEfRDHRMLXQRkQ4iGeiYTiwSEekokoFuoD4XEZEOohno6kMXEekkmoGOaTx0EZEOehToZjbFzFabWZmZ3drFMleZ2UozW2Fmv+/dMjuuS4ctioh0lOhuATOLA/cBFwDlwEIzm+nuKzOWOQ64DZjs7rvM7PC+KhjC49D7cgUiIhHUkxb66UCZu7/j7s3AH4DLOyzzT8B97r4LwN0rerfM9sx02KKISEc9CfRxwKaM6fJwXqbjgePN7BUzm29mU7K9kJlNNbNFZraosrLywCqmtYWuRBcRydRbO0UTwHHAucA1wK/MbETHhdz9IXef5O6TSkpKDnhl6kMXEemsJ4G+GRifMV0azstUDsx096S7vwusIQj4PhF0uSjRRUQy9STQFwLHmdkEM8sFrgZmdljmKYLWOWZWTNAF807vldmejkMXEems20B39xbgRmA2sAp43N1XmNl3zeyycLHZQJWZrQTmAje5e1VfFa3RFkVEOuv2sEUAd58FzOow746M+w58I/zpcxoPXUSks4ieKaoWuohIR9EMdPWhi4h0EslAR+Ohi4h0EslAN42fKyLSSTQDHfWhi4h0FM1A15miIiKdRDPQ0WGLIiIdRTLQY2qhi4h0EslANzPSCnQRkXYiGeig4XNFRDqKZKCbLlkkItJJZANdeS4i0l40Ax2Nhy4i0lE0A10tdBGRTqIZ6OiwRRGRjqIZ6GZqoYuIdBDNQAf1oYuIdBDJQEd96CIinUQy0DV6rohIZ9EMdF1TVESkk0gGugbnEhHpLJKBbhhpJbqISDvRDHS10EVEOolkoIP2iYqIdBTJQDcztdBFRDqIZqADaqOLiLTXo0A3sylmttrMyszs1n0s91kzczOb1HslZluP+tBFRDrqNtDNLA7cB1wMTASuMbOJWZYbCnwdeL23i+y8LrXPRUQ66kkL/XSgzN3fcfdm4A/A5VmW+x7wQ6CxF+vLSuOhi4h01pNAHwdsypguD+e1MbNTgfHu/vS+XsjMpprZIjNbVFlZud/F7n0dtdBFRDp6zztFzSwGTAO+2d2y7v6Qu09y90klJSUHvk7Uhy4i0lFPAn0zMD5jujSc12oocCLwopmtB84EZvbpjlGNhy4i0klPAn0hcJyZTTCzXOBqYGbrg+5e7e7F7n6Uux8FzAcuc/dFfVIxGg9dRCSbbgPd3VuAG4HZwCrgcXdfYWbfNbPL+rrAbDQ4l4hIZ4meLOTus4BZHebd0cWy5773svZNw+eKiHQW2TNF1UIXEWkvmoGuLhcRkU6iGeioy0VEpKNIBjpqoYuIdBLJQDd0pqiISEfRDHQluohIJ9EMdPWhi4h0Es1AVx+6iEgn0Q30/i5CROQQE81A13joIiKdRDLQc+JGcyrd32WIiBxSIhnoBXkJ6ptT/V2GiMghJZKBXpgbp0GBLiLSTiQDvSA3QV1TS3+XISJySIlooMepb05px6iISIZIBnphXoKWtGvHqIhIhkgGekFuHED96CIiGSId6HUKdBGRNhEN9ODKefXaMSoi0iaSgV6YF7TQdSy6iMhekQz0ITlBC72uWS10EZFWkQz0thZ6k1roIiKtIhnobX3oSQW6DBLzfgQzrunvKuQQl+jvAg5E61Eu2ikqg8YLd/V3BRIBkWyhF+a29qGrhS4i0qpHgW5mU8xstZmVmdmtWR7/hpmtNLO3zOx5Mzuy90vda4ha6CIinXQb6GYWB+4DLgYmAteY2cQOiy0BJrn7ScATwH/2dqGZchMxcuMx9aGLiGToSQv9dKDM3d9x92bgD8DlmQu4+1x3rw8n5wOlvVtmZ0Ny42qhi4hk6EmgjwM2ZUyXh/O6cgPwTLYHzGyqmS0ys0WVlZU9rzKLwty4+tBFRDL06k5RM7semAT8KNvj7v6Qu09y90klJSXvaV0FeQkNziUikqEnhy1uBsZnTJeG89oxs08A/w6c4+5NvVNe1wpy4zpTVEQkQ09a6AuB48xsgpnlAlcDMzMXMLNTgAeBy9y9ovfL7KwgN64zRUVEMnQb6O7eAtwIzAZWAY+7+woz+66ZXRYu9iOgCPiTmS01s5ldvFyvKcxNUJ9UC10GmbQu6iJd69GZou4+C5jVYd4dGfc/0ct1dasgL0H9DrXQZZBJt0Ast7+rkENUJM8UBSjIUR+6DEJpfeala9EN9Dz1ocsgpECXfYhsoAd96Cncvb9LETl4FOiyD5EN9CG5cVJpp6lFO4lkEEnrr1LpWmQDvTBXl6GTQUgtdNmHyAZ6QV54kQvtGJXBxNWAka5F7wIXyQaoraAwEfSdq4Uug4pa6LIP0Wuhv/003HsSxU3B6AN1GnFRBhP1ocs+RC/QcwsBKLRguBgN0CWDilrosg/RC/ScAgAKYklAl6GTQUaBLvsQvUAPW+hDvBHQTlEZZBTosg/RC/ScIQDkE3S51OlsURlMFOiyDxEM9KDLpTXQH5u/gfvmlvVnRSJ9K/NsaO0UlX2IXqCHXS656QYAVm7dw49mr+7PikT6VmaIq4Uu+xC9QA+7XOItDeQmole+yH7LDHG10GUfopeIYZcLyYa20/8Bmg/ymC7/vaSc2Su2HdR1yiDVLtDVQpeuRS/QY3FI5ENzHSMK9g70v7uh+aCW8X//+CZf/u3ig7pOGaTUQpceil6gQ9DtkqynpCivbdbu+uRBW31N48Fbl4j60KWnIhrohdBcT/HQvS30XXVBC722qYV0um/HSF+zvbZPX1+kHXW5SA9FM9BzCyBZz2dPLW2btau+mWQqzYl3zub2vyzv09Wv3V7Tp68v0o4CXXoomoGeEwT6+SeM5vlvngPArvokO2qDY9N/9/rGPl39hp31AOTpKBs5GBTo0kPRTKScAqguB3fGjyygKC/Bko272L6nqW2Rvuzn3hgGelNLmlQfd+9IL3KHWTfDhtf6u5L9kzkGunaKyj5EM9DHnAQVK2H1LHITMS784GieWb6NTWHQArxVXt3uKau27qGqtqnjKx2Q8oz11Gr43shINtbAggfhN1P6u5T902Gn6GvrqvjlS+v6rx45ZEUz0D/x7eB2W9BXfsXJ46hpbOGPCze1LbJ4w662++m0c/G9/8NnH3i1V1a/cWc9iZgBewM9mUq37ZiVQ9O/PfpCf5dwYDK6WV5eu51rfjWfu595m4qaxn4sSg5F0Qz0nCFQNBr2lAPw0WNGUVyUx8tlOwA49vAipj27hhVbglb6qm17AFhfVZ/99fZDTWOSXfVJJo4dBuy9wMatTy7jlO89y7dnrtAY7Yeodevf7e8SDkxGoM96s7zt/vOrKg56Ke5OY1Kf70NVNAMdYNi4oB8dSMRj/OuFxwMwelgev7j2FPISMaY+upgv/Pp1LvnZy21Pc3cWb9hJ+a7s4f76O1UkU53POq1pTDJvTSWbdgZjyJzwvmHh/OCX7ck3glqmv7qevyzd3Pa8VNp5p3LvYY7T5qzm7mfe7vFmLt20m1+/3D6ImlpSXPur+by2rqrT8o3JVK/069/9zNtMfXRRj5ZtTKb6tetp7tsVbKvO3lpNpZ2W8P+z2KqzLnPIywj0OHvD9M1Nuw96Kb97fSMfuP1vPLdy+0Ff9/5YtH4n1Qfx3JRDRY8C3cymmNlqMyszs1uzPJ5nZn8MH3/dzI7q9Uo7Gl4KVWWQCj7snz9tPL//pzN4+AuT+EBRI1/7+LFs3t3A/6zd0e5px/zbLD77wGt88ZEFNCZTVNU28Y/TF/Lb+RtYtH4nn39oPrc88RYrtlTz8R+/yP+srQTg639YyhcfWcC/P7UMgBPGDAXgmWVb2wL7kth8PmjreeHtirZj4R95+V0+/pOX+PHs1bg7P3uhjF++tI7V24JDH1uyfHkAvFq2g511zVxx3yt8768rqaxp4s6/LOfVdTs48/vP8+q6qk6Bm0ylOedHc/n4T16kuqH9h7mmMcl9c8s6fcjrm1u47c/LOn3B/fKldcxZuZ1kKs3STbuZ+eYWgKytsyvue4VJdz2bdTs6akml+fnza9myu4Gt1cGX4+OLNnUbEOm08+BL6zrVuacxyT9MX8i1D8/P+rx//t1iPvbDubg7o2xPj2rMZvnmaq568LVuuzlmLdvK9/66Muvz/+PplWze3dA2b/GGnfxpUftuwsz9PD+evZpvPbWsXR96IiPQyyq6Ph/ilbIdXP3Qa/tsTf9t+VbWZTQ2nl+1nV/Ne4eVW/bwX6+u58dZBr2btyb4ffh5D0Y4XbJxFz94ZhXuzl+WbmZ3fTPuzr3PrWXR+p3dPn9/PLNsK799bT0AG6vqufKXr3Hzk2+yq66ZVVv30JJKc/+LZfvVTVXdkOSBF9dlHVZk8+4GFm/Yxbw1lbxatiPLs9srq6hlWXk163fU9Xj9B6Lbi0SbWRy4D7gAKAcWmtlMd8/81N4A7HL3Y83sauCHwOf7ouA2w0th1Uz4yfvh5GuxC77LR48phvkPwK9v5V9Ovo5rb7+HC++Zh7tz28UncNfTK/nIkYexfU8jyzZX84Hb/9b2ci+8XUE87Bf/85LN/HlJ0Mr+/qy3+c5lcV54O/jzdvXGbUy0bZxx5JkAPPzyuzz88ruMopp7cu5jJ0OZsvJufvrcUL58zjHMWBAcQvmLuWU89vqGtvXd8uRb3Hv1yXz6/lf5yjnHcMPHJhCLGRU1jdz8xFu8uLqy3eZOe3Y1MxZs4r9e2/saNU0t/P71jby0poKmljSnHjGy7Uif51Zu57MfKWXTznrWVtTwxobd/GJuGUs27uaGj01g4phhvLFxF/8wfSEQ/CXw8N9N4o6nlvOFs45sW8c/Tl/Y9qX41ze3MGfldj56zCgmH1vMi6srKB1ZwNvhl9NXZyzh7GOLueq08QA8tWQzP31uDeW7Grj+jCPIz4m31fyTZ9cE78u1p3D7U8tJptIcNSoYSXPcyCF8cOxwRg/L489vbGZUUS5jhg9hxoKNvLi6khlTz2TV1j38aVE5E4qDsX3eqWz/i7J4w06eX1XB7BXBF8UlP3uZ89nbQr/oJy/w/StP4SNHjsz68UqnnTUVNfxx4SY+NG4433j8TQAu/dnLfHj8CK4+bTznnzAaCILxyTc285Vzj+Gff/cGEAT4fdedyq1PLuOjx4ziN6++y6adDazYsocvnnUk/zl7dVvNf1u+jTs/9cG2fTzXnXEEXzjrSH4RhubNJwxjWFhXnL3hsq6yljkrtjH91fXEY0ZTS5rbL5nI5t31/O/Hgjpee6eK895/ONPC93toXoKTSoezeXcD33j8TY4uLuRn15zC08u28sCLwY7W/JwYjclgPcOGJBg7YgiXnjQW2Psl8uam3XzlscWcPuEwFm/YRcyMlDsjhuQA0JJy/hh+WVXVNvPE4nKK8hLc+PFj+elza/jpc3DP50/m1XU7GD4kh69/4niK8hI0taSYNmcN1Q1J0u7UNrVQWdPE6RMOY/W2Wq44ZWxbLRD8xX3Pc2u59/m1AHz61FJ+O389ALNXbGf2iqCh8ZPPfZj//NtqlpVX88D1HwGguj7J7xZsYPzIAh6a9w4lQ/P44llHsuDdnUw+tpjrHn4dgN8v2MCj/3gGRxxWwIPz1tGUTPPIK+9S09hCbjxGPGb89Wsf45iSora6kqk0D760jiknjmFIbpxPTHsJgJEFOTz9tbMZO2JI1s/de2Xu+/7z3MzOAr7t7heF07cBuPsPMpaZHS7zmpklgG1Aie/jxSdNmuSLFvXsT/qstq+AhQ/D9pWwKWydFY2G2oyW3vAjSCeC4QEy/xRxnE0760mmgvJyEzHyc+LsaWxh+JAcchJxUg5NyXTb4Y8xM44qLqR+x0aGWQMUjKIpMZTtu+uImTOEJkZZDWlLsCM9lN1e0La+Yfk57Mk4jHJEQS676zvvQDULvlC6+z9pFY8ZqbRjZu2eE4sZ7mBAOnO+WbvpA5GfE++2DzU3EcOdrF1XHXWsvaOceKzT67Rud0cxMxJx63LdJVbNSAsCaV16DB6Lk4gZ6fA9NNs79HhPas+JxzALlnXv/P52nC7MS1DX1NK2zUNy4jSngkNfY2Ed2Z5bGGtmHMEXfGPOSDY35WNmpB0cwzOeg9HudeIxIx6z9zx4XevIps0taYYPyaG2qaXT/0G2/6ueSsRjxML3P/M1chOxTrV3HGU18/GceIyWVJqOn47Mz1nr81Np73H3pJmRiFmX29f6PrdK+96/vhMxoyVjPWZG1fFXceZ1d/Zo3VlqWezuk7I91m0LHRgHbMqYLgfO6GoZd28xs2pgFNDubxEzmwpMBTjiiCN6VHyXRn8QLv1p8Ofo6w9CzVZorA4G7jrzK7DyKah4m1gq81BFa/v3fSUe/OeYETfIT8QoxjF3CD8O7mA1jTS3pBmWn0OiIIfkiIm8VXACJ7GWPHeKSlIQi5OTkwPjJhI7bAIjlz5O7c560u6MKMjlsMJcGqrqyEsEYVhSXMieHbU0NqcYNiSHllRQS8qhJZ0mLxEjLxGnIDfOjtom8nPiNCRTQSssmaa4KI/hQ3LIz4nRkEwFH+K0s6uuuS1MK2ubiBkkYjEKcuNUNyQ5uqSQjVX15OfGqW9qoSXtFOUlKMxL0JhMUdPYQlF+cD/Z4pgFAd6STpMTC9Z17JhhbK1uoCGZwgiCIplKE48Z+Tlx6ptbqA2/KAtz44wZMYTNuxrC7YrT1JJiWH4OO+uayUnESLakyc+Nc3hRHrVNLRTmJYhZ8OduYzLN0aOLaEk5aytqGJqfQ3V9klgs+IVJhMGem4jRmEwRs+AXx4CC3DhF+QlSaae5Jc3Iwly27Wmk4OhjyWvezaiaOtZX1QVBHIaph58NC9+3lnSa3PC9NYPSkcGX9Jaw26QuDJKceIxxI4dQvqsed8iJG2ZGQzJNXk4QSIcV5nL4sHzKKmpoaklzdEkRw/KDX79NuxqorGkiJx58PtPBx5LxhxWwdXcDlak0ftgoSt93OLk122FHHaOH5YVdfU7MjPcNzycRM96prGsLlnjMqA1rzE8En4P65hSxMOCPGFXAxqrgc5qIBV8QMTPGjMinsqaJllQYeAa1YSAZMG70UA7PjbOmogZ3GFWUS21jCxOKC6mqa2bL7oa298/C37nSkUPYtKuetMPQ/ASJmLG7PtlWa23L3kZCcVEeqbRTmJfg8KF5JFPOqq17yInHaE6l22ppVZgb57jRQ3l72x5qk2ly4sb4kQWU72rAw9/lZMrJC78cMjuqcuLBZ+aYkiKSqTSbwiPYWtLBe5KbiJNMpWluCb4kRhbkEDNjV30zMbO297713JTWSHcgN26kPPiCzYnHiMeN4qJcNu1sIGfY6O4z7gD0pIV+JTDF3b8UTn8BOMPdb8xYZnm4THk4vS5cpsvOpffcQhcRGYT21ULvyU7RzcD4jOnScF7WZcIul+FA50MwRESkz/Qk0BcCx5nZBDPLBa4GZnZYZibwd+H9K4EX9tV/LiIiva/bPvSwT/xGYDYQBx5x9xVm9l1gkbvPBH4N/NbMyoCdBKEvIiIHUU92iuLus4BZHebdkXG/Efhc75YmIiL7I7pnioqISDsKdBGRAUKBLiIyQCjQRUQGiG5PLOqzFZtVAhu6XTC7YjqchToIaJsHB23z4PBetvlIdy/J9kC/Bfp7YWaLujpTaqDSNg8O2ubBoa+2WV0uIiIDhAJdRGSAiGqgP9TfBfQDbfPgoG0eHPpkmyPZhy4iIp1FtYUuIiIdKNBFRAaIyAV6dxesjioze8TMKsKLhbTOO8zMnjWzteHtyHC+mdnPwvfgLTM7tf8qP3BmNt7M5prZSjNbYWZfD+cP2O02s3wzW2Bmb4bb/J1w/oTwAutl4QXXc8P5B/8C7H3AzOJmtsTM/hpOD+jtBTCz9Wa2zMyWmtmicF6ffrYjFegZF6y+GJgIXGNmE/u3ql4zHZjSYd6twPPufhzwfDgNwfYfF/5MBR44SDX2thbgm+4+ETgT+Jfw/3Mgb3cT8HF3/zBwMjDFzM4kuLD6T939WGAXwYXXIeMC7MBPw+Wi6OvAqozpgb69rc5z95Mzjjnv28+2u0fmBzgLmJ0xfRtwW3/X1YvbdxSwPGN6NTAmvD8GWB3efxC4JttyUf4B/gJcMFi2GygA3iC4Ru8OIBHOb/ucE1yH4KzwfiJczvq79v3cztIwvD4O/JXg0psDdnsztns9UNxhXp9+tiPVQif7BavH9VMtB8Nod98a3t8GtF5ZdsC9D+Gf1qcArzPAtzvsflgKVADPAuuA3e7eEi6SuV3tLsAOtF6APUruAW4G0uH0KAb29rZyYI6ZLTazqeG8Pv1s9+gCF9L/3N3NbEAeY2pmRcCTwP9x9z1m1vbYQNxud08BJ5vZCOC/gQ/0b0V9x8wuBSrcfbGZndvP5RxsH3P3zWZ2OPCsmb2d+WBffLaj1kLvyQWrB5LtZjYGILytCOcPmPfBzHIIwvx37v7ncPaA324Ad98NzCXochgRXmAd2m9X1C/APhm4zMzWA38g6Ha5l4G7vW3cfXN4W0HwxX06ffzZjlqg9+SC1QNJ5sW3/46gj7l1/hfDPeNnAtUZf8ZFhgVN8V8Dq9x9WsZDA3a7zawkbJljZkMI9hmsIgj2K8PFOm5zZC/A7u63uXupux9F8Pv6grtfxwDd3lZmVmhmQ1vvAxcCy+nrz3Z/7zg4gB0NnwTWEPQ7/nt/19OL2zUD2AokCfrPbiDoO3weWAs8BxwWLmsER/usA5YBk/q7/gPc5o8R9DO+BSwNfz45kLcbOAlYEm7zcuCOcP7RwAKgDPgTkBfOzw+ny8LHj+7vbXgP234u8NfBsL3h9r0Z/qxozaq+/mzr1H8RkQEial0uIiLSBQW6iMgAoUAXERkgFOgiIgOEAl1EZIBQoIuIDBAKdBGRAeL/A5YpCr5TKkeCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Perda')\n",
    "plt.plot(history.history['loss'], label='treino')\n",
    "plt.plot(history.history['val_loss'], label='teste')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db897441",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "  O gráfico seguinte apresenta a acurácia de treino e de teste:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "assured-flesh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAujklEQVR4nO3deXyV5Z3//9cn+wKBQMIadkFAUdCIIrUuFMSlVduOFdtqO+3gr6O201pH/NWqterYfrtYO9Yp/RZtZ1rQ0Y5lHDquoF20EhQVUCAglgSVfSf75/vHfZ/kzjkJOUDCcvN+Ph555N7PdZ+cvM91rvs692XujoiIxFfGkS6AiIh0LQW9iEjMKehFRGJOQS8iEnMKehGRmFPQi4jEnIJe5CCZWbaZLTWzS9Lc/g9mdm1Xl0skmakfvcSNmS0CTgX6uXttFz7O7UCOu9/WVY8h0hlUo5dYMbOhwDmAA5/o5GObmWWE05nAduD2znwMka6goJe4uQZ4BXgEaG4mMbNBZvY7M9tkZlvM7F/D5Xea2X9EthtqZm5mWeH8IjO7x8z+DOwFhpvZF4FlwD1ApZldFy2AmV0WNunsNLM1ZjY9cqwvh9MjzOyFsCybzew3Ztaz654WOZ4p6CVurgF+E/5caGZ9w9r3U8B7wFBgIDDvAI75eWAm0D08xmbgUqAI+CLwYzM7DcDMJgK/Bm4GegIfBda1cUwD/gUYAIwBBgF3HkCZRNKWdaQLINJZzOwjwBDgMXffbGZrgKsJavgDgJvdvSHc/E8HcOhH3H15ZP6/I9MvmtkzBM1FrwFfAua4+7Ph+uq2DujulUBlOLvJzH4E3HEAZRJJm4Je4uRa4Bl33xzO/zZcVg28Fwn5A7U+OmNmU4BvA8OBJqAEeCtcPQhY0NEBzawv8BOCN4juBJ+utx1k+UT2S0EvsWBm+cCVQKaZfRAuziVoPvkQGGxmWW2E/R6gIDLfr43DN3dNM7Mc4PfADOApd3cz+z1BUwwEbwoj0ijyveFxx7n7VjO7HPjXNPYTOWBqo5e4uBxoBMYC48OfMcAfw3XvA/eZWaGZ5ZnZ5HC/pcBHzWywmfUAbu3gcXKBfII3CMzsImBqZP0vgS+a2RQzyzCzgWY2uo3jdAd2AzvMbCBBm75Il1DQS1xcCzzs7n9z9w8SPwS15BnAx4ETgL8BVcBnAMK29EeBN4ElBBdt2+Xuu4CvAnMJmlquBuZH1r9KeIEW2AG8SHDdINl3gNPCbf4H+N1BnbVIGvSFKRGRmFONXkQk5hT0IiIxp6AXEYk5Bb2ISMwddf3oS0pKfOjQoUe6GCIix5QlS5ZsdvfSttYddUE/dOhQKioqjnQxRESOKWb2Xnvr1HQjIhJzCnoRkZhT0IuIxJyCXkQk5hT0IiIx12HQm9kcM9toZsvaWW9m9oCZVZrZm4mRdsJ115rZ6vDn2rb2FxGRrpVOjf4RYPp+1l8EjAx/ZgIPAZhZL4IRc84EJgJ3mFnxoRRWREQOXIf96N39JTMbup9NLgN+7cFtMF8xs55m1h84D3jW3bcCmNmzBG8Ycw+51G2p2wN/uh+KBkDNjmC+DbUNjbxRtYP+PfIYVByMN7F8ww4cOHlAD/bWNfBW9U7cnd7dcjmhTyFvrN9BXnYGvQpzqWtsol9RLkvX76ChsYmC3CzGDSyivtGp3LibMf27U9/ovLF+O41NTlF+NmP7F7GntoFlG4LjJgzuXcDu2ga27q4jw4xxZT3YWVPPu5v2UJCbRV1DEw2NTc3bF+Vn4+7UNTq19Y30LMhm+9765vU9C3IAZ29dI3UNTeRmZwbbNzSRk5VBhhk19Y0pz0mfojyyM43qbftaLS/MzaKmvpHGJm8pT1MTRXnZ7NxX31ymnfvqKS7MoSg/m79t2UuP/GwAduyrp3teFntqG8jLzmRPbcuYH0X52eyuaaAwN5OahiayMgwzo66hifzsTHbXNpBhMLZ/Eeu27Gk+ZwAzY9zAIgpysli+YQeNDvWNTdQ3NLUqU3vnXJSfzc6aeorystlT20D3vGz69hvAu5v3kle/rfnc0lFcmEO3vCz6ds/lnQ920eSwt7btgayKC3MA2LanjuysDLIyjKyMDE4aUMSK93eyc189mRlG97xsBhTn0dTkvPP+LnKyMsjNysQMdu6rp1+PPMyM97fvo6SogBNOHAdbKlm7eQ+9C3N4d/MeauobKcrPZldNA91ys9hV03JOieenPT3ys9kR/fvW1FNckEOP/Gz21TVS19jE9r31dMvNZFdNy7kOL+3Gzn31NDSF6/Oy2FvbSFMbd8iNPkZCXnYmQ0oKWPn+rg6f96L8bHbXNlCQk0ldQxNm1vz6SMjMNCYM6smG7TVs2B68tkf37071tprm5xKgIDeL2oZGGhtTy9mzIHgt76xpoKmpZX33/OzgOW3n5r8ZZhTkZrK7puNBzTIyjIKcYFvrMZAz/+6mDvc5UGndpjgM+qfc/eQ21j0F3OfufwrnnwduIQj6PHe/O1z+bWCfu/+gjWPMJPg0wODBg09/7712+/23b89m+D/JA/tYymYOuAerMqLzgIWbR58Ss9bzbS0zC//e3v4xkpc1F6+d4xx2SWU5YsdI96Hae04PQoa1PkiTp75u0inPwZalzX0TRWjrmJF10bIfTLk71VH4Gkr5nzqMr9GDsTr7RE687a8Hta+ZLXH38rbWHRXfjHX32cBsgPLy8oP7MxSWwEXfhz/8czA/80UYMB6ApiZn3ZY9DC/txvW/WcKCtz6gMCeTRTefz4c7a7j0p8E40bddMoZnV3zIzpoGbr1oNNfMeZWzhvfilbVbWz3UZ8oH8WjFep74yiQ+9dDL3PHxsXznv1cA8OjMs/j1K++xZN02brt0DDf89nUenXkW9y54m6zMDJ74ytkA/PT51fzw2VUA3HPFydz13yv4xKkD+M8lVXxsTF+ee/tDAFbfcxHZmRksXLmRLz68uLkMI0oLWbNpD584dQAPzJjA/c+t4v7nVjev/9XfT+TaOa8C8Nh1k7jy5y83T08c1qt5uwVvvc8//uY1AO667CSumTQUgCXvbeVTDwX7/OFr53DRT/4IQJ/uuWzcVct15w7n5TVbeLNqR6vy7s/8GyZzSllPrv7FK/xlzZYOt0+29Pap9CzI4dKf/pG8rEwuGtef7z61onn9Szefz++XVvPDZ1cxflBPlq7fDsCr35pCn+55ANw5fzmP/GVdq+N+LGMJ/zfnhwDMrPs6M675R84f3afD8nzh4VdZtHITALlZGdSGnyheuOlchpd2a7XtJQ/8keUbdgIwqm83Vn24u3ndNZOG8OuX32P2509n5r8vabXfBaP78MI7G1vKGnmuPzamL/evvYRuVkP1gGlMXvsFIAi3j5xQwh9Xb27e7/7PjOfyCQP5wdMr+deFlUwb25fZ16Rmwi2Pv8mjFeu5dtIQ8nOy+LcX1+z3Ofj550/nwpP68eVfVfDK2i3sDj/NRMu57r5LWu1z6+/eYu6rf+NzZw3m7svHAbB5dy3ldz8XPFfj+vPgZ0+jPVN+uIg1m1I/sVfc9jFKuuUC0NjknH73s/QqyGHt5j3cc8XJvLhyE8+saHmdPvLFMyjpltv8/7/m3ovJzGh5s3zg+dX8KPwfjZ7Ho4v/xi1PvEVJtxwqbosOLtZi6Kz/AeDhL5zR4Wspse28mWdx1vDe+932YHVGr5tqggGRE8rCZe0t7zrZ+ZHplmFAv/f0O1zwwxep2ra3ObT31DVyxj3PNf+RAe7+n7f567tbOXtEb8qHFpOTmcEra7cyvLSw1cM8WhGMFT1hUDFlxfnNIQ+wZU8dFeu2ctbwXs1NQ5+Z/QpvVO1gUuSPOGlEy/Sg4gLKivP5zyVVAHx+UjAgUXamkZ0Z/InOGNoSzgBjB/QAoKw4P/xd0Gr96H7dI9sWNU8ntk+IvrDOjpRp3MCeAAzokceJfYNj5WdnUpCT2fx4pw0OLrlcd+7w5v2yMtqvVY7tH5RjwuCe7W6TcM7IEnqHTR0JQdMUnD2ihIr3trUKeYD+PfM4bUhx8/4JiZAHOKWsR8pj7SMnMp1L+dD0LiWNH9SzeToR8gDDSgpTtk0EUKL8Cb0Kc5i3OHg9DeldyMCerf8+54/uQ/8eLeX/p4+NbDWdKPsr61ua3U4Z2INzR7W+5cmZw3u1KvOpkbJHjQufn3FlPfnoqKCcieaLtpwZVhrKivObQx7ghgtOAFr+5lGJv8EpA1vKUNItl+Hh8xb932jLxGFtr48+x5kZxpTRfVm7OXhDOHtESavXNwT/U2PC8hXlZbUKeaD59Q0wsk/LG/ek4SVhOUtoT+Ic03ktTRvbN+XxOltn1OjnAzeY2TyCC6873P19M3sauDdyAXYaHY/HeWgi4U52yz/Hr8Ia3JL3trF1Tx3TxvZt9c4OQW0+PyeTDDMuPKkfBTlZPPL3Z/Du5j2cPqSYXTUNbNi+j6Xrt/Pwn4PjZWQYk4b3bg5ogE27atm4q5bBvQsZ1KulPPdeMY5LxvVvnj+lrCf52Znsq29kUK+C5o/u551YyjknlPA/X/1Ic1s3QLfcLJ74yiTcg8D72aJKAPqHwTAoKcCLC3J47hsfJcOMbrktf+a+RXmttutVmMOv/34i++obOaFPy5tDTlYGv79+Mv165JGRYTx140coLszhs794pfnx/u70Ms4f3Yczhvbi0ZlnsXFXLeeMLOGdD3axt66BWU+8xcZdtfzg707lxL7dyQrftL42ZRTlQ3sxvqwnlZt207d7HnvrG2hscnrkZ1O1bR9j+hdxzZxX2bKnjm9MHcUlp7Q8d185dwTDSwppdOeE0m58ZnZQpuzMDM4e0ZuHv3gGHzmhhE+eVtbqGgfA5eMH0rMgmzOH9ea1v23jxL7duf/hDcGggMC3LptA97z2gy3q+vNP4NSyngDsrm2gX488CnOyMEt9s0tkyCcnDGTWRaP5+8nD2FvfwAPPr2bBW8FY5oN7FfC7fzyba375Kis/3MXwkkL+7vQyLhs/gG176vhgRw0nD+zBnC+U4w4nD+zB9twCqNtJjefwtSkjGdW3O2eP6E1RfjbDSwspH9qL5dU76d8jeH1MGdOHh79wRqs3wqirJw5mQM88zhvVh4wM44//fD6l3XP567tbqWto4ifPr2JZ9U6+dfEYTh3Us/nNN/pa/+a0UYwf1JMnvnI2Q3sXpDzGZ8oH0bcol/NGta7p/uxzp/FW1Q4+fuqA/T7vd3x8LBeP68eJ/bpTvW0fPfKz27wO8N3LT+Kjo0ooyMliWEkhfYsGUZCbxaDiAnKyjMLw/+KpGz9Cr6RKBcDkE4LXUmG4f8Lg3gX89stntvtmCUFNft2WPWm9lh6YMaH5mlJX6TDozWwuQXt7iZlVEfSkyQZw938DFgAXA5XAXoLxMglHtv8ukGhvuCtxYbbLtFGj/9PqzdTUB//sz70dfAT+5GkDU4L+IyNLGN2vde0jqAW0/of42Ji+zUEPcNKAIv5zCVwxYSD/9Xo1azbtxh1KuuVQHKkJXX3m4FbHycnKoHxoMX9cvZkBPfPYurcOCN5wMjKMkwak1jxPH9JSq88IwyRRgx6QVBPMycpoFdwJybUWgI+OavOGd61eyCcP7NHqcfsW5ZGXndlcczwz8skg8SkhKyPokXva4J6tmjJysjI4/8Tgn/yMwtafVKDl00lZcT5vrN/O1WcOblVbKy7M4aqJg1P2g+BCbeLYbdWsMzKMC0YHNahzRgZlnziyDIJWLkYP6tvmcduSnZmRVhMPtDxv007qR152JoPDADxreG8WvPUBmRlGfk4m+TmZDC8tZOWHu/jax0aSl51JXnYmRXnZDOkdnE+i/AD5hd2h7gP2kcPVZw5u9Uae2C5aQzaz/ZY5+vxAS4An/s7/9XoVy6p30qcot1UTYPST4mXjBwJw+pC2a6jJj5Ewul9Ryv9gW/KyM5v/dtFPa8kKcrKay5KYv7J8UMp2idd2suhrKdnZJ7Rfmwfo3S2X3pHX7P4k/sZdKZ1eNzM6WO/A9e2smwPMObiiHYRWQR9MR9sYX3tvGyXdcjh/dB+mn9SPf/jocD710F8AKEqzFleYm8U/njeCkX2D4Lp8wkBeWr2Zb0wdxQvvbGTVh0GPgV6FOZgZXzlvRKtmlKhrJw1laO9CcrMy+dnVp/G716sZkdS2256vTx3F9r11zTXdgT3zuXz8AJ5cuqHN7b97+cnt9gY5EA/MmMC/vbiGE/p0XM6HPnc6v/zTuwzulVqrS8cnTh1AabfcViHflm9MHUW/Hu3/w3fk9BP6Nwd9q0+Fnejbl44lM8Oam0MSpp/cjxfe2cg1k1rGD79p2igam5ypYzt+08nODcq7j1xK0wyWQzFr+hjqG50pY1qXbVTfltd4W7VjObKOusHBy8vL/aBvU/zey/Bw0OV//Y3VFHfLo/zuZ5kwqJiX1wYX/8YP6smT109u3iVxIWTZdy5s1cRxMEb8/wtoDLtgzf2Hszpsa+wKifNJvgAm+7GjCn58UjD9T29Bz7Y/LRyVfjEFqiv4fv2V/PM9vzhixXB3ht26AIB3/+XiNpuvpGvtr9dNvG6BEKnRn/N/XuTSB/5ITX0TU8a0fPwa1E7tsjDn0D86RS/O9e525Go1fbp3fc0uVlpd2+maGn1X8+z8jjfqQmbGiLDTgkL+6BOzoG/9T7puy17Mgi5qCcm9ThI648U559ozmqeTe4wcLm/cPo2F3zzviDz2MauNJr9jzdemn3Kki8BTN57D699uu7uhHFlHRT/6TtPGP+mYfkUMjIT7oOKuq7H1iFx8TfRGONx67KcrnLQjK9K+n3VsBn1eftvXgQ6nxMVkOfrELOhTQ3xYSXCxMzvTqG/0lBr9vJlnsWlXbacVYcFXz6Hiva1t9m6Ro1T001zGMfoh9xj9JCKHR8yCPvXFnhv2TS3MzWL73vr9fmGoM4wdUNTqC0oih8Uxem1BDo9jtPrSjqzULna52WHQ5wTvaQPbaaMXOaapRi/7Ea+gb+Njd25W0GZYmJtJ36Lc5nmRWMnUtRlpX7yabtqQaLrpmZ9Dz3x9kUPiSteEpH3HTdDf+YmTdIFU4icnvM3DsXoRWQ6L+AX95Q9x78t7IbylfW54DwldIJX9umouR/WNyttzxc+hYg70n3CkSyJHsfgF/firefPVl4Hg/mm5XXhHOImR0Rcf6RIcnKL+cMG3jnQp5CgXyxRM3K0SFPQiIrFMwegYoeplIyLHu/gHfXYsT1FEJG2xTEE13YiItEgrBc1supmtNLNKM5vVxvohZva8mb1pZovMrCyyrtHMloY/8zuz8O2paVDTjYhIQjpDCWYCDwJTgSpgsZnNd/foyMw/AH7t7r8yswuAfwE+H67b5+7jO7fY+7evLhr0qtGLyPEtnRScCFS6+1p3rwPmAZclbTMWeCGcXtjG+sPG3altiDTddPFYjCIiR7t0gn4gsD4yXxUui3oD+GQ4fQXQ3cwSt4XMM7MKM3vFzC5v6wHMbGa4TcWmTZvSL30boiEPqtGLiHRWCn4TONfMXgfOBaqBRPvJkHAcw6uB+81sRPLO7j7b3cvdvby0tPSQChLtcQOQo6AXkeNcOt+MrQYGRebLwmXN3H0DYY3ezLoBn3L37eG66vD3WjNbBEwA1hxqwduzLynodXsbETnepVPdXQyMNLNhZpYDXAW06j1jZiVmljjWrcCccHmxmeUmtgEmA9GLuJ0u2rUyLF1XPpyIyFGvw6B39wbgBuBp4G3gMXdfbmZ3mdknws3OA1aa2SqgL3BPuHwMUGFmbxBcpL0vqbdOp0s03VxZXkaf7rntDgYuInK8SOumZu6+AFiQtOz2yPTjwONt7PcXYNwhlvGAJIL+onH9+f6nTz2cDy0iclSK3ZXKRB/6fHWrFBEBYhj0W/fWAVBcoNGkREQgjkG/Jwj63t0U9CIiEMOg37y7DjPV6EVEEmIX9Fv31FJckKPxYUVEQrEL+i276+hVqNq8iEhC/IJ+Tx29FfQiIs3iF/S7a3UhVkQkInZBv6e2kW65aX0PTETkuBC7oK9paCRPX5YSEWkWv6Cvb9S3YkVEImIV9O5OTX2TRpUSEYmIVdAnRpfKy47VaYmIHJJYJWLizpV5WarRi4gkxCzogxp9fo6CXkQkIVZBnxhGUE03IiIt0kpEM5tuZivNrNLMZrWxfoiZPW9mb5rZIjMri6y71sxWhz/Xdmbhk6npRkQkVYdBb2aZwIPARcBYYIaZjU3a7AfAr939FOAu4F/CfXsBdwBnAhOBO8ysuPOK31pz0KvXjYhIs3Rq9BOBSndf6+51wDzgsqRtxgIvhNMLI+svBJ51963uvg14Fph+6MVu2z4FvYhIinSCfiCwPjJfFS6LegP4ZDh9BdDdzHqnuS9mNtPMKsysYtOmTemWPUVtvbpXiogk66xE/CZwrpm9DpwLVAON6e7s7rPdvdzdy0tLSw+6EGq6ERFJlc7dv6qBQZH5snBZM3ffQFijN7NuwKfcfbuZVQPnJe276BDKu181DQp6EZFk6dToFwMjzWyYmeUAVwHzoxuYWYmZJY51KzAnnH4amGZmxeFF2Gnhsi6xry7sR6+gFxFp1mHQu3sDcANBQL8NPObuy83sLjP7RLjZecBKM1sF9AXuCffdCnyX4M1iMXBXuKxL1KgfvYhIirRu3O7uC4AFSctuj0w/Djzezr5zaKnhdyk13YiIpIpV1bepyQHIMA0MLiKSEKug9yDnUc6LiLSIV9CHv5XzIiIt4hX0zTV6Rb2ISEK8gj6s0yvmRURaxCvo1UYvIpIiXkEf/lbTjYhIi3gFvbtq8yIiSWIW9GqfFxFJFq+gx9VsIyKSJF5Brxq9iEiKeAU96nEjIpIsXkHvYKrTi4i0Eq+gR203IiLJYhX0ynkRkVSxCnq10YuIpEor6M1supmtNLNKM5vVxvrBZrbQzF43szfN7OJw+VAz22dmS8Off+vsE4hyd7XRi4gk6XCEKTPLBB4EpgJVwGIzm+/uKyKb3UYwxOBDZjaWYDSqoeG6Ne4+vlNL3Y4mhwzlvIhIK+nU6CcCle6+1t3rgHnAZUnbOFAUTvcANnReEdPnrvvciIgkSyfoBwLrI/NV4bKoO4HPmVkVQW3+xsi6YWGTzotmdk5bD2BmM82swswqNm3alH7pkziuhhsRkSSddTF2BvCIu5cBFwP/bmYZwPvAYHefAHwD+K2ZFSXv7O6z3b3c3ctLS0sPuhDuqNuNiEiSdIK+GhgUmS8Ll0V9CXgMwN1fBvKAEnevdfct4fIlwBpg1KEWen+U8yIiraUT9IuBkWY2zMxygKuA+Unb/A2YAmBmYwiCfpOZlYYXczGz4cBIYG1nFT5ZcJtiRb2ISFSHvW7cvcHMbgCeBjKBOe6+3MzuAircfT5wE/ALM/s6wYXZL7i7m9lHgbvMrB5oAv4/d9/aVSejfvQiIqk6DHoAd19AcJE1uuz2yPQKYHIb+z0BPHGIZUyb7l4pIpIqZt+MVdONiEiyeAW9avQiIiliFfRN+sKUiEiKWAU9aHBwEZFksQp6Nd2IiKSKX9Ar6UVEWolX0KPbFIuIJItX0KtGLyKSIl5Bj9roRUSSxSvo1b1SRCRFvIIeP9JFEBE56sQq6FEbvYhIilgFvQMZSnoRkVZiFfRNrm/Giogki1XQ65uxIiKp4hX0qNeNiEiytILezKab2UozqzSzWW2sH2xmC83sdTN708wujqy7NdxvpZld2JmFT+buqtGLiCTpcISpcMzXB4GpQBWw2Mzmh6NKJdwGPObuD5nZWILRqIaG01cBJwEDgOfMbJS7N3b2iUBQo1fSi4i0lk6NfiJQ6e5r3b0OmAdclrSNA0XhdA9gQzh9GTDP3Wvd/V2gMjxe11AbvYhIinSCfiCwPjJfFS6LuhP4nJlVEdTmbzyAfTuNhhIUEUnVWRdjZwCPuHsZcDHw72aW9rHNbKaZVZhZxaZNmw66EOp1IyKSKp0wrgYGRebLwmVRXwIeA3D3l4E8oCTNfXH32e5e7u7lpaWl6Zc+5Tj6ZqyISLJ0gn4xMNLMhplZDsHF1flJ2/wNmAJgZmMIgn5TuN1VZpZrZsOAkcCrnVX4ZI7rm7EiIkk67HXj7g1mdgPwNJAJzHH35WZ2F1Dh7vOBm4BfmNnXCS7MfsHdHVhuZo8BK4AG4Pqu6nEDweDgIiLSWodBD+DuCwguskaX3R6ZXgFMbmffe4B7DqGMadNtikVEUsXqm7GgL0yJiCSLVdDrYqyISKp4BT0KehGRZPEKendMjTciIq3EK+hRjV5EJFm8gl7fjBURSRGvoAdV6UVEksQr6N3JUM6LiLQSs6BX042ISLJ4Bb1uUywikiJeQa8avYhIivgFvZJeRKSVeAU9+sKUiEiyeAW9o7YbEZEk8Qp6lPMiIsliFfSojV5EJEVaQW9m081spZlVmtmsNtb/2MyWhj+rzGx7ZF1jZF3yEISdSm30IiKpOhxhyswygQeBqUAVsNjM5oejSgHg7l+PbH8jMCFyiH3uPr7TSrwf7pARr88oIiKHLJ1YnAhUuvtad68D5gGX7Wf7GcDczijcgWrSbYpFRFKkE/QDgfWR+apwWQozGwIMA16ILM4zswoze8XMLj/YgqZDtykWEUmV1uDgB+Aq4HF3b4wsG+Lu1WY2HHjBzN5y9zXRncxsJjATYPDgwQf94O4HvauISGylU6OvBgZF5svCZW25iqRmG3evDn+vBRbRuv0+sc1sdy939/LS0tI0itS2oEavKr2ISFQ6Qb8YGGlmw8wshyDMU3rPmNlooBh4ObKs2Mxyw+kSYDKwInnfTuOuFnoRkSQdNt24e4OZ3QA8DWQCc9x9uZndBVS4eyL0rwLmubdqQBkD/NzMmgjeVO6L9tbpbGqjFxFJlVYbvbsvABYkLbs9af7ONvb7CzDuEMp3QHT3ShGRVLHqda770YuIpIpX0KtGLyKSIn5Br6QXEWklVkHf5Gq6ERFJFqugBzXdiIgki1XQq+lGRCRVvIJetykWEUkRr6BXjV5EJEW8gh4FvYhIsngFve5HLyKSIl5BD+p2IyKSJFZBj74ZKyKSIlZBr/vRi4ikilfQu5OhnBcRaSVWQd+kphsRkRSxCnrdplhEJFW8gl41ehGRFGkFvZlNN7OVZlZpZrPaWP9jM1sa/qwys+2Rddea2erw59pOLHsKd5T0IiJJOhxK0MwygQeBqUAVsNjM5kfHfnX3r0e2vxGYEE73Au4Aygk6xSwJ993WqWcRLa+SXkSklXRq9BOBSndf6+51wDzgsv1sPwOYG05fCDzr7lvDcH8WmH4oBd4fd9ctEEREkqQT9AOB9ZH5qnBZCjMbAgwDXjiQfc1spplVmFnFpk2b0il3m9RyIyKSqrMvxl4FPO7ujQeyk7vPdvdydy8vLS096AfX3StFRFKlE/TVwKDIfFm4rC1X0dJsc6D7HjLdj15EJFU6Qb8YGGlmw8wshyDM5ydvZGajgWLg5cjip4FpZlZsZsXAtHBZl3CHjFh1GBUROXQd9rpx9wYzu4EgoDOBOe6+3MzuAircPRH6VwHz3N0j+241s+8SvFkA3OXuWzv3FFo06faVIiIpOgx6AHdfACxIWnZ70vyd7ew7B5hzkOU7QOp1IyKSLFYNHfpmrIhIqngFPep1IyKSLF5Br6EERURSxCvoUY1eRCRZvIJebfQiIiliFvS6H72ISLJ4Bf2RLoCIyFEoVkGPQ4Zq9CIircQq6Jt0m2IRkRSxCnrdplhEJFW8gl63KRYRSRGvoEe9bkREksUr6NWPXkQkRVp3rzxW6C7FIvFXX19PVVUVNTU1R7ooR0ReXh5lZWVkZ2envU+sgh5H97oRibmqqiq6d+/O0KFDj7umWndny5YtVFVVMWzYsLT3i1fTje5HLxJ7NTU19O7d+7gLeQAzo3fv3gf8aSatoDez6Wa20swqzWxWO9tcaWYrzGy5mf02srzRzJaGPylDEHYmtdGLHB+Ox5BPOJhz77DpxswygQeBqUAVsNjM5rv7isg2I4Fbgcnuvs3M+kQOsc/dxx9wyQ6Co2/GiogkS6dGPxGodPe17l4HzAMuS9rmH4AH3X0bgLtv7NxipkffjBWRrrZ9+3Z+9rOfHdA+GzZs4NOf/nQXlahj6QT9QGB9ZL4qXBY1ChhlZn82s1fMbHpkXZ6ZVYTLL2/rAcxsZrhNxaZNmw6k/K2o6UZEulp7Qd/Q0NDuPgMGDODxxx/vymLtV2f1uskCRgLnAWXAS2Y2zt23A0PcvdrMhgMvmNlb7r4murO7zwZmA5SXlx/aTShVpRc5bnznv5ezYsPOTj3m2AFF3PHxk9pdP2vWLNasWcP48ePJzs4mLy+P4uJi3nnnHd5++21mzZrFokWLqK2t5frrr+e6665j3bp1XHrppSxbtoxHHnmE+fPns3fvXtasWcMVV1zB97//fQDmzp3Lvffei7tzySWX8L3vfa9TzimdoK8GBkXmy8JlUVXAX929HnjXzFYRBP9id68GcPe1ZrYImACsoZO5B+8PinkR6Ur33Xcfy5YtY+nSpSxatIhLLrmEZcuWMWzYMGbPnk2PHj1YvHgxtbW1TJ48mWnTpqVcQF26dCmvv/46ubm5nHjiidx4441kZmZyyy23sGTJEoqLi5k2bRpPPvkkl19++SGXOZ2gXwyMNLNhBAF/FXB10jZPAjOAh82shKApZ62ZFQN73b02XD4Z+P4hl7oNYc6rQi9yHNlfzftwmThxYnOf9meeeYY333yzuZlmx44drF69mlGjRrXaZ8qUKfTo0QOAsWPH8t5777FlyxbOO+88SktLAfjsZz/LSy+9dHiC3t0bzOwG4GkgE5jj7svN7C6gwt3nh+ummdkKoBG42d23mNnZwM/NrIngesB90d46nSnR3qMvTInI4VRYWNg87e789Kc/5cILL2y1zbp161rN5+bmNk9nZmbut32/M6TVj97dF7j7KHcf4e73hMtuD0MeD3zD3ce6+zh3nxcu/0s4f2r4+5dddSLNTTfKeRHpQt27d2fXrl1trrvwwgt56KGHqK+vB2DVqlXs2bMnreNOnDiRF198kc2bN9PY2MjcuXM599xzO6XMsbkFQkuNXkSk6/Tu3ZvJkydz8sknk5+fT9++fZvXffnLX2bdunWcdtppuDulpaU8+eSTaR23f//+3HfffZx//vnNF2Mvuyy5J/vBsURN+GhRXl7uFRUVB7xfXUMTo277A9+cNoobLhjZBSUTkaPB22+/zZgxY450MY6otp4DM1vi7uVtbR+be904iaYb1elFRKLiE/TqdSMi0qb4Bb1a6UVEWolP0KNeNyIibYlP0DfX6EVEJCo+QR/+Vo1eRKS1+AR9871ulPQi0nUO5jbFCffffz979+7t5BJ1LD5BH/5WjV5EutKxGPTx+Wbs0fW9LxE5HP4wCz54q3OP2W8cXHRfu6ujtymeOnUqffr04bHHHqO2tpYrrriC73znO+zZs4crr7ySqqoqGhsb+fa3v82HH37Ihg0bOP/88ykpKWHhwoU888wz3HHHHdTW1jJixAgefvhhunXr1rnnQ4xq9DT3o1eVXkS6zn333ceIESNYunQpU6dOZfXq1bz66qssXbqUJUuW8NJLL/G///u/DBgwgDfeeINly5Yxffp0vvrVrzJgwAAWLlzIwoUL2bx5M3fffTfPPfccr732GuXl5fzoRz/qkjLHp0aP7kcvctzZT837cHjmmWd45plnmDBhAgC7d+9m9erVnHPOOdx0003ccsstXHrppZxzzjkp+77yyiusWLGCyZMnA1BXV8ekSZO6pJzxCfqwRp+hpBeRw8TdufXWW7nuuutS1r322mssWLCA2267jSlTpnD77ben7Dt16lTmzp3b5eWMTdNNk+teNyLS9aK3Kb7wwguZM2cOu3fvBqC6upqNGzeyYcMGCgoK+NznPsfNN9/Ma6+9lrLvWWedxZ///GcqKysB2LNnD6tWreqSMsenRh/+Vs6LSFeK3qb4oosu4uqrr25ucunWrRv/8R//QWVlJTfffDMZGRlkZ2fz0EMPATBz5kymT5/e3Fb/yCOPMGPGDGprawG4++67U0aj6gxp3abYzKYDPyEYYer/untKw5iZXQncSZC5b7j71eHya4Hbws3udvdf7e+xDvY2xTtr6rn1ibe48oxBnDuq9ID3F5Fjg25TfOC3Ke6wRm9mmcCDwFSCQcAXm9n86JCAZjYSuBWY7O7bzKxPuLwXcAdQTvAGsCTcd9tBnd1+FOVl8+BnT+vsw4qIHPPSaaOfCFS6+1p3rwPmAcnDnvwD8GAiwN19Y7j8QuBZd98arnsWmN45RRcRkXSkE/QDgfWR+apwWdQoYJSZ/dnMXgmbetLdFzObaWYVZlaxadOm9EsvIselo21kvMPpYM69s3rdZAEjgfOAGcAvzKxnuju7+2x3L3f38tJSta+LSPvy8vLYsmXLcRn27s6WLVvIy8s7oP3S6XVTDQyKzJeFy6KqgL+6ez3wrpmtIgj+aoLwj+676IBKKCISUVZWRlVVFcfrp/+8vDzKysoOaJ90gn4xMNLMhhEE91XA1UnbPElQk3/YzEoImnLWAmuAe82sONxuGsFFWxGRg5Kdnc2wYcOOdDGOKR0Gvbs3mNkNwNME3SvnuPtyM7sLqHD3+eG6aWa2AmgEbnb3LQBm9l2CNwuAu9x9a1eciIiItC2tfvSH08H2oxcROZ7trx99bG6BICIibTvqavRmtgl47xAOUQJs7qTiHCt0zscHnfPx4WDPeYi7t9lt8agL+kNlZhXtfXyJK53z8UHnfHzoinNW042ISMwp6EVEYi6OQT/7SBfgCNA5Hx90zseHTj/n2LXRi4hIa3Gs0YuISISCXkQk5mIT9GY23cxWmlmlmc060uXpLGY2x8w2mtmyyLJeZvasma0OfxeHy83MHgifgzfN7JgcicXMBpnZQjNbYWbLzexr4fLYnreZ5ZnZq2b2RnjO3wmXDzOzv4bn9qiZ5YTLc8P5ynD90CN6AofAzDLN7HUzeyqcj/U5m9k6M3vLzJaaWUW4rEtf27EI+sgoWBcBY4EZZjb2yJaq0zxC6mAts4Dn3X0k8Hw4D8H5jwx/ZgIPHaYydrYG4CZ3HwucBVwf/j3jfN61wAXufiowHphuZmcB3wN+7O4nANuAL4XbfwnYFi7/cbjdseprwNuR+ePhnM939/GR/vJd+9p292P+B5gEPB2ZvxW49UiXqxPPbyiwLDK/EugfTvcHVobTPwdmtLXdsfwD/J5gKMvj4ryBAuA14EyCb0hmhcubX+cENxKcFE5nhdvZkS77QZxrWRhsFwBPAXYcnPM6oCRpWZe+tmNRoyfNkaxipK+7vx9OfwD0Dadj9zyEH88nAH8l5ucdNmEsBTYSDLu5Btju7g3hJtHzaj7ncP0OoPdhLXDnuB/4Z6ApnO9N/M/ZgWfMbImZzQyXdelrO5370ctRzN3dzGLZR9bMugFPAP/k7jvNrHldHM/b3RuB8eHobP8FjD6yJepaZnYpsNHdl5jZeUe4OIfTR9y92sz6AM+a2TvRlV3x2o5LjT6dUbDi5EMz6w8Q/k4Mxh6b58HMsglC/jfu/rtwcezPG8DdtwMLCZoteppZokIWPa/mcw7X9wC2HN6SHrLJwCfMbB0wj6D55ifE+5xx9+rw90aCN/SJdPFrOy5B3zwKVniF/ipg/hEuU1eaD1wbTl9L0IadWH5NeKX+LGBH5OPgMcOCqvsvgbfd/UeRVbE9bzMrDWvymFk+wTWJtwkC/9PhZsnnnHguPg284GEj7rHC3W919zJ3H0rwP/uCu3+WGJ+zmRWaWffENMGoe8vo6tf2kb4w0YkXOC4GVhG0a37rSJenE89rLvA+UE/QPvclgnbJ54HVwHNAr3BbI+h9tAZ4Cyg/0uU/yHP+CEE75pvA0vDn4jifN3AK8Hp4zsuA28Plw4FXgUrgP4HccHleOF8Zrh9+pM/hEM//POCpuJ9zeG5vhD/LE1nV1a9t3QJBRCTm4tJ0IyIi7VDQi4jEnIJeRCTmFPQiIjGnoBcRiTkFvYhIzCnoRURi7v8BD4l3PR6y4igAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Acurácia')\n",
    "plt.plot(history.history['accuracy'], label='treino')\n",
    "plt.plot(history.history['val_accuracy'], label='teste')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4612397e",
   "metadata": {},
   "source": [
    "<div>\n",
    "  Por fim, são feitas as classificações finais, onde são criadas as estruturas para as métricas de avaliação. \n",
    "</div>\n",
    "\n",
    "<h3>Classification Report</h3>\n",
    "\n",
    "<ul>\n",
    "    <li>TN / True Negative: o caso foi negativo e previsto como negativo</li>\n",
    "    <li>TP / True Positive: o caso foi positivo e positivo previsto</li>\n",
    "    <li>FN / False Negative: o caso era positivo, mas previsto como negativo</li>\n",
    "    <li>FP / False Positive: o caso foi negativo, mas previsto como positivo</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<h3>Precisão - Qual porcentagem de suas previsões estava correta?</h3>\n",
    "<p>É a capacidade de um classificador de não marcar uma instância como positiva (na verdade, negativa). Para cada categoria, é definido como a proporção de verdadeiros positivos para a soma de verdadeiros positivos e falsos positivos.</p>\n",
    "<p>Formula (Precisão de previsões positivas): <i>Precision = TP/(TP + FP)</i> </p>\n",
    "\n",
    "<h3>Recall - Qual a porcentagem de casos positivos que você pegou?</h3>\n",
    "<p>É a capacidade do classificador de encontrar todas as instâncias positivas. Para cada categoria, é definido como a proporção de verdadeiros positivos para a soma de verdadeiros positivos e falsos negativos.</p>\n",
    "<p>Fórmula (Fração de positivos que foram identificados corretamente): <i>Recall = TP/(TP+FN)</i></p>\n",
    "\n",
    "<h3>F1 Score - Qual porcentagem de previsões positivas estavam corretas?</h3>\n",
    "<p>É a média harmônica ponderada de acurácia e recordação, portanto, a pontuação mais alta é 1,0 e a pior diferença é 0,0. As pontuações F1 são mais baixas do que as medições de precisão porque incorporam precisão e recall no cálculo. Geralmente, a média ponderada F1 deve ser usada para comparar os modelos do classificador, ao invés da precisão geral.</p>\n",
    "<p>Fórmula: <i>F1 Score = 2*(Recall * Precision) / (Recall + Precision)</i></p>\n",
    "\n",
    "<h3>Support</h3>\n",
    "<p>É o número real de ocorrências da classe no conjunto de dados especificado. O suporte desequilibrado nos dados de treinamento pode indicar fraquezas estruturais nas pontuações do classificador relatadas e pode indicar a necessidade de amostragem estratificada ou rebalanceamento. O suporte não mudará entre os modelos, mas sim um processo de avaliação diagnóstica.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "forty-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rótulos ['circles', 'squares', 'triangles']\n",
      "Preds Created\n",
      "Preds 1D created\n"
     ]
    }
   ],
   "source": [
    "labels = os.listdir('shapes_split/test')\n",
    "print('Rótulos', labels)\n",
    "#criando estruturas para métricas de avaliação, processo um pouco mais demorado\n",
    "Y_pred = model.predict(test_generator)\n",
    "print('Preds Created')\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Preds 1D created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "nuclear-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------CLASSIFICATION--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     circles       0.35      0.35      0.35        20\n",
      "     squares       0.40      0.40      0.40        20\n",
      "   triangles       0.15      0.15      0.15        20\n",
      "\n",
      "    accuracy                           0.30        60\n",
      "   macro avg       0.30      0.30      0.30        60\n",
      "weighted avg       0.30      0.30      0.30        60\n",
      "\n",
      "----------------MATRIX--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification = classification_report(test_generator.classes, y_pred, target_names=labels)\n",
    "print('----------------CLASSIFICATION--------------')\n",
    "print(classification)\n",
    "matrix = confusion_matrix(test_generator.classes, y_pred)\n",
    "df_cm = pd.DataFrame(matrix, index = [i for i in range(3)],\n",
    "                  columns = [i for i in range(3)])\n",
    "plt.figure(figsize = (10,7))\n",
    "print('----------------MATRIX--------------')\n",
    "sn.heatmap(df_cm, annot=True, linewidths=2.5, xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1e421",
   "metadata": {},
   "source": [
    "<h3>Referências bibliográficas:</h3>\n",
    "<hr />\n",
    "<div>\n",
    "<p><strong>Mini Curso CNN Transfer Learning</strong>, William Sdayle Marins Silva. Disponível em: https://colab.research.google.com/drive/11akI_B5M0Y2cuO1Y5Qq7W36YuehkzvKh?usp=sharing. Acesso em 20 de Abril de 2021.</p>\n",
    "    \n",
    "<p><strong>A Gentle Introduction to the Rectified Linear Unit (ReLU)</strong>, Jason Brownlee. Disponível em: https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/. Acesso em 20 de Abril de 2021.</p>\n",
    "    \n",
    "<p><strong>Arquiteturas de Redes Neurais Convolucionais para reconhecimento de imagens</strong>, Alexandre Luiz Bianchi. Disponível em: https://www.viceri.com.br/insights/arquiteturas-de-redes-neurais-convolucionais-para-reconhecimento-de-imagens/. Acesso em 20 de Abril de 2021.</p>\n",
    "\n",
    "<p><strong>Overfitting e underfitting em Machine Learning</strong>, Henrique Branco. Disponível em: https://abracd.org/overfitting-e-underfitting-em-machine-learning/. Acesso em 20 de Abril de 2021.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
