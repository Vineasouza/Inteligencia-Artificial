{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e230538",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <h1 align=\"center\">Trabalho de Deep Learning</h1>\n",
    "  <div align=\"center\">Lucas de Almeida, RA: 1996762</div>\n",
    "  <div align=\"center\">Vinícius Augusto de Souza, RA: 1997530</div>\n",
    "  <hr/>\n",
    "  <div align=\"center\">Uma abordagem dos conceitos de redes neurais convolucionais pré treinadas utilizando o método de <i>transfer learning</i>.\n",
    "</div>\n",
    "  <div align=\"center\">A base de dados a ser utilizada será a <i>Basic Shapes</i>, que pode ser encontrada <a href=\"https://www.kaggle.com/cactus3/basicshapes\">neste link</a>. Ela é bem simples e objetiva, contendo um acervo de 300 imagens: 100 imagens de cada forma geométrica (circulos, quadrados e triangulos) desenhados manualmente por <a href=\"https://www.kaggle.com/cactus3\">Mark S.</a></div>\n",
    "</div>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-combat",
   "metadata": {},
   "source": [
    "<h3>Considerações sobre o trabalho:</h3>\n",
    "<hr/>\n",
    "<p>Para o desenvolvimento deste trabalho, foi escolhido o modelo pré-treinado da literatura <i><a href=\"https://keras.io/api/applications/xception/\">Xception</a></i>, considerando os pesos também pré treinados da <i>ImageNet</i>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electric-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcacff7f",
   "metadata": {},
   "source": [
    "<h3>Separação dos arquivos:</h3>\n",
    "<hr>\n",
    "<div>Antes de começar a tratar os dados, é necessário realizar a divisão do dataset em 80% para treino e 20% para testes.</div>\n",
    "<div>O código a seguir realiza essa tarefa, passando como variáveis:</div>\n",
    "<ul>\n",
    "    <li><i>data_dir</i>: o nome do caminho do diretório do dataset escolhido;</li>\n",
    "    <li><i>classes</i>: as classes das quais os arquivos pertencem (circulos, quadrados e triângulos);</li>\n",
    "    <li><i>output_dir</i>: o nome do caminho do diretório de saída, após separação;</li>\n",
    "    <li><i>ratio</i>: a taxa de divisão dos arquivos (i.e. 80% treino e 20% testes);</li>\n",
    "</ul>\n",
    "<p>Em seguida são carregadas essas variávies e todas as imagens <i>.png</i> são selecionadas e armazenadas na variável <i>file</i>.</p>\n",
    "<p>Em seguida, é escolhida uma <i>seed</i> arbitrária para embaralhar as imagens de forma que seja possível reproduzir essa mesma divisão posteriormente. Os arquivos então são embaralhados e divididos conforme os parâmetros passados anteriormente.</p>\n",
    "<p>Por fim, os arquivos divididos são enviados cada um para seu respectivo diretório, treino ou teste, e sempre divididos em pastas referentes à sua classe, conforme a estrutura a seguir:</p>\n",
    "<ul>\n",
    "    <li><i>test</i> <span  style=\"color:lightgrey\">(80% do dataset)</span></li>\n",
    "    <ul>\n",
    "        <li><i>circles</i></li>\n",
    "        <li><i>triangles</i></li>\n",
    "        <li><i>squares</i></li>\n",
    "    </ul>\n",
    "    <li><i>train</i> <span  style=\"color:lightgrey\">(20% do dataset)</span></li>\n",
    "    <ul>\n",
    "        <li><i>circles</i></li>\n",
    "        <li><i>triangles</i></li>\n",
    "        <li><i>squares</i></li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b530441",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"shapes\"\n",
    "classes = [\"circles\", \"squares\", \"triangles\"]\n",
    "output_dir = \"shapes_split\"\n",
    "ratio = [0.8, 0.2]\n",
    "\n",
    "def split(data_dir, output_dir, ratio):\n",
    "    for cell in classes:\n",
    "        cell_path = os.path.join(data_dir, cell)\n",
    "        files = os.listdir(cell_path)\n",
    "        files = [os.path.join(cell_path, f) for f in files if f.endswith('.png')]\n",
    "\n",
    "        random.seed(230)\n",
    "        files.sort()\n",
    "        random.shuffle(files)\n",
    "\n",
    "        split_train = int(ratio[0] * len(files))\n",
    "        split_test = split_train\n",
    "\n",
    "        files_train = files[:split_train]\n",
    "        files_test = files[split_test:]\n",
    "        files_type = [(files_train, \"train\"), (files_test, \"test\")]\n",
    "\n",
    "        for (files, folder_type) in files_type:\n",
    "            full_path = os.path.join(output_dir, folder_type)\n",
    "            full_path = os.path.join(full_path, cell)\n",
    "            pathlib.Path(full_path).mkdir(parents=True, exist_ok=True)\n",
    "            for f in files:\n",
    "                shutil.copy2(f, full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e330a6b",
   "metadata": {},
   "source": [
    "<h3>Definição dos parâmetros do modelo:</h3>\n",
    "<hr>\n",
    "<div>Antes de prosseguir, é necessário compreender em quais parâmetros o modelo se baseia. Dois desses parâmetros terão de ser definidos neste momento, os quais são:</div>\n",
    "<ul>\n",
    "    <li><i>epochs</i>: quantas vezes o algoritmo de treino será executado;</li>\n",
    "    <li><i>batch size</i>: quantas amostras serão carregadas a cada uma dessas execuções.</li>\n",
    "</ul>\n",
    "<div>Para o treinamento, foi definido que seriam utilizadas 500 <i>epochs</i> e 32 como <i>batch size</i>.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75598ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f534751",
   "metadata": {},
   "source": [
    "<h3>Carregamento do modelo \"<i>Xception</i>\":</h3>\n",
    "<hr>\n",
    "<div>Primeiramente o modelo escolhido é carregado juntamente com os pesos aprendidos durante o treino (sem a camada densa) para a variável <i>base_model</i>. Em seguida, a variável <i>x</i> recebe a saída do modelo carregado.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "round-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.Xception(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elegant-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=base_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab5f27",
   "metadata": {},
   "source": [
    "<h3>Configuração do modelo \"<i>Xception</i>\":</h3>\n",
    "<hr />\n",
    "<div>\n",
    "  Nesta etapa é necessário adicionar algumas camadas de nós. Para explicar o que\n",
    "  ocorre em cada uma das camadas, é preciso observá-las uma a uma, conforme\n",
    "  descrito abaixo:\n",
    "</div>\n",
    "<ul>\n",
    "  <li>\n",
    "    <i>camada GlobalMaxPooling</i>: Para reduzir a resolução, é utilizada uma\n",
    "    operação de <i>pooling</i> conhecida como “<i>pooling máximo</i>” (ou\n",
    "    <i>max pooling</i>). Nesta operação de agrupamento, um “bloco” com altura\n",
    "    'A' e largura 'L' desliza sobre os dados de entrada (conforme na figura\n",
    "    abaixo, de 'a' até 'd'). A cada iteração (ou seja, o quanto ela avança\n",
    "    durante a operação de deslizamento) é muitas vezes igual ao tamanho da\n",
    "    <i>pool</i>, de modo que seu efeito é igual a uma redução na altura e\n",
    "    largura. Para cada bloco, ou “pool”, a operação envolve simplesmente o\n",
    "    cálculo do valor máximo. Fazendo isso para cada pool, obtemos um resultado\n",
    "    bem reduzido, otimizando muito a quantidade de espaço de que precisamos.\n",
    "  </li>\n",
    "  <img src=\"max-pooling.png\" width=\"500\" />\n",
    "  <br /><br />\n",
    "  <li>\n",
    "    camada densa com função de ativação \"<i>ReLU</i>\": A função de ativação\n",
    "    linear retificada (ou <i>ReLU</i>) é uma função linear por partes que\n",
    "    produzirá a entrada diretamente se for positiva, caso contrário, ela\n",
    "    produzirá zero. Ela se comporta conforme o gráfico abaixo:\n",
    "    <br />\n",
    "    <img src=\"relu.jpg\" width=\"500\" />\n",
    "    Neste caso, foram adicionadas três camadas densas deste tipo, porém uma com\n",
    "    128 neurônios, outra com 64 neurônios e outra com 32 neurônios.\n",
    "    <br />\n",
    "  </li>\n",
    "  <li>\n",
    "    <i>camada dropout</i>: é feita uma espécide de \"regularização\", onde alguns\n",
    "    neurônios são desligados de forma aleatória, juntamente com suas conexões,\n",
    "    apenas durante o período de treinamento, porém durante a predição todos os\n",
    "    neurônios são mantidos ativos. O motivo de se fazer isso é evitar\n",
    "    <i>overfitting</i> no treinamento. A porcentagem escolhida nesse caso foi de\n",
    "    50%, conforme orientação no enunciado do projeto.\n",
    "  </li>\n",
    "  <li>\n",
    "    <i>camada de ativação</i>: utiliza uma função de ativação ao final das camadas anteriores. Essa função tenta aplicar um comportamento biologicamente análogo às excitações dos neurônios reais, isto é, replicar o comportamento de transmissão de informações dos neurônios, que só conseguem passar adiante a informação após sofrerem um estímulo. O que ocorre na prática é que a função insere um comportamento de \"não-linearidade\" após a função dos pesos com as entradas. Conforme enunciado, teria de ser feita uma escolha entre a função <i>sigmóide</i> e a função <i>softmax</i>. A escolha nesta situação é intuitiva, pois a função sigmóid é mais utilizada no aprendizado de funções lógicas, uma vez que ela tenta encaixar os valores entre 0 e 1. Já a função softmax produz uma distribuição de probabilidades para cada uma das classes das imagens durante a classificação, ao contrário da sigmóid que só consegue lidar com duas classes. Sendo assim, fica definido então que a função a ser utilizada é a <i>softmax</i> com 3 classes.\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<div>\n",
    "  Em seguida é feita a definição do modelo final bem como sua exibição, que pode\n",
    "  ser vista na sumário a seguir:\n",
    "</div>\n",
    "<span style=\"color: lightgrey\"\n",
    "  >Obs.: em virtude do tamanho do sumário, a linha de código que o exibe foi\n",
    "  comentada.</span\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extended-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "\n",
    "x=tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "preds=tf.keras.layers.Dense(3,activation='softmax')(x)\n",
    "\n",
    "model=tf.keras.models.Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be707171",
   "metadata": {},
   "source": [
    "<h3>Treinamento e teste do modelo:</h3>\n",
    "<hr />\n",
    "<div>\n",
    "  Primeiramente, é feito o congelamento dos neurônios já treinados na\n",
    "  <i>ImageNet</i>, para retreinar somente as camadas densas incluídas no passo\n",
    "  anterior. Para fazer isso, é feita a mudança na variável booleana\n",
    "  \"<i>treinable</i>\" de cada camada que não inicia com o nome \"<i>dense</i>\"\n",
    "  para false.\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Em seguida são criados dois objetos:\n",
    "  <ul>\n",
    "    <li><i>train_data_gen</i>;</li>\n",
    "    <li><i>test_data_gen</i>.</li>\n",
    "  </ul>\n",
    "  Cada um desses objetos irá receber as imagens já processadas com o método da <i>ResNetV2</i>, separados em treino e teste conforme a nomenclatura da variável.\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Posteriormente, é necessário criar os geradores das imagens (tanto de teste quanto de treino). Isso é feito atravez dos objetos criados anteriormente, através da função \"<i>flow_from_directory</i>\". Seus parâmetros são os que seguem:\n",
    "  <ul>\n",
    "    <li><i>path</i>: o caminho do diretório onde estão localizadas as imagens;</li>\n",
    "    <li><i>target_size</i>: o tamanho da imagem (neste caso, foi escolhido o tamanho 128x128);</li>\n",
    "    <li><i>batch_size</i>: o mesmo explicado anteriormente, que já foi definido como 32;</li>\n",
    "    <li><i>class_mode</i>: pode ser \"input\", caso a imagem de entrada e saída forem as mesmas, \"binary\" se existirem apenas duas classes para realizar a predição ou \"categorical\", caso hajam mais classes, que é este caso;</li>\n",
    "    <li><i>shuffle</i>: <i>booleano</i> para ativar ou não o embaralhamento da ordem das imagens que seram utilizadas.</li>\n",
    "  </ul>\n",
    "  O resultado obtido são dois geradores como saída, armazenados nos objetos:\n",
    "  <ul>\n",
    "    <li><i>train_generator</i>;</li>\n",
    "    <li><i>test_generator</i>.</li>\n",
    "  </ul>\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  Com os geradores criados, é preciso definir o otimizador. Conforme enunciado, os otimizadores que apresentam melhores resultados são o <i>SGD</i> e o <i>Adam</i>. Sendo assim, foi escolhido o <i>Adam</i>. Sendo assim, foi compilado o modelo com esses parâmetros, juntamente com a métrica escolhida como sendo por acurácia (<i>accuracy</i>), conforme orientação do enunciado.\n",
    "</div>\n",
    "</div>\n",
    "<br />\n",
    "<div>Por fim foram definidos os steps, e o modelo foi efetivamente treinado e testado. Os resultados podem ser vistos nos próximos tópicos.</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "golden-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    if l.name.split('_')[0] != 'dense':\n",
    "        l.trainable=False\n",
    "    else:\n",
    "        l.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "marine-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input) \n",
    "\n",
    "test_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "studied-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory('shapes_split/train',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "test_generator = test_data_gen.flow_from_directory('shapes_split/test',\n",
    "                                                 target_size=(128, 128), # tamanho da imagem para o generator                                                  \n",
    "                                                 batch_size=batch,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "individual-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=lr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "instrumental-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_test = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "about-bride",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.9187 - accuracy: 0.5425 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2804 - accuracy: 0.8676 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1542 - accuracy: 0.9393 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0927 - accuracy: 0.9711 - val_loss: 0.0430 - val_accuracy: 0.9688\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0597 - accuracy: 0.9777 - val_loss: 0.0642 - val_accuracy: 0.9688\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.0376 - val_accuracy: 0.9688\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0567 - accuracy: 0.9713 - val_loss: 0.0578 - val_accuracy: 0.9688\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0347 - accuracy: 0.9909 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0294 - accuracy: 0.9944 - val_loss: 0.0413 - val_accuracy: 0.9688\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0193 - accuracy: 0.9889 - val_loss: 0.1363 - val_accuracy: 0.9688\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0407 - accuracy: 0.9759 - val_loss: 0.1988 - val_accuracy: 0.9375\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0255 - accuracy: 0.9877 - val_loss: 0.1435 - val_accuracy: 0.9688\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.1096 - val_accuracy: 0.9688\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0252 - accuracy: 0.9879 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 0.0811 - val_accuracy: 0.9688\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0310 - accuracy: 0.9914 - val_loss: 0.0915 - val_accuracy: 0.9688\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0239 - accuracy: 0.9802 - val_loss: 0.0880 - val_accuracy: 0.9688\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0934 - val_accuracy: 0.9688\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0383 - accuracy: 0.9737 - val_loss: 0.0665 - val_accuracy: 0.9688\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0193 - accuracy: 0.9861 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9688\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0327 - accuracy: 0.9751 - val_loss: 0.0583 - val_accuracy: 0.9688\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 7s 967ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9688\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0281 - accuracy: 0.9868 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0083 - accuracy: 0.9926 - val_loss: 0.0331 - val_accuracy: 0.9688\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9688\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0280 - val_accuracy: 0.9688\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.0384 - val_accuracy: 0.9688\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 7s 995ms/step - loss: 0.0070 - accuracy: 0.9945 - val_loss: 2.3994e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 7s 972ms/step - loss: 0.0075 - accuracy: 0.9953 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0076 - accuracy: 0.9933 - val_loss: 0.0310 - val_accuracy: 0.9688\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0225 - accuracy: 0.9950 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0063 - accuracy: 0.9961 - val_loss: 0.0376 - val_accuracy: 0.9688\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0179 - accuracy: 0.9853 - val_loss: 3.3007e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0106 - accuracy: 0.9912 - val_loss: 7.4587e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0139 - accuracy: 0.9892 - val_loss: 8.5468e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 7s 983ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 6.6366e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.3429e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 7s 973ms/step - loss: 0.0148 - accuracy: 0.9880 - val_loss: 1.6954e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0096 - accuracy: 0.9907 - val_loss: 5.6038e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 4.0444e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0040 - accuracy: 0.9975 - val_loss: 4.0852e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0230 - accuracy: 0.9810 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 2.6213e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0206 - accuracy: 0.9812 - val_loss: 7.9155e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0036 - accuracy: 0.9982 - val_loss: 1.6233e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0129 - accuracy: 0.9925 - val_loss: 4.9267e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 3.4748e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0096 - accuracy: 0.9928 - val_loss: 1.9296e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 3.2088e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 1s/step - loss: 0.0103 - accuracy: 0.9942 - val_loss: 5.2111e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0097 - accuracy: 0.9931 - val_loss: 4.0373e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0132 - accuracy: 0.9892 - val_loss: 7.5782e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0113 - accuracy: 0.9901 - val_loss: 3.8254e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 8.1705e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.7302e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0225 - accuracy: 0.9840 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0047 - accuracy: 0.9961 - val_loss: 1.3895e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0039 - accuracy: 0.9972 - val_loss: 0.0717 - val_accuracy: 0.9688\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0076 - accuracy: 0.9949 - val_loss: 0.0630 - val_accuracy: 0.9688\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8004e-04 - accuracy: 1.0000 - val_loss: 8.2328e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0132 - accuracy: 0.9931 - val_loss: 2.1197e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0167 - accuracy: 0.9881 - val_loss: 2.3171e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9688\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0109 - accuracy: 0.9889 - val_loss: 0.0560 - val_accuracy: 0.9688\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0065 - accuracy: 0.9951 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0070 - accuracy: 0.9944 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 4.6938e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 6.9238e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5739e-04 - accuracy: 1.0000 - val_loss: 3.8743e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0098 - accuracy: 0.9901 - val_loss: 0.0329 - val_accuracy: 0.9688\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.5899e-04 - accuracy: 1.0000 - val_loss: 1.8254e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 0.0106 - accuracy: 0.9892 - val_loss: 7.0244e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 7s 975ms/step - loss: 0.0169 - accuracy: 0.9865 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.0083 - accuracy: 0.9928 - val_loss: 3.7625e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.2540e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9688\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 7s 963ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9688\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 2.0117e-07 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9688\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9688\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0384 - val_accuracy: 0.9688\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 6.5505e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0122 - accuracy: 0.9920 - val_loss: 3.0920e-07 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0148 - accuracy: 0.9859 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0073 - accuracy: 0.9931 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 4.7327e-04 - accuracy: 1.0000 - val_loss: 2.3097e-07 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.2475e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.1781e-07 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.6489e-04 - accuracy: 1.0000 - val_loss: 4.3213e-07 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0049 - accuracy: 0.9949 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.4037e-04 - accuracy: 1.0000 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0222 - accuracy: 0.9812 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0270 - accuracy: 0.9858 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.6170e-05 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 3.1292e-07 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0073 - accuracy: 0.9960 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.9399e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.0081 - accuracy: 0.9950 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.1176e-07 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0054 - accuracy: 0.9948 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0226 - accuracy: 0.9790 - val_loss: 2.3502e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 11s 1s/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.2321e-04 - accuracy: 1.0000 - val_loss: 2.5108e-04 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0033 - accuracy: 0.9961 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 4.5749e-05 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 2.8762e-04 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0045 - accuracy: 0.9945 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0137 - accuracy: 0.9892 - val_loss: 1.2666e-07 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2293e-07 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 1.7221e-05 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9740e-04 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.9980e-04 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0141 - accuracy: 0.9928 - val_loss: 1.3411e-07 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.0463e-05 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0075 - accuracy: 0.9926 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0148 - accuracy: 0.9891 - val_loss: 1.2890e-04 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0079 - accuracy: 0.9928 - val_loss: 9.6570e-05 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0156 - accuracy: 0.9837 - val_loss: 7.1303e-05 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0108 - accuracy: 0.9945 - val_loss: 1.4901e-08 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9688\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.5639e-04 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9688\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0095 - accuracy: 0.9918 - val_loss: 0.0720 - val_accuracy: 0.9688\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0109 - accuracy: 0.9904 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 11s 1s/step - loss: 2.3339e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.0692 - val_accuracy: 0.9688\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0051 - accuracy: 0.9945 - val_loss: 0.0293 - val_accuracy: 0.9688\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0070 - accuracy: 0.9945 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9688\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 5.2154e-08 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.2245 - val_accuracy: 0.9688\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0337 - accuracy: 0.9813 - val_loss: 0.3880 - val_accuracy: 0.9375\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.0252 - val_accuracy: 0.9688\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0076 - accuracy: 0.9919 - val_loss: 0.1757 - val_accuracy: 0.9688\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.4132e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9375\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0604 - accuracy: 0.9905 - val_loss: 0.1457 - val_accuracy: 0.9688\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0262 - accuracy: 0.9976 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0232 - accuracy: 0.9832 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.4079 - val_accuracy: 0.9375\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0380 - accuracy: 0.9853 - val_loss: 0.3439 - val_accuracy: 0.9688\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 0.9963 - val_loss: 0.1337 - val_accuracy: 0.9688\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0044 - accuracy: 0.9951 - val_loss: 1.3204e-04 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.0087e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.9158e-04 - accuracy: 1.0000 - val_loss: 7.0959e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.0129 - accuracy: 0.9896 - val_loss: 4.0978e-08 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 0.9981 - val_loss: 6.5758e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 6.6682e-07 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0134 - accuracy: 0.9906 - val_loss: 5.5134e-07 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0044 - accuracy: 0.9945 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0280 - accuracy: 0.9845 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0039 - accuracy: 0.9961 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1908e-04 - accuracy: 1.0000 - val_loss: 3.6844e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0040 - accuracy: 0.9945 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0163 - accuracy: 0.9862 - val_loss: 5.5506e-07 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0036 - accuracy: 0.9961 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0167 - accuracy: 0.9893 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 6.3338e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0083 - accuracy: 0.9919 - val_loss: 3.7253e-07 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0349 - accuracy: 0.9700 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0167 - accuracy: 0.9880 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.3092e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 3.3908e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.7048e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0040 - accuracy: 0.9961 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0106 - accuracy: 0.9865 - val_loss: 6.3329e-07 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0037 - accuracy: 0.9952 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.3056e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0154 - accuracy: 0.9891 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 9.3974e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.7153e-05 - accuracy: 1.0000 - val_loss: 3.5572e-05 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0085 - accuracy: 0.9957 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0093 - accuracy: 0.9926 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 4.7311e-07 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5128e-04 - accuracy: 1.0000 - val_loss: 4.7311e-07 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.3337e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 8.8460e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0157 - accuracy: 0.9931 - val_loss: 3.8209e-05 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.2195e-05 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "7/7 [==============================] - 7s 952ms/step - loss: 0.0189 - accuracy: 0.9793 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "7/7 [==============================] - 7s 943ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.9173e-07 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 5.1322e-05 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1176e-08 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "7/7 [==============================] - 6s 892ms/step - loss: 1.5979e-05 - accuracy: 1.0000 - val_loss: 2.7201e-05 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "7/7 [==============================] - 6s 883ms/step - loss: 0.0077 - accuracy: 0.9962 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "7/7 [==============================] - 6s 897ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "7/7 [==============================] - 6s 875ms/step - loss: 0.0139 - accuracy: 0.9889 - val_loss: 2.4187e-05 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "7/7 [==============================] - 6s 885ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "7/7 [==============================] - 6s 922ms/step - loss: 9.4427e-04 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 1s/step - loss: 0.0055 - accuracy: 0.9963 - val_loss: 2.3097e-07 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "7/7 [==============================] - 6s 899ms/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9688\n",
      "Epoch 234/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.1050e-05 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9688\n",
      "Epoch 235/500\n",
      "7/7 [==============================] - 6s 910ms/step - loss: 8.7848e-05 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9688\n",
      "Epoch 236/500\n",
      "7/7 [==============================] - 6s 887ms/step - loss: 0.0165 - accuracy: 0.9875 - val_loss: 2.4214e-07 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "7/7 [==============================] - 6s 874ms/step - loss: 9.2085e-04 - accuracy: 1.0000 - val_loss: 2.3097e-07 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "7/7 [==============================] - 6s 905ms/step - loss: 1.5423e-05 - accuracy: 1.0000 - val_loss: 3.8306e-05 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "7/7 [==============================] - 6s 883ms/step - loss: 0.0054 - accuracy: 0.9930 - val_loss: 0.0307 - val_accuracy: 0.9688\n",
      "Epoch 241/500\n",
      "7/7 [==============================] - 7s 950ms/step - loss: 2.7928e-04 - accuracy: 1.0000 - val_loss: 3.4366e-05 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "7/7 [==============================] - 6s 920ms/step - loss: 1.1462e-05 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9688\n",
      "Epoch 243/500\n",
      "7/7 [==============================] - 6s 905ms/step - loss: 0.0041 - accuracy: 0.9948 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0208 - accuracy: 0.9861 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1007e-05 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0028 - accuracy: 0.9973 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0077 - accuracy: 0.9930 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0061 - accuracy: 0.9943 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0435 - accuracy: 0.9680 - val_loss: 1.6104e-05 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0047 - accuracy: 0.9961 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "7/7 [==============================] - 6s 864ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "7/7 [==============================] - 6s 932ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "7/7 [==============================] - 7s 960ms/step - loss: 1.8809e-04 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "7/7 [==============================] - 6s 915ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.0658e-05 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "7/7 [==============================] - 6s 875ms/step - loss: 2.8653e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "7/7 [==============================] - 6s 867ms/step - loss: 1.5772e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "7/7 [==============================] - 6s 928ms/step - loss: 0.0024 - accuracy: 0.9975 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "7/7 [==============================] - 7s 954ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.2410e-07 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "7/7 [==============================] - 6s 863ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.4406e-05 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "7/7 [==============================] - 6s 913ms/step - loss: 0.0074 - accuracy: 0.9945 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "7/7 [==============================] - 6s 881ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "7/7 [==============================] - 6s 865ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "7/7 [==============================] - 6s 912ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.2626e-05 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "7/7 [==============================] - 6s 869ms/step - loss: 8.9895e-05 - accuracy: 1.0000 - val_loss: 1.1978e-05 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "7/7 [==============================] - 6s 933ms/step - loss: 0.0027 - accuracy: 0.9981 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "7/7 [==============================] - 7s 957ms/step - loss: 8.3353e-05 - accuracy: 1.0000 - val_loss: 1.3371e-05 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.2170e-05 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.4354e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.3695e-05 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 0.0138 - accuracy: 0.9884 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "7/7 [==============================] - 7s 949ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3338e-05 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "7/7 [==============================] - 7s 968ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0276 - accuracy: 0.9774 - val_loss: 2.1234e-07 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.3682e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0066 - accuracy: 0.9952 - val_loss: 1.3695e-05 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "7/7 [==============================] - 6s 921ms/step - loss: 0.0115 - accuracy: 0.9945 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.4846e-04 - accuracy: 1.0000 - val_loss: 1.1651e-05 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "7/7 [==============================] - 7s 986ms/step - loss: 1.1826e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.6686e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "7/7 [==============================] - 7s 983ms/step - loss: 1.3535e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "7/7 [==============================] - 6s 919ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 980ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 6.8761e-06 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "7/7 [==============================] - 6s 938ms/step - loss: 0.0082 - accuracy: 0.9948 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "7/7 [==============================] - 6s 917ms/step - loss: 0.0055 - accuracy: 0.9928 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "7/7 [==============================] - 6s 996ms/step - loss: 0.0228 - accuracy: 0.9761 - val_loss: 7.7391e-04 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0140 - accuracy: 0.9887 - val_loss: 3.0924e-04 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.0780e-07 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.8971e-04 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9774e-04 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.0779e-04 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.8917e-07 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0100 - accuracy: 0.9868 - val_loss: 1.8310e-04 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "7/7 [==============================] - 7s 953ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.4894e-04 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 6.5564e-07 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 6.3330e-08 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0040 - accuracy: 0.9972 - val_loss: 5.6560e-04 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0174 - accuracy: 0.9893 - val_loss: 6.0674e-04 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 7.5338e-04 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "7/7 [==============================] - 7s 990ms/step - loss: 0.0103 - accuracy: 0.9930 - val_loss: 4.7771e-04 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "7/7 [==============================] - 7s 972ms/step - loss: 2.0714e-05 - accuracy: 1.0000 - val_loss: 3.8058e-04 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.7646e-05 - accuracy: 1.0000 - val_loss: 7.2270e-07 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.9730e-05 - accuracy: 1.0000 - val_loss: 7.1152e-07 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.1197e-04 - accuracy: 1.0000 - val_loss: 4.2758e-04 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0111 - accuracy: 0.9919 - val_loss: 9.2386e-07 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "7/7 [==============================] - 7s 979ms/step - loss: 0.0190 - accuracy: 0.9887 - val_loss: 8.7543e-07 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "7/7 [==============================] - 7s 944ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 9.0896e-07 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 8.1955e-07 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.4383e-04 - accuracy: 1.0000 - val_loss: 8.3818e-07 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "7/7 [==============================] - 6s 920ms/step - loss: 1.6914e-04 - accuracy: 1.0000 - val_loss: 4.0744e-04 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.5076e-07 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4925e-04 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.9488e-07 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 2.2352e-08 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "7/7 [==============================] - 6s 988ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 3.1716e-05 - accuracy: 1.0000 - val_loss: 1.3493e-04 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8626e-08 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 3.0920e-07 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 8.7578e-05 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 9.1345e-05 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0141e-04 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1141e-04 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "7/7 [==============================] - 7s 967ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.1571e-04 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "7/7 [==============================] - 7s 952ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1683e-04 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "7/7 [==============================] - 7s 963ms/step - loss: 3.2235e-04 - accuracy: 1.0000 - val_loss: 1.2303e-04 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "7/7 [==============================] - 6s 911ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3432e-04 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.5771e-04 - accuracy: 1.0000 - val_loss: 3.2037e-07 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.9824e-05 - accuracy: 1.0000 - val_loss: 1.5499e-04 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.2037e-07 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6325e-04 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0065 - accuracy: 0.9949 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "7/7 [==============================] - 6s 925ms/step - loss: 3.9620e-04 - accuracy: 1.0000 - val_loss: 1.7551e-04 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "7/7 [==============================] - 6s 993ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.7533e-04 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2410e-07 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.2176e-04 - accuracy: 1.0000 - val_loss: 1.7693e-04 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 1.8146e-06 - accuracy: 1.0000 - val_loss: 3.4272e-07 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.1020e-06 - accuracy: 1.0000 - val_loss: 1.9232e-04 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "7/7 [==============================] - 7s 950ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.2410e-07 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7010e-04 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.3619e-06 - accuracy: 1.0000 - val_loss: 8.8288e-07 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "7/7 [==============================] - 7s 920ms/step - loss: 5.0339e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "7/7 [==============================] - 7s 968ms/step - loss: 1.0612e-04 - accuracy: 1.0000 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "7/7 [==============================] - 6s 895ms/step - loss: 2.6040e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "7/7 [==============================] - 7s 962ms/step - loss: 0.0058 - accuracy: 0.9952 - val_loss: 1.0691e-06 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0152 - accuracy: 0.9887 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "7/7 [==============================] - 6s 1000ms/step - loss: 8.9052e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "7/7 [==============================] - 7s 956ms/step - loss: 4.1860e-06 - accuracy: 1.0000 - val_loss: 1.0319e-06 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "7/7 [==============================] - 7s 989ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 3.7253e-09 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8103e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.6629e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5138e-05 - accuracy: 1.0000 - val_loss: 9.5033e-04 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 9.6863e-04 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 6.5937e-07 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.9518e-06 - accuracy: 1.0000 - val_loss: 6.6309e-07 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "7/7 [==============================] - 7s 941ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.7800e-07 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "7/7 [==============================] - 7s 956ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2485e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "7/7 [==============================] - 7s 988ms/step - loss: 9.8726e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "7/7 [==============================] - 7s 960ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0093 - accuracy: 0.9931 - val_loss: 7.1525e-07 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.5988e-06 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0040 - accuracy: 0.9972 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "7/7 [==============================] - 10s 2s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.7868e-05 - accuracy: 1.0000 - val_loss: 7.7858e-07 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 7.8975e-07 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 8.1210e-07 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "7/7 [==============================] - 7s 933ms/step - loss: 0.0156 - accuracy: 0.9880 - val_loss: 3.9769e-04 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "7/7 [==============================] - 7s 975ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.6497e-04 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "7/7 [==============================] - 7s 947ms/step - loss: 0.0296 - accuracy: 0.9889 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.2557e-06 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "7/7 [==============================] - 7s 973ms/step - loss: 5.1525e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "7/7 [==============================] - 6s 941ms/step - loss: 0.0116 - accuracy: 0.9910 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4178e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "7/7 [==============================] - 7s 970ms/step - loss: 1.8818e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.6094e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 5.8237e-05 - accuracy: 1.0000 - val_loss: 1.0915e-06 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0468e-06 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4422e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 1.5209e-07 - accuracy: 1.0000 - val_loss: 9.2013e-07 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0107 - accuracy: 0.9931 - val_loss: 8.4563e-07 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2501e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 3.6145e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.5653e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "7/7 [==============================] - 7s 988ms/step - loss: 0.0025 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 1s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 6.2564e-04 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.1682e-07 - accuracy: 1.0000 - val_loss: 5.0612e-04 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.3086e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.5022e-04 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.8056e-07 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.9075e-06 - accuracy: 1.0000 - val_loss: 4.6962e-04 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.6660e-07 - accuracy: 1.0000 - val_loss: 4.7763e-04 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "7/7 [==============================] - 7s 970ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 4.9376e-04 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.2254e-04 - accuracy: 1.0000 - val_loss: 4.6193e-07 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "7/7 [==============================] - 7s 962ms/step - loss: 1.7705e-07 - accuracy: 1.0000 - val_loss: 2.9057e-07 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "7/7 [==============================] - 6s 961ms/step - loss: 3.4471e-04 - accuracy: 1.0000 - val_loss: 2.6449e-07 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "7/7 [==============================] - 7s 998ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5332e-07 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.4959e-07 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 7.1708e-04 - accuracy: 1.0000 - val_loss: 3.1665e-07 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 7.8231e-08 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.4362e-05 - accuracy: 1.0000 - val_loss: 9.6583e-06 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "7/7 [==============================] - 7s 962ms/step - loss: 5.6301e-04 - accuracy: 1.0000 - val_loss: 5.0291e-07 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.8069e-04 - accuracy: 1.0000 - val_loss: 7.2642e-07 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0100 - accuracy: 0.9931 - val_loss: 1.6569e-04 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 8.5627e-06 - accuracy: 1.0000 - val_loss: 1.9706e-06 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 1.8020e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.0036 - accuracy: 0.9972 - val_loss: 7.7460e-04 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.1890e-06 - accuracy: 1.0000 - val_loss: 2.5666e-06 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "7/7 [==============================] - 7s 985ms/step - loss: 2.7232e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "7/7 [==============================] - 7s 968ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.0292e-06 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 9.5392e-06 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.4845e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 5.6599e-06 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.9672e-06 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 9.6225e-04 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 2.7865e-06 - accuracy: 1.0000 - val_loss: 7.7142e-04 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0036 - accuracy: 0.9973 - val_loss: 2.5182e-06 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.9627e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.8425e-06 - accuracy: 1.0000 - val_loss: 6.2520e-04 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0109 - accuracy: 0.9918 - val_loss: 2.1531e-06 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.2280e-05 - accuracy: 1.0000 - val_loss: 2.6113e-06 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "7/7 [==============================] - 6s 935ms/step - loss: 0.0023 - accuracy: 0.9972 - val_loss: 5.5398e-04 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0072 - accuracy: 0.9945 - val_loss: 1.0021e-06 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.1423e-04 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0174 - accuracy: 0.9889 - val_loss: 1.8581e-04 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0067 - accuracy: 0.9949 - val_loss: 2.3610e-04 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6714e-04 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 8.4061e-04 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0328 - accuracy: 0.9880 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.8663e-06 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.0983e-06 - accuracy: 1.0000 - val_loss: 6.1094e-07 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 2.0943e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0034 - accuracy: 0.9975 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 1s/step - loss: 1.1053e-06 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9688\n",
      "Epoch 456/500\n",
      "7/7 [==============================] - 6s 960ms/step - loss: 1.1009e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "7/7 [==============================] - 7s 965ms/step - loss: 0.0049 - accuracy: 0.9963 - val_loss: 1.9147e-06 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "7/7 [==============================] - 7s 979ms/step - loss: 1.3398e-05 - accuracy: 1.0000 - val_loss: 1.9632e-06 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "7/7 [==============================] - 7s 978ms/step - loss: 0.0154 - accuracy: 0.9892 - val_loss: 2.0377e-06 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 6.6649e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9688\n",
      "Epoch 461/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 462/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0201 - accuracy: 0.9892 - val_loss: 0.0827 - val_accuracy: 0.9688\n",
      "Epoch 463/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0150 - accuracy: 0.9930 - val_loss: 0.0755 - val_accuracy: 0.9688\n",
      "Epoch 464/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9688\n",
      "Epoch 465/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 4.1190e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.4304e-04 - accuracy: 1.0000 - val_loss: 1.3038e-06 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.1801e-04 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9688\n",
      "Epoch 468/500\n",
      "7/7 [==============================] - 7s 992ms/step - loss: 0.0056 - accuracy: 0.9964 - val_loss: 0.0824 - val_accuracy: 0.9688\n",
      "Epoch 469/500\n",
      "7/7 [==============================] - 7s 951ms/step - loss: 4.8116e-06 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9688\n",
      "Epoch 470/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4081e-06 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "7/7 [==============================] - 7s 934ms/step - loss: 1.6001e-04 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9688\n",
      "Epoch 472/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.1788e-07 - accuracy: 1.0000 - val_loss: 1.3374e-06 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 4.7329e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "7/7 [==============================] - 7s 964ms/step - loss: 0.0140 - accuracy: 0.9893 - val_loss: 1.3262e-06 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "7/7 [==============================] - 7s 994ms/step - loss: 5.5825e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.0107 - accuracy: 0.9919 - val_loss: 9.8719e-07 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9688\n",
      "Epoch 479/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0106 - accuracy: 0.9919 - val_loss: 6.9662e-07 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "7/7 [==============================] - 9s 1s/step - loss: 1.7981e-04 - accuracy: 1.0000 - val_loss: 6.4074e-07 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "7/7 [==============================] - 7s 984ms/step - loss: 9.0399e-05 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9688\n",
      "Epoch 482/500\n",
      "7/7 [==============================] - 7s 946ms/step - loss: 0.0157 - accuracy: 0.9889 - val_loss: 0.0342 - val_accuracy: 0.9688\n",
      "Epoch 483/500\n",
      "7/7 [==============================] - 7s 999ms/step - loss: 5.5230e-04 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9688\n",
      "Epoch 484/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 1.4850e-04 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9688\n",
      "Epoch 485/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9688\n",
      "Epoch 486/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9688\n",
      "Epoch 487/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0037 - accuracy: 0.9972 - val_loss: 0.0700 - val_accuracy: 0.9688\n",
      "Epoch 488/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9688\n",
      "Epoch 489/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 7.5073e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "7/7 [==============================] - 7s 940ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "7/7 [==============================] - 7s 974ms/step - loss: 1.0613e-04 - accuracy: 1.0000 - val_loss: 8.8661e-07 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "7/7 [==============================] - 6s 898ms/step - loss: 2.4444e-06 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9688\n",
      "Epoch 493/500\n",
      "7/7 [==============================] - 6s 908ms/step - loss: 0.0034 - accuracy: 0.9981 - val_loss: 0.0694 - val_accuracy: 0.9688\n",
      "Epoch 494/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9688\n",
      "Epoch 495/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2.2986e-05 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9688\n",
      "Epoch 496/500\n",
      "7/7 [==============================] - 8s 1s/step - loss: 6.2418e-08 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9688\n",
      "Epoch 497/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9688\n",
      "Epoch 498/500\n",
      "7/7 [==============================] - 7s 986ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.8743e-07 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "7/7 [==============================] - 7s 1s/step - loss: 8.3085e-07 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9688\n",
      "Epoch 500/500\n",
      "7/7 [==============================] - 7s 999ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 4.0978e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_generator,\n",
    "                   validation_steps=step_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quality-denver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 7s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0455 - accuracy: 0.9688\n",
      "Acurácia de treino: 1.000 \n",
      "Acurácia de teste: 0.969 \n"
     ]
    }
   ],
   "source": [
    "loss_train, train_acc = model.evaluate(train_generator, steps=step_size_train)\n",
    "loss_test, test_acc = model.evaluate(test_generator, steps=step_size_test)\n",
    "print('Acurácia de treino: %.3f ' % (train_acc))\n",
    "print('Acurácia de teste: %.3f ' % (test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc01ce6",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "  Observando os números acima para a acurácia, podemos ver que o resultado foi um número muito atípico, no caso <i>1.000</i>, que representa 100% de acurácia no treino e no teste. Quando isso acontece, geralmente se dá o nome de <i>overfit</i> (ou <i>overfitting</i>), que é quando um modelo estatístico se ajusta bem demais ao conjunto de dados observado, mas se mostra ineficaz para prever novos resultados. Os gráficos abaixo ilustram bem esse comportamento:\n",
    "<img src=\"https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png\" width=\"700\"/>\n",
    "</div>\n",
    "<br/>\n",
    "<div>\n",
    "  O gráfico seguinte apresenta a taxa de perda de treino e de teste:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "northern-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Perda')\n",
    "plt.plot(history.history['loss'], label='treino')\n",
    "plt.plot(history.history['val_loss'], label='teste')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa20292",
   "metadata": {},
   "source": [
    "O gráfico seguinte apresenta a acurácia de treino e de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "industrial-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Acurácia')\n",
    "plt.plot(history.history['accuracy'], label='treino')\n",
    "plt.plot(history.history['val_accuracy'], label='teste')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b4bc4",
   "metadata": {},
   "source": [
    "Por fim, são feitas as classificações finais, onde são criadas as estruturas para as métricas de avaliação.\n",
    "\n",
    "<h3>Classification Report</h3>\n",
    "\n",
    "<ul>\n",
    "    <li>TN / True Negative: o caso foi negativo e previsto como negativo</li>\n",
    "    <li>TP / True Positive: o caso foi positivo e positivo previsto</li>\n",
    "    <li>FN / False Negative: o caso era positivo, mas previsto como negativo</li>\n",
    "    <li>FP / False Positive: o caso foi negativo, mas previsto como positivo</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<h3>Precisão - Qual porcentagem de suas previsões estava correta?</h3>\n",
    "<p>É a capacidade de um classificador de não marcar uma instância como positiva (na verdade, negativa). Para cada categoria, é definido como a proporção de verdadeiros positivos para a soma de verdadeiros positivos e falsos positivos.</p>\n",
    "<p>Formula (Precisão de previsões positivas): <i>Precision = TP/(TP + FP)</i> </p>\n",
    "\n",
    "<h3>Recall - Qual a porcentagem de casos positivos que você pegou?</h3>\n",
    "<p>É a capacidade do classificador de encontrar todas as instâncias positivas. Para cada categoria, é definido como a proporção de verdadeiros positivos para a soma de verdadeiros positivos e falsos negativos.</p>\n",
    "<p>Fórmula (Fração de positivos que foram identificados corretamente): <i>Recall = TP/(TP+FN)</i></p>\n",
    "\n",
    "<h3>F1 Score - Qual porcentagem de previsões positivas estavam corretas?</h3>\n",
    "<p>É a média harmônica ponderada de acurácia e recordação, portanto, a pontuação mais alta é 1,0 e a pior diferença é 0,0. As pontuações F1 são mais baixas do que as medições de precisão porque incorporam precisão e recall no cálculo. Geralmente, a média ponderada F1 deve ser usada para comparar os modelos do classificador, ao invés da precisão geral.</p>\n",
    "<p>Fórmula: <i>F1 Score = 2*(Recall * Precision) / (Recall + Precision)</i></p>\n",
    "\n",
    "<h3>Support</h3>\n",
    "<p>É o número real de ocorrências da classe no conjunto de dados especificado. O suporte desequilibrado nos dados de treinamento pode indicar fraquezas estruturais nas pontuações do classificador relatadas e pode indicar a necessidade de amostragem estratificada ou rebalanceamento. O suporte não mudará entre os modelos, mas sim um processo de avaliação diagnóstica.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "upper-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando classificações..\n",
      "Rótulos ['circles', 'squares', 'triangles']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2001: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds Created\n",
      "Preds 1D created\n"
     ]
    }
   ],
   "source": [
    "print('Criando classificações..')\n",
    "labels = os.listdir('shapes_split/test')\n",
    "print('Rótulos', labels)\n",
    "#criando estruturas para métricas de avaliação, processo um pouco mais demorado\n",
    "Y_pred = model.predict_generator(test_generator)\n",
    "print('Preds Created')\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Preds 1D created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89466cbe",
   "metadata": {},
   "source": [
    "Podemos observar as classificações finais, divididas em:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beneficial-fluid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------CLASSIFICATION--------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     circles       0.29      0.30      0.29        20\n",
      "     squares       0.26      0.25      0.26        20\n",
      "   triangles       0.45      0.45      0.45        20\n",
      "\n",
      "    accuracy                           0.33        60\n",
      "   macro avg       0.33      0.33      0.33        60\n",
      "weighted avg       0.33      0.33      0.33        60\n",
      "\n",
      "----------------MATRIX--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classification = classification_report(test_generator.classes, y_pred, target_names=labels)\n",
    "print('----------------CLASSIFICATION--------------')\n",
    "print(classification)\n",
    "matrix = confusion_matrix(test_generator.classes, y_pred)\n",
    "df_cm = pd.DataFrame(matrix, index = [i for i in range(3)],\n",
    "                  columns = [i for i in range(3)])\n",
    "plt.figure(figsize = (10,7))\n",
    "print('----------------MATRIX--------------')\n",
    "sn.heatmap(df_cm, annot=True, linewidths=2.5, xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223cf4c",
   "metadata": {},
   "source": [
    "<h3>Referências bibliográficas:</h3>\n",
    "<hr />\n",
    "<div>\n",
    "<p><strong>Mini Curso CNN Transfer Learning</strong>, William Sdayle Marins Silva. Disponível em: https://colab.research.google.com/drive/11akI_B5M0Y2cuO1Y5Qq7W36YuehkzvKh?usp=sharing. Acesso em 20 de Abril de 2021.</p>\n",
    "    \n",
    "<p><strong>A Gentle Introduction to the Rectified Linear Unit (ReLU)</strong>, Jason Brownlee. Disponível em: https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/. Acesso em 20 de Abril de 2021.</p>\n",
    "    \n",
    "<p><strong>Arquiteturas de Redes Neurais Convolucionais para reconhecimento de imagens</strong>, Alexandre Luiz Bianchi. Disponível em: https://www.viceri.com.br/insights/arquiteturas-de-redes-neurais-convolucionais-para-reconhecimento-de-imagens/. Acesso em 20 de Abril de 2021.</p>\n",
    "\n",
    "<p><strong>Overfitting e underfitting em Machine Learning</strong>, Henrique Branco. Disponível em: https://abracd.org/overfitting-e-underfitting-em-machine-learning/. Acesso em 20 de Abril de 2021.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
